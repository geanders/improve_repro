## Example: Creating a reproducible data pre-processing protocol

We will walk through an example of creating a reproducible protocol for the
automated gating of flow cytometry data for a project on the immunology of
tuberculosis lead by one of our Co-Is. This data pre-processing protocol was
created using RMarkdown and allows the efficient, transparent, and reproducible
gating of flow cytometry data for all experiments in the research group. We will
walk the trainees through how we developed the protocol initially, the final
pre-processing protocol, how we apply this protocol to new experimental data.

**Objectives.** After this module, the trainee will be able to:

- Explain how a reproducible data pre-processing protocol can be integrated into
a real research project
- Understand how to design and implement a data pre-processing protocol to
replace manual or point-and-click data pre-processing tools

### Introduction and example data

In this module, we'll provide advice and an example of how you can use the 
tools for knitted documents to create a reproducible data preprocessing 
protocol. This module builds on ideas and techniques that were introduced 
in the last two modules, to help you put them into practical use for 
data preprocessing that you do repeatedly for research data in your 
laboratory.

In this module, we will use an example of a common pre-processing task in
immunological research: estimating the bacterial load in samples by plating at
different dilutions, identifying a good dilution for counting colony-forming
units (CFUs), and then back-calculating the estimated bacterial load in the
original sample based on the colonies counted at this dilution. This
experimental technique dates back to the late 1800s, with Koch, and continues to
be widely used in microbiology research and applications today
[@ben2014estimation]. These data are originally from example data for an R
package called `bactcountr`, currently under development at
https://github.com/aef1004/bactcountr/tree/master/data.

These data represent data from a common laboratory task in immunological
research: estimating the bacterial load in samples by plating each sample at
different dilutions and counting colony-forming units at a "good" dilution for
each sample. For example, you may be testing out some drugs against an
infectious bacteria and want to know how successful different drugs are in
limiting bacterial load. You run an experiment and have samples from animals
treated with different drugs or under control. You want to know: How much viable
(i.e., replicating) bacteria are in each of your samples? 

You can find out by plating the sample at different dilutions and
counting the colony-forming units (CFUs) that are cultured on each plate.
You put a sample on a plate with a medium they can grow on and then give them
time to grow. The idea is that individual bacteria from the original sample end
up randomly around the surface of the plate, and any that are viable (able to
reproduce) will form a new colony that, after a while, you'll be able to see.

To count the number of colonies, you need a "just right" dilution (and you
typically won't know which dilution this is for a sample until after plating) to
have a countable plate. If you have too high of a dilution (i.e., one with very
few viable bacteria), randomness will play a big role in the CFU count, and
you'll estimate the original with more variability. If you have too low of a
dilution (i.e., one with lots of viable bacteria), it will be difficult to
identify separate colonies, and they may complete for resources. To translate
from diluted concentration to original concentration, you can then do a
back-calculation, incorporating both the number of colonies counted at that
dilution and how dilute the sample was. There is therefore some pre-processing
required (although it is fairly simple) to prepare the data collected by 
counting the CFUs on each plate for use in statistical testings and to 
combine with other experimental data. 

We will use this example pre-processing protocol as an illustration in this
module. If you would like, you can access all the components and follow along
with the example, re-rendering it yourself on your own computer. The example
data are available as a csv file, downloadable
[here](https://raw.githubusercontent.com/geanders/improve_repro/master/data/bactcountr_example_data/cfu_data.csv).
You can open this file using spreadsheet software, or look at it directly in
RStudio. 

The final pre-processing protocol for these data can be downloaded, including
both [the original RMarkdown
file](https://raw.githubusercontent.com/geanders/improve_repro/master/data/bactcountr_example_data/example_protocol.Rmd)
and [the output PDF
document](https://github.com/geanders/improve_repro/raw/master/data/bactcountr_example_data/example_protocol.pdf).
Throughout this module, we will walk through elements of this document, to
provide an example as we explain the process of developing data pre-processing
modules for common tasks in your research group.

This example is intentionally simple, to allow a basic introduction to the
process using pre-processing tasks that are familiar to many laboratory-based
scientists and easy to explain to anyone who has not used plating experimental
work. However, the same general process can also be used to create
pre-processing protocols for data that are much larger or more complex or for
pre-processing pipelines that are much more involved.

### Advice on designing a pre-processing protocol

Before you write your protocol in a knitted document, you should decide on the
content to include in the protocol. 

**Defining input and output data for the protocol.**

The first step in designing the data pre-processing protocol is to decide on
what the starting point will be for the protocol (the data input) and what will
be the ending point (the data output). It may make sense to design a separate
protocol for each major type of data that you collect in your research
laboratory. Your input data for the protocol, under this design, might be the
data that is output from a specific type of equipment (e.g., flow cytometer) or
from a certain type of sample or measurement (e.g., metabolomics run on a mass
spectrometer), even if it is a fairly simple type of data (e.g., CFUs from
plating data, as used in the example protocol for this module). For example, say
you are working with data from a flow cytometer, metabolomics data measuremd
with a mass spectrometer, and bacterial load data measured by plating data and
counting colony forming units (CFUs). In this case, you may want to create three
pre-processing protocols: one for the flow data, one for the metabolomics data,
and one for the CFU data. 

While pre-processing protocols for some types of data might be very complex,
others might be fairly simple. However, it is still worthwhile to develop a
protocol, as it allows you to pass along some of the details of pre-processing
the data that might have become "common sense" to longer-tenured members of your
research group. For example, The pre-processing protocol is fairly simple for
the CFU data used in the example protocol for this module. This protocol inputs
data collected in a plain-text delimited file (a csv file, in the example).
Within the protocol, there are be steps to convert initial measurements from
plating at different dilutions into estimates of the bacterial load in each
original sample. There are also sections in the protocol for exploratory data
analysis, to allow for quality assessment and control of the collected data as
part of the preprocessing. The output of the protocol is a simple data object (a
dataframe, in this example) with the bacterial load for each original sample.
These data are now ready to be used in tables and figures in the research report
or manuscript, as well as to explore associations with the experimental design
details (e.g., comparing bacterial load in treated versus untreated animals) or
merged with other types of experimental data (e.g., comparing immune cell
populations, as measured with flow cytometry data, with bacterial loads, as
measured from plating and counting CFUs).

Once you have identified the input data type to use for the protocol, you should
identify an example dataset from your laboratory that you can use to create the
protocol. This could be a dataset that you currently need to pre-process, in
which case the development of the protocol will serve a second purpose as
allowing you to complete this task at the same time. However, you may not have a
new set of data of this type that you need to pre-process, and in this case you
can build your protocol using a dataset from a previous experiment in your
laboratory. In this case, you may already have a record of the steps that you
used to pre-process the data previously, and these can be helpful as a starting
point as you draft the more thorough pre-processing protocol. You may want to
select an example dataset that you have already published or are getting ready
to publish, so you won't feel awkard about making the data available for people
to practice with.  If you don't have an example dataset from your own
laboratory, you can explore example datasets that are already available, either
as data included with existing R packages or through open repositories,
including those hosted through national research institutions like the NIH. In
this case, be sure to cite the source of the data and include any available
information about the equipment that was used to collect it and the settings
used when the data were collected.

You can include the data and the RMarkdown file for the protocol in an RStudio
Project (see module [x]) and post this either publicly or privately on GitHub
(see modules [x]). This creates a "packet" of everything that a reader needs to
use to recreate what you did---they can download the whole GitHub repository and
will have a nice project directory on their computer with everything they need
to try out the protocol.

For the example protocol for this module, we want to pre-process data that were
collected "by hand" by counting CFUs on plates in the laboratory. These counts
were recorded in a plain text delimited file (a csv file) using spreadsheet
software. The spreadsheet was set up to ensure the data were recorded in a
"tidy" format, as described in module 2.3. The first few rows of the input data
look like:

```{r echo = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
cfu_data <- read_csv("data/bactcountr_example_data/cfu_data.csv")

head(cfu_data)
```

Each row represents the number of bacterial colonies counted after plating a
certain sample at a certain dilution. Columns are included with values for the
experimental group of the sample (`group`), the specific ID of the sample within
that experimental group (`replicate`, e.g., `2-A` is mouse A in experimental
group 2), the dilution level for that plating (`dilution`), and the number of
bacterial colonies counted in that sample (`CFUs`).

When you have identified the input data type you will use for the protocol, 
as well as selected an example dataset of this type to use to create the 
protocol, you can include a subsection in the "Overview" section of the protocol
that describes these input data, what file format they are in, and how they
can be read into R for pre-processing (Figure \@ref(fig:protocoldatainput)).

```{r protocoldatainput, echo = FALSE, out.width = "\\textwidth", fig.fullwidth = TRUE, fig.cap = "Providing details on input data in the pre-processing protocol. Once you have an example data file for the type of data that will be input for the protocol, you can add a section that provides the code to read the data into R. You can also add code that will show the first few rows of the example dataset, as well as a description of the data. This figure shows examples of how these elements can be added to an RMarkdown file for a pre-processing protocol, and the associated elements in the final pdf of the protocol, using the example protocol for this module."}
knitr::include_graphics("figures/protocol_data_input.png")
```

For the data output, it often makes sense to plan for data in a format that is
appropriate for data analysis and for merging with other types of data collected
from the experiment.

**Outlining key tasks in pre-processing the input data.**

The next step is to outline the key tasks that are involved in moving from the
data input to the desired data output. For the plating data we are using for our
example, the key tasks to be included in the pre-processing protocol are:

1. Read the data into R
2. Explore the data and perform some quality checks
3. Identify a "good" dilution for each sample---one at which you have a
"countable" plate
4. Estimate the bacterial load in each original sample based on the CFUs counted
at the "good" dilution for the sample
5. Output data with the estimated bacterial load for each original sample

Once you have this basic design, you can set up the pre-processing protocol to
include a separate section for each task, as well as an "Overview" section at
the beginning to describe the overall protocol, the data being pre-processed,
and the laboratory procedures used to collect those data. In RMarkdown, you can
create first-level section headers by putting the text for the header on its own
line and beginning that line with `#`, followed by a space. You should include a
blank line before and after the line with this header text. Figure
\@ref(fig:protocolsections) shows how this is done in the example protocol for
this module, showing how text in the plain text RMarkdown file for the protocol
align with section headers in the final pdf output of the protocol.

```{r protocolsections, echo = FALSE, out.width = "\\textwidth", fig.fullwidth = TRUE, fig.cap = "Dividing an RMarkdown data pre-processing protocol into sections. This shows an example of creating section headers in a data pre-processing protocol created with RMarkdown, showing section headers in the example pre-procotcol for this module."}
knitr::include_graphics("figures/protocol_sections.png")
```

**Adding key code for pre-processing.**

For many of these steps, you likely have code---or can start drafting the
code---required for that step. If you were doing the pre-processing entirely
through a code script or interactively, you would exclusively write code for the
steps. A good next step, therefore, in designing your pre-protocol is to add in
the code for each step to conduct the pre-processing required in each section.

In RMarkdown, you can test this code as you write it. You insert each piece
of executable code within a special section, separated from the regular 
text with special characters, as described in previous modules.

For any pre-processing steps that are straightforward (e.g., calculating the
dilution factor in the example module, which requires only simple mathematical
operations), you can directly write in the code required for the step. 
For other pre-processing steps, however, the algorithm may be a bit more 
complex. For example, complex algorithms have been developed for steps like 
peak identification and alignment that are required when 
pre-processing data from a mass spectrometer. 

For these more complex tasks, you can start to explore available R packages for
performing the task. There are thousands of packages available that extend the
basic functionality of R, providing code implementations of algorithms in a
variety of scientific fields. Many of the R packages relevant for biological
data---especially high-throughput biological data---are available through a
repository called Bioconductor. These packages are all open-source (so you can
explore their code if you want to) and free. You can use vigettes and package
manuals for Bioconductor packages to identify the different functions you can
use for your pre-processing steps. Once you have identified a function for the
task, you can use the helpfile for the function to see how to use it. This help
documentation will allow you to determine all of the function's parameters and
the choices you can select for each.



### Writing research protocols

There are some standards that are typically used when writing protocols for
research. This is a common practice for task that are repeated in a laboratory, 
including [examples from wet lab].

[Advantages of creating and using a protocol]

Computation tasks, including data pre-processing, can also be standardized 
through the creation and use of a protocol. 

A protocol, in the sense we use it here, is essentially an annotated 
recipe for each step in preparing your data from the initial, "raw" state 
that is output from the laboratory equipment (or collected by hand) to a
state that is useful for answering important research questions. The 
exact implementation of each step is given in code that can be re-used and
adapted with new data of a similar format. However, the code script is 
often not enough to helpfully understand, share, and collaborate on the
process. Instead, it's critical to also include descriptions written 
by humans and for humans. These annotations can include descriptions of the
code and how certain parameters are standardized the algorithms in the code.
They can also be used to justify choices, and link them up both with 
characteristics of the data and equipment for your experiment as well as
with scientific principles that underlie the choices. Protocols like this
are critical to allow you to standardize the process you use across many 
samples from one experiment, across different experiments and projects in 
your research laboratory, and even across different research laboratories.

[Links with Good Laboratory Practices (GLP), then link in with 
"Good Enough" computational practice, links with the idea of 
standard operating procedures]

Clinical studies are organized and guided by a protocol prepared before the 
study: 

> "Writing a research proposal is probably one of the most challenging and
difficult task as research is a new area for the majority of postgraduates and
new researchers." [@al2016protocol]

> "Clinical research is conducted according to a plan (a protocol) or an action plan. The protocol demonstrates the guidelines for conducting the trial. It illustrates what will be made in the study by explaining each essential part of it and how it is carried out. It also describes the eligibility of the participants, the length of the study, the medications and the related tests." [@al2016protocol]

> "Protocol writing allows the researcher to review and critically evaluate the published literature on the interested topic, plan and review the project steps and serves as a guide throughout the investigation."  [@al2016protocol]

A protocol should include some background, the aims of the work, hypotheses
to be tested, materials and methods, methods of data collection and 
equipment to analyze samples [@al2016protocol] (This reference is discussing
full protocols for a study, e.g., a clinicial trial, so includes more steps
that just pre-processing.)

One characteristic of a good protocol for a clinical study: 

> "It should provide enough detail (methodology) that can allow another investigator to do the study and arrive at comparable conclusions." [@al2016protocol]

Good protocols include not only how, but also why. This includes both 
higher-level (i.e., what a larger question is being asked) and also at a 
fine level, for each step in the process. [Analogy---cookbook that covers
deeper principles for why each step in process is done. *America's Test Kitchen*
recipes versus back-of-the-package recipes.]

When you write a protocol within RMarkdown, you can include references 
very easily. Figure \@ref(fig:protocolreferences) shows an example of the 
elements you use to do this, showing each element in the example protocol for
this module. 

```{r protocolreferences, echo = FALSE, out.width = "\\textwidth", fig.fullwidth = TRUE, fig.cap = "Including references in a data pre-processing protocol created with RMarkdown. RMarkdown has a built-in referencing system that you can use, based on the BibTeX system for LaTeX. This figure shows examples from the example protocol for this module of the elements used for referencing. You create a BibTeX file with information about each reference, and then use the key for the reference within the text to cite that reference. All cited references will be printed at the end of the document; you can chose the header that you want for this reference section in the RMarkdown file ('References' in this example). In the YAML of the RMarkdown file, you specify the path to the BibTeX file (with the 'bibliography: ' key), so it can be linked in when the RMarkdown file is rendered."}
knitr::include_graphics("figures/protocol_references.png")
```


The process of writing a protocol forces you to think about each step in the
process, why you do it a certain way (include parameters you choose for 
certain functions in a pipeline of code), and include justifications from 
the literature for this reasoning. If done well, it should allow you to 
quickly and thoroughly write the associated sections of Methods in research 
reports and manuscripts and help you answer questions and challenges from 
reviewers. 

Writing this will also help you identify steps for which you are uncertain
how to proceed and what choices to make in customizing an analysis for your
research data. These are areas where you can search more deeply in the 
literature to understand implications of certain choices and, if needed, 
contact the researchers who developed and maintained associated software 
packages to get advice.

> "Due to the slow growth rate and pathogenicity of mycobacteria, enumeration by
traditional reference methods like colony counting is notoriously
time-consuming, inconvenient and biohazardous. " [@pathak2012counting]

> "Traditionally, quantification of mycobacteria is done by seeding serial
dilutions of bacterial suspensions on suitable media such as Middlebrook 7H10
agar or Lowenstein Jensen followed by counting colony-forming units (CFU).
However, this method is hampered by the long generation time and the tendency of
mycobacteria to aggregate, resulting in multiple founders of a single colony and
an underestimation of the correct number of bacteria. Typically, the time
required for visible colonies to appear on 7H10 agar is 2--3 weeks for M.
tuberculosis and M. a. avium, while it takes about 4--8 weeks for M. a.
paratuberculosis. In addition, plating enough dilutions to make sure the results
can be reliably counted is a tedious task that gives piles of plates with
biohazardous bacteria. A further disadvantage of the colony counting method is
that it cannot be reliably conducted on frozen samples, which may be both more
practical and desirable in several research settings." [@pathak2012counting]

> "Mycobacterium tuberculosis culture, a critical technique for routine diagnosis of tuberculosis, takes more than two weeks." [@ghodbane2014dramatic]

> "A major problem when dealing with tuberculosis has been a difficulty in
diagnosis due to slow growth of mycobacterial cultures, which subsequently
explains the slow process of evaluating the susceptibility of this microorganism
to antibiotics. Using current tools, a primary culture is obtained in two to
four weeks on average and antibiotic susceptibility is determined after an
additional two to four weeks. Therefore, four to eight weeks are needed to
obtain an isolate and determine its susceptibility to antibiotics."
[@ghodbane2014dramatic]

> "Quantification of viable bacteria is a crucial foundation for many types of
research. This seemingly simple task can be challenging, expensive, and
imprecise for Mycobacterium paratuberculosis, a slowly growing organism (>24-h
generation time) with a strong tendency to form large clumps. Studies of
environmental survival, resistance to pasteurization or disinfectants, and
quantification of the pathogen in milk and feces from infected animals are just
a few examples that require precise and sensitive quantification of viable M.
paratuberculosis cells." [@shin2007rapid]

> "The main challenge in serial dilution experiments is the estimation of the
undiluted microorganisms counts $n_0$ from the measured $\hat{n_j}$. There are
two competing processes (Tomasiewicz et al., 1980) that affect the accuracy of
the estimation: sampling errors and counting errors. Sampling errors are caused
by the statistical fluctuations of the population. For example, when sampling an
average of 100 colonies, the fluctuations in the number of the population are
expected to be $\pm \sqrt{100}$ when the sampling process is governed by a
Poisson probability (Poisson and Binomial distributions are often used in
statistical analysis to describe the dilution process (Hedges, 2002, Myers et
al., 1994)) where the standard deviation equals square-root of the mean; the
relative error (ratio of the standard deviation to the mean) is $\sqrt{100} /
100 = 0.1$. Thus, the larger the sample size is, the smaller the relative
sampling error; hence, one would like to use a dilution plate with the largest
number  (i.e., the least diluted sample, $j \rightarrow 1$). However, as the
number of colonies increases, counting error is introduced due to the high
probability of two (or more) colonies to merge (due to overcrowding) and become
indistinguishable, and be erroneously counted as one colony. An optimum (a
'sweet spot') between these two processes (sampling and counting error) needs to
be found for using the optimal dilution  (i.e., the optimal jth plate) with
which to estimate $n_0$. Cells can grow into colonies in various ways. Wilson
(1922) states that when two cells are placed very close together only one cell
will develop, and when two cells are situated at a distance from each other both
cells may grow and then fuse into one colony. Either way, the end result is the
appearance of one colony which causes counting error." [@ben2014estimation]

For open-source software, resources to consult extend beyond the traditional
one. You can often find information on open-source software, including the
algorithms and principles that underlie the software, through peer-reviewed
publications in the scientific literature. However, you can also find
details---and often more thorough details---in *vignettes* that are published in
conjunction with the package. [More on vignettes and where to find them.]
Further, software is often presented at conferences and workshops, including the
yearly BioC [?] conference for the Bioconductor community. These talks and
workshops are sometimes available after the event as online recordings [some
examples of these]. You can consult books, as well, although these often 
quickly become outdated for software that is rapidly evolving; an exception 
is online books, which are becoming very popular to create through R's
`bookdown` package and can be rapidly updates. Many of these books are 
available through [bookdown's gallery page].

An added advantage of data pre-processing protocols, created with knitted
documents, is that you can include steps and code for data quality 
assessment. [More on exploratory data analysis] [Examples of how 
exploratory data analysis could help when pre-processing biomedical 
data---for example, identify outliers that might indicate equipment 
was malfunctioning?]

Be sure that, in each step of your pre-processing protocol, you explain 
*why* you are taking a certain step. For example, if you have a step
that aligns peaks across samples in metabolomics data [?], be sure to 
explain that ... [why it's important to do this]. Include references to 
the literature that justify this explanation; these references also 
serve as further literature that someone else could read to understand
the step. This *why* is important even if the step is obvious to you---it
will allow you to pass along the task to others in your research group 
without the new person needing to blindly trust each step. 

It is particularly important to clearly explain what you are doing in 
each step and how you are implementing your choices through code. Yes,
the code itself allows someone else to replicate what you did. However, 
only those who are very, very familiar with the software program, including
any of the extension packages you include, can "read" the code directly 
to understand what it's doing. Further, even if you understand the code
very well when you create it, it is unlikely that you will stay at that
same level of comprehension in the future, as other tasks and challenges
take over that brain space. Explaining for humans, in text that augments
and accompanies the code, is also important because function names and
parameter names in code often are not easy to decipher. While excellent
programmers can sometimes create functions with clear and transparent
names, easy to translate to determine the task each is doing, this is 
difficult in software development and is rare in practice. Human annotations, 
written by and for humans, are critical to ensure that the steps will 
be clear to you and others in the future when you revisit what was
done with this data and what you plan to do with future data. 

You can begin to create this pre-processing protocol before you collect
any of your own research data. Example datasets exist online, and you 
can often find an example that aligns with the type of data you will 
be collecting and the format you will be collecting it in. [Places where
you could get this data---repositories, R package example datasets.]
[Characteristics that are important in your example dataset---same file
format that you will get from your equipment, key characteristics, like 
number of experimental groups, like treatment categories and single vs 
multiple time points]

If the format of the initial data is similar to the format you anticipate for
your data, you can create the code and explanations for key steps in your
pre-processing for that type of data. Often, you will be able to adapt the
RMarkdown document to change it from inputting the example data to inputting
your own experimental data with minimal complications, once your data 
comes in. By thinking through and researching data pre-processing options
before the data is collected, you can save time in analyzing and presenting
your project results once you've completed the experimental data 
collection for the project. 

Further, with an example dataset, you can get a good approximation of the
format in which you will output data from the pre-processing steps. 
This will allow you to begin planning the analysis and visualization 
that you will use to combine the different types of data from your 
experiment and use it to investigate important research hypotheses. 
Again, if data follow standardized formats across steps in your process, 
it will often be easy to adapt the code in the protocol to input the new
dataset that you created, without major changes to the code developed with 
the example dataset. 

For each step of the protocol, you can also include potential problems
that might come up in specific instances of the data you get from 
future experiments. This can help you adapt the code in the protocol in 
thoughtful ways as you apply it in the future to new data collected
for new studies and projects.

> "Given an unknown sample which contains $n_0$ colony forming units (CFUs), a
series of $J$ dilutions are made sequentially each with a dilution factor
$\alpha$. From each of the J dilutions a fraction $\alpha_p^{-1}$ is taken and
spread (plated) on an agar plate (assay) where colonies are counted. Thus, in
general there are two dilution factors: $\alpha$ and $\alpha_p$. For example,
$\alpha = 10$ indicates a 10-fold dilution, e.g., by diluting successively 0.1
ml of sample into 0.9 ml of media; and $\alpha_p = 1$ means that the entire
volume is spread (plated) on the agar plate. For an experiment with a larger
dilution factor $\alpha_p$, multiple plates may be spread at the same dilution
stage. For example, $\alpha_p = 20$ represent a 5% plating of the dilution, and
thus up to 20 replicates could be created. At each dilution the true number of
colonies is $n_j = n_0 \alpha^{-j} \alpha_p^{-1}$ and the estimated number is
$\hat{n_j}$. The estimated quantities are denoted with a 'hat' (estimated
quantities can be measured quantities, or quantities that are derived from
measured or sampled quantities); symbols without a 'hat' denote true quantities
(also known as population values in statistics) that do not contain any sampling
or measurement error. In this work both $n_j$ and $n_0$ are 'counts', i.e.,
number of colonies. Knowing the aliquot volume, one can easily convert counts to
concentration (for example CFU/ml)." [@ben2014estimation]

In your data pre-processing protocol, show the code that you use to implement
this choice and also explain clearly in the text why you made this choice and
what alternatives should be considered if data characteristics are different.
Write this as if you are explaining to a new research group member (or your
future self) how to think about this step in the pre-processing, why you're
doing it the way your doing it, and what code is used to do it that way. You
should also include references that justify choices when they are
available---include these using BibTex. By doing this, you will make it much
easier on yourself when you write the Methods section of papers that report on
the data you have pre-processed, as you'll already have draft information on
your pre-processing methods in your protocol.

### Practice quiz

<!-- > "Quantitative estimation of the number of viable microorganisms in -->
<!-- bacteriological samples has been a mainstay of the microbiological laboratory -->
<!-- for more than one-hundred years, since Koch first described the technique (Koch, -->
<!-- 1883). Serial dilution techniques are routinely used in hospitals, public -->
<!-- health, virology, immunology, microbiology, pharmaceutical industry, and food -->
<!-- protection (American Public Health Association, 2005, Hollinger, 1993, Taswell, -->
<!-- 1984, Lin and Stephenson, 1998) for microorganisms that can grow on -->
<!-- bacteriological media and develop into colonies." [@ben2014estimation] -->

<!-- > "The objective of the serial dilution method is to estimate the concentration -->
<!-- (number of colonies, organisms, bacteria, or viruses) of an unknown sample by -->
<!-- counting the number of colonies cultured from serial dilutions of the sample, -->
<!-- and then back track the measured counts to the unknown concentration." -->
<!-- [@ben2014estimation] -->

<!-- > "The most widely used method for determining drug efficacy [for TB] in mice  -->
<!-- remains enumeration of the bacterial load in lungs and spleens, by counting -->
<!-- the colony forming units (CFU) of the organ homogenates on agar plates." -->
<!-- [@franzblau2012comprehensive] -->

<!-- > "Quantitative estimation of the number of viable microorganisms in -->
<!-- bacteriological samples has been a mainstay of the microbiological laboratory -->
<!-- for more than one-hundred years, since Koch first described the technique (Koch, -->
<!-- 1883). Serial dilution techniques are routinely used in hospitals, public -->
<!-- health, virology, immunology, microbiology, pharmaceutical industry, and food -->
<!-- protection (American Public Health Association, 2005, Hollinger, 1993, Taswell, -->
<!-- 1984, Lin and Stephenson, 1998) for microorganisms that can grow on -->
<!-- bacteriological media and develop into colonies." [@ben2014estimation] -->

<!-- > "The objective of the serial dilution method is to estimate the concentration -->
<!-- (number of colonies, organisms, bacteria, or viruses) of an unknown sample by -->
<!-- counting the number of colonies cultured from serial dilutions of the sample, -->
<!-- and then back track the measured counts to the unknown concentration." -->
<!-- [@ben2014estimation] -->

<!-- > "The indirect or viable count has, as a rule, been performed by a  -->
<!-- modification of Koch's original plating method. ... The modifications of  -->
<!-- Koch's method have been concerned with the medium used, the question of  -->
<!-- preliminary dilution, the methods of dilution and the exact technique of  -->
<!-- counting the plates. The majority of observers appear to have used agar,  -->
<!-- but [a few] seem to have preferred gelatin, though in some cases both  -->
<!-- media were employed. With regard to preliminary dilution, the earlier -->
<!-- workers generally preferred to plate out the original emulsion, while -->
<!-- of late the tendency has been in the opposite direction ... . The  -->
<!-- method of dilution has been subject to considerable variation; on the  -->
<!-- whole volumetric pipettes have been the most popular, but [some]  -->
<!-- used dropping pipettes, while [others] resorted ot the use of a standard -->
<!-- platinum loop. ... The important question of the counting of the plates -->
<!-- has naturally depended largely on whether or no a preliminary dilution  -->
<!-- of the emulsion was made. Where the number of colonies was very great,  -->
<!-- microscopic counting was adopted ... . Where on the contrary, dilution was -->
<!-- employed, the use of the microscope was no longer necessary, and counting  -->
<!-- was performed with the naked eye or with a magnifying glass ..."  -->
<!-- [@wilson1922proportion] -->

<!-- > "In perusing the results of previous workers, it was striking to  -->
<!-- observe the peculiar lack of attention which was paid to the estimation -->
<!-- of the experimental error involved in the methods employed. Probably this  -->
<!-- is to be attributed to the fact that in many cases in which the enumeration -->
<!-- of bacteria was undertaken, a relative, rather than an absolute accuracy -->
<!-- was essential. It was felt that the successful accomplishment of this -->
<!-- object could only be obtained by working out a technique in which the  -->
<!-- errors inherent in every step should be known with certainty."  -->
<!-- [@wilson1922proportion] -->

<!-- > "The plate count method for estimating bacterial populations is  -->
<!-- satisfactory for many comparative purposes if *relative* rather than  -->
<!-- *absolute* numbers of cells are wanted, although in some cases, because -->
<!-- of clumping, plate counts may not bear a constant relation to total  -->
<!-- counts even during the logarithmic growth phase (Jennison, 1937).  -->
<!-- This lack of agreement may be overcome, at least with some organisms,  -->
<!-- by proper shaking to break up clumps of cells (Ziegler and Halvorson,  -->
<!-- 1935)." [@jennison1940evaluation] -->

<!-- > "Generally speaking, the methods which have been employed may be classified -->
<!-- into (1) the direct and (2) the indirect. In the former the organisms are -->
<!-- counted directly under the microscope, in the latter the number of bacteria -->
<!-- present is calculated from an enumeration of the colonies which develop when  -->
<!-- an aliquot part of the emulsion in question is mixed with a nutrient medium -->
<!-- in a Petri dish, and incubated for a variable period of time. The former  -->
<!-- is designed to record the total number of organisms present, the latter only -->
<!-- the number which happens to be viable at the moment of sampling."  -->
<!-- [@wilson1922proportion] -->

<!-- > "Mtb is a member of the slow-growing pathogenic mycobacterial species, -->
<!-- characterized by a 12- to 24-hour division rate and prolonged culture period on -->
<!-- agar of up to 21 days. Why Mtb grows so slowly is not well understood. Proposed -->
<!-- mechanisms include limitation of nutrient uptake through the highly impermeable -->
<!-- cell wall and slow rates of RNA synthesis (96). During experimental infections, -->
<!-- its metabolism can shift from an aerobic, carbohydrate-metabolizing mode to one -->
<!-- that is microaerophilic and lipid metabolizing (25). Mycobacteria are -->
<!-- facultative intracellular bacteria that multiply within phagocytic cells, -->
<!-- particularly macrophages and monocytes. Although many mycobacterial species are -->
<!-- environmental, Mtb is strictly parasitic." [@sakamoto2012pathology] -->

<!-- > "For the testing of single compounds as well as short term mouse experiments,  -->
<!-- some investigators mentioned plating whole lungs while others plate the  -->
<!-- homogenate of a single lung lobe from each animal. After long treatment  -->
<!-- regimens when low bacterial numbers are expected, generally the whole lung is -->
<!-- homogenized and a sizeable fraction of up to one-half of the homogenate is plated.  -->
<!-- One group homogenizes whole lungs in a total of 2.5 mL PBS and then plates -->
<!-- the entire homogenate on five 7H11 plates (0.5 mL per plate). Another group -->
<!-- uses whole lungs and total spleen homogenized in 4 mL PBS supplemented with  -->
<!-- 0.05% Triton X-100." [@franzblau2012comprehensive] -->

<!-- > "Several issues regarding the endpoints and the mouse models themselves -->
<!-- were discussed. Regarding accurate endpoints in treatment trials, the  -->
<!-- method used for enumerating bacteria from organ homogenates should be  -->
<!-- carefully (re)considered given the possibility that some non-culturable  -->
<!-- bacteria in samples of animal tissues may not form colonies on solid agar.  -->
<!-- Liquid media, such as BACTEC or MGIT, was suggested as a method to enhance -->
<!-- sensitivity for finding low numbers of CFU and to gain some insight into  -->
<!-- the state of the bacillus at the time point examined. Liquid testing using  -->
<!-- the MGIT system is also now the method of choice for sputum evaluation to assess  -->
<!-- culture conversion for clinical trials. Several automated liquid culture -->
<!-- systems have shown greater sensitivity than the traditional solid-media -->
<!-- cultures the acknowledged increased in the mycobacterial recovery rate of  -->
<!-- liquid media, which is likely due to a more mycobacterial populations  -->
<!-- being able to recover in liquid culture than on solid media. This is -->
<!-- supported by in vivo and in vitro observations that subpopulations of  -->
<!-- M. tuberculosis with different states of metabolic activity co-exist in  -->
<!-- old liquid cultures, as well as in liquid cultures with bacterial growth  -->
<!-- from chronic infected mice that do not grow on solid media." -->
<!-- [@franzblau2012comprehensive] -->

<!-- > "Another topic of discussion in at least two laboratories was the issue -->
<!-- of drug carry-over at the time of enumeration of bacterial colonies  -->
<!-- in the organs. CLF and TMC-207 both have long half-lives, high tissue -->
<!-- distribution and tissue binding, and therefore drug might still be present -->
<!-- at the time of sacrificing the animals. The first indication that  -->
<!-- drug carry-over is an issue is observed when dilutions of organ  -->
<!-- homogenates do not have the expected reduction in bacterial number.  -->
<!-- Another indication might also be the lack of correlation between the bacterial -->
<!-- number and the gross pathology observation. Several methods have been described -->
<!-- to reduce the carry-over of drug in agar plates, including using LJ medium -->
<!-- or 7H11 with 5% bovine serum albumin (BSA) for TMC-207, and using 0.4% -->
<!-- activated charcoal for CLF. Relapse studies will then show the true -->
<!-- sterilizing potential of these drugs and drug combinations." [@franzblau2012comprehensive] -->

<!-- > "It was pointed out that colony forming units (CFU) measures by plating -->
<!-- organ homogenates on solid agar are often inaccurate since they do not -->
<!-- necessarity include just single bacilli but rather small clumps or -->
<!-- conglomerations. There was discussion around the hypothesis that these -->
<!-- clusters represent a type of biofilm. Hatfull et al. found these -->
<!-- M. tuberculosis biofilms in vitro to consist of bacteria surrounded by  -->
<!-- a layer of free mycolic acids. Although the biofilm hypothesis was not -->
<!-- accepted by everyone, it was agreed that the extracellular bacteria in these -->
<!-- micro-environments are unique and should be treated by drug treatment.  -->
<!-- Another topic of discussion was about the drug refractory nature of these -->
<!-- persisting bacilli being a drug penetration issue, by drugs not getting through -->
<!-- this fibrous rim and extracellular lipid matrix. The ability to determine -->
<!-- the penetration of TB drugs into a granuloma was seen as an important -->
<!-- gap in the current knowledge about TB drugs." [@franzblau2012comprehensive] -->

<!-- > "The activity of an investigational drug or regimen has been in recent years -->
<!-- mostly determined by the reduction of colony forming units (CFU) of M. -->
<!-- tuberculosis by dilution of organ homogenates on solid agar 7H11 plates. Plating -->
<!-- of the organ homogenates has always been the gold standard for quantifying drug -->
<!-- efficacy in vivo. However, drug discovery efforts are often times held up by -->
<!-- this time consuming step requiring an incubation period of the bacterial plates -->
<!-- of 3--4 weeks. For early drug discovery efforts, more efforts are being -->
<!-- investigated lately for indirect, but more rapid, methods to 'measure' the -->
<!-- bacterial load: such as the luciferase readout or fluorescence. These novel -->
<!-- detection methods will undoubtedly accelerate the TB drug discovery process by -->
<!-- delivering an immediate readout on the efficacy of an experimental compound at -->
<!-- either time of sacrifice (for luciferase readout) and even in live animals in -->
<!-- real time (fluorescence). Thorough validation, however, is not available as of -->
<!-- yet and would be required before these indirect methods can replace the -->
<!-- enumeration by CFU for all drug classes." [@franzblau2012comprehensive] -->

<!-- > "Another discussion took place at several occasions during this project, -->
<!-- pointing out that perhaps not all bacteria can be identified, cultured or -->
<!-- visualized by current methods. The discussion started with the recent -->
<!-- introduction of liquid culture media for the diagnostic evaluation of clinical -->
<!-- specimens for suspected tuberculosis. The question then became whether drugs or -->
<!-- regimens which preferentially kill certain bacillary populations would give rise -->
<!-- to a 'flawed' readout by only culturing certain subsets of bacteria on solid -->
<!-- agar. If liquid cultures of organ homogenates allow the growth of TB -->
<!-- subpopulations that will not grow on solid media, the parallel evaluation in -->
<!-- liquid and in solid cultures might offer an opportunity to study drug effects on -->
<!-- subpopulations in different metabolic states. ... This question might even be -->
<!-- more relevant in animal models with a greater variety in granulomatous lesion -->
<!-- types where bacilli are located in different environments (such as in necrotic, -->
<!-- closed or cavitary lesions) and hence might have different metabolic stages." -->
<!-- [@franzblau2012comprehensive] -->

<!-- > "The importance of serial dilution and colony counting is reflected by the -->
<!-- number of standard operating procedures and regulatory guidelines describing -->
<!-- this methodology. In all of these guidelines the optimal number ($\hat{n_j}$) of -->
<!-- colonies to be counted has been reported (Park and Williams, 1905, Wilson, 1922, -->
<!-- Jennison and Wadsworth, 1940, Tomasiewicz et al., 1980, FDA, 2001, Goldman and -->
<!-- Green, 2008) as 40--400, 200--400, 100--400, 25--250, 30--300. It is interesting -->
<!-- to note that these references do not specify the area in which the colonies -->
<!-- grow, nor the diameter of the particular organism assayed. The result is that -->
<!-- titration and counting colonies is done within a range that may be inadequate, -->
<!-- and may introduce considerable error." [@ben2014estimation] -->

<!-- > "The plate count method is based on viable cell counts. The plate count  -->
<!-- method is performed by diluting the original sample in serial dilution  -->
<!-- tubes, followed by the plating of aliquots of the prepared serial dilutions -->
<!-- into appropriate plate count agar plates by the pour plate or spread  -->
<!-- plate technique. The pour plate technique utilizes tempered molton plate -->
<!-- count agar poured into the respective plate and mixed with the diluted -->
<!-- aliquot sample in the plate, whereas the spread plate technique utilizes -->
<!-- the addition and spreading of the diluted aliquot sample on the surface -->
<!-- of the preformed solid plate count agar in the respective plant. ... -->
<!-- These prepared plate count agar plates are then optimally incubated, and the -->
<!-- colonies observed on these plate count agar plates are then counted as  -->
<!-- the number of CFUs. The counting of CFUs assumes that every colony is  -->
<!-- separate and founded by a single viable microbial cell. The total  -->
<!-- colony counts obtained in CFUs from the incubated agar plates and the  -->
<!-- respective dilution factor used can then be combined to calculate the  -->
<!-- original number of microorganisms in the sample in CFUs per mL. The typical  -->
<!-- counting ranges are 20--250 CFUs or 30--300 CFUs per standard plate count -->
<!-- agar plate. Additional considerations for counting CFUs are counting of  -->
<!-- plate spreaders, too numerous to count (TNTC) reporting and statistics,  -->
<!-- rounding and averaging of observed plate counts, limit of detection, and  -->
<!-- limit of quantification of plate countes (77--79). There are also  -->
<!-- optimal condition assumptions for the plate count method as changes to the  -->
<!-- plate count agar nutrient level or temperature can affect the surface growth of  -->
<!-- bacteria (80, 81). Primary equipment and materials used for this method  -->
<!-- are serial dilution tubes (bottles); Petri plates or dishes; pipettes;  -->
<!-- specific growth medium, diluents, and reagents; incubator and water bath -->
<!-- with appropriate optimal temperature setting; commercial colony counter -->
<!-- (manual or automate); and plate spreader or rod. Total bacteria and fungi -->
<!-- can be enumerated separately using the plate count method based on the  -->
<!-- type of culture medium utilized (82--86). Specific or selective culture -->
<!-- medium can also be used in place of the standard plate count agar media -->
<!-- for more specific microbial enumeration (87). Sources of error using this  -->
<!-- method are improper or inadequate preparation of the test samples,  -->
<!-- serial dilution error, suboptimal incubation conditions, undercounting -->
<!-- due to cell aggregation or clumping, and analyst error in the colony -->
<!-- counting or calculation of observed results." [@goldman2015practical] -->

<!-- > "Almost every textbook, laboratory manual and methods volume in  -->
<!-- microbiology contains the statement that plates for counting bacteria should -->
<!-- contain, when possible 30--300 colonies. The '30--300' concept has been  -->
<!-- so ingrained in our thinking that the limits are rarely questioned. ... -->
<!-- The '30--300' concept originated with two publications by Breed and  -->
<!-- Dotterrer (7,8); the text and tables presented in both publications are  -->
<!-- identical. The authors summarized results of a few early studies and  -->
<!-- then proceeded to more clearly define the problem and provide a solution." -->
<!-- [@tomasiewicz1980most] -->

<!-- > "Considering the plating method per se, the total error of the mean plate -->
<!-- count of a given dilution of cells is chiefly made up of two rather  -->
<!-- distinct sources of deviations: (a) the distribution or sampling error,  -->
<!-- sometimes inaccurately called the counting error, (i.e., variation in  -->
<!-- number of colonies, due to sampling, between replicate plates of the  -->
<!-- given dilution), and (b), the dilution error, (i.e., the errors of  -->
<!-- pipetting involved in reaching the given dilution). ... It is customary  -->
<!-- to measure the reliability of the plate count by calculating only the -->
<!-- distribution error, and assuming that the dilution error is small, constant,  -->
<!-- and unimportant. We shall show, however, that at best this dilution error  -->
<!-- is of about the same order of magnitude as the distribution error, and  -->
<!-- is, therefore, equally deserving of consideration in arriving at the total -->
<!-- error of plate counts. Furthermore, the dilution error increases with higher -->
<!-- dilutions, whereas the distribution error does not. Obviously, one must take into -->
<!-- account both sources of variation in evaluating the total error, as, for example, -->
<!-- in a problem involving significance of differences, in which the same -->
<!-- dilution might be employed." [@jennison1940evaluation] -->

<!-- > "Traditionally, quantification of mycobacteria is done by seeding serial -->
<!-- dilutions of bacterial suspensions on suitable media such as Middlebrook 7H10 -->
<!-- agar or Lowenstein Jensen followed by counting colony-forming units (CFU). -->
<!-- However, this method is hampered by the long generation time and the tendency of -->
<!-- mycobacteria to aggregate, resulting in multiple founders of a single colony and -->
<!-- an underestimation of the correct number of bacteria. Typically, the time -->
<!-- required for visible colonies to appear on 7H10 agar is 2--3 weeks for M. -->
<!-- tuberculosis and M. a. avium, while it takes about 4--8 weeks for M. a. -->
<!-- paratuberculosis. In addition, plating enough dilutions to make sure the results -->
<!-- can be reliably counted is a tedious task that gives piles of plates with -->
<!-- biohazardous bacteria. A further disadvantage of the colony counting method is -->
<!-- that it cannot be reliably conducted on frozen samples, which may be both more -->
<!-- practical and desirable in several research settings." [@pathak2012counting] -->

<!-- > "It is clear that if three tubes are put up from an emulsion containing a -->
<!-- comparatively small number of bacilli, the chances of obtaining a representative -->
<!-- sample must be smaller than if an emulsion be employed which contains a much -->
<!-- larger number of bacilli. Similarly with the tubes themselves. If only a few -->
<!-- bacilli are introduced, the chances of obtaining a correct idea of the exact -->
<!-- number are smaller than if a large number of bacilli are introduced. Thus the -->
<!-- greater the number of colonies per tube, the less is the error of sampling. That -->
<!-- this is not a mere theoretical consideration is shown from an examination of the -->
<!-- data accumulated during the progress of this work... the percentage deviation of -->
<!-- each individual tube from the arithmetic mean was considerably greater in the -->
<!-- case when a small number of colonies developed than in the case when a large -->
<!-- number of bacilli were inoculated. In other words the sampling error in the -->
<!-- former instance was large, in the latter comparatively small." -->
<!-- [@ben2014estimation] -->

<!-- > "We now come to consider the second factor determining the optimum number -->
<!-- of bacilli to be inoculated in putting up viable counts by the tube method,  -->
<!-- namely the error of overcrowding. More or less in proporation as the error  -->
<!-- of sampling decreases as the number of developing colonies increases, so the -->
<!-- error of overcrowding increases as the number of developing colonies increases. -->
<!-- The two vary in opposite directions; the greater the number of colonies the  -->
<!-- less the sampling error; the fewer the number of colonies, the less is the  -->
<!-- overcrowding error. A point must be chosen between the two which will permit -->
<!-- of the minimum combined error experienced. Before this could be done, however,  -->
<!-- it was necessary to ascertain the actual effect of overcrowding on the  -->
<!-- development of colonies in tube preparations. As mentioned above, this  -->
<!-- overcrowding error is one which seems to have been neglected by the  -->
<!-- majority of observers, or at any rate, not clearly recognized. It is obvious -->
<!-- that the greater the number of bacilli distributed in a given space, the less -->
<!-- is the interval between each of them, and the greater the chance of two  -->
<!-- being coincident. In every case in which two bacilli are coincident or are -->
<!-- placed very close together only one colony will develop. Further, when two  -->
<!-- bacilli are situated at such a distance from each other that each is able  -->
<!-- to develop, yet at such a distance that continued development of both  -->
<!-- will result in fusion, it is clear that a simple colony must arise. Whether -->
<!-- one continues to grow and the other desists or whether both develop, the  -->
<!-- result is the same---namely, the appearance of one colony in place of two  -->
<!-- bacilli. On pure a priori grounds one would expect this overcrowding factor  -->
<!-- to be of considerable importance in determining the number of colonies which -->
<!-- will develop in a given space. One would expect it to play but a small part -->
<!-- so long as comparatively few bacilli were inoculated, but as the number -->
<!-- of the latter increased so should the percentage which fails to develop into -->
<!-- colonies become greater." [@ben2014estimation] -->

<!-- > "So far as evaluating the distribution error is concerned, this is usually -->
<!-- done by calculating the standard deviation of the mean (standard error)  -->
<!-- of the replicate plates, assuming that the variation between such plates  -->
<!-- is that of random samples. Under good experimental conditions, this  -->
<!-- coefficient of variation will average $\pm$ 4--5 per cent (Jennison, 1937). -->
<!-- In order to test whether observed variations between replicate plates  -->
<!-- are due to chance or to technique, the $\chi^2$ ('chi square') test may  -->
<!-- be used (Wilson and Kullmann, 1931). The calculated value of $\chi^2$ will  -->
<!-- be distributed in a known manner if the replicate samples are from a  -->
<!-- Poisson series, that is, if their variation is that of random samples from  -->
<!-- the same population. Fisher, Thornton, and MacKenize (1922), and Fisher (1938), -->
<!-- have shown that a Poisson distribution is obtained in parallel plate counts -->
<!-- made under standardized experimental conditions. Both the $\chi^2$ test -->
<!-- and colculation of the standard error of replicate plates apply only to  -->
<!-- a given dilution; they do not account for errors involved in arriving at that -->
<!-- dilution." [@jennison1940evaluation] -->

<!-- > "Plates with over 500 colonies under-estimate the true count owing to the -->
<!-- overcrowding error. With careful workers the actual error of counting probably -->
<!-- does not become appreciable till there are about 300 colonies per plate, and for -->
<!-- some distance above this limit it will probably be counterbalanced by the -->
<!-- diminished sampling error. If many places, however, have to be counted, the -->
<!-- fatigue error, which seems to be mainly responsible for the failure of the -->
<!-- sampling error to decrease with increasing numbers of colonies in accordance -->
<!-- with theoretical expectations, becomes appreciable." -->
<!-- [@wilson1935bacteriological] -->

<!-- > "For automated equipment (10), the optiumum counting range may well vary with  -->
<!-- the instrument, particle (colony) size limits, range of colony sizes, etc. -->
<!-- Furthermore, even if automation is not used, appropriate numbers of colonies -->
<!-- that should be on a countable plate can vary widely, depending on many other -->
<!-- variables. With soil fungi, for example, maxima of from 25-100 colonies per  -->
<!-- plate have been suggested (17). Coliform analyses demand another range (24)." -->
<!-- [@tomasiewicz1980most] -->

<!-- > "Given an unknown sample which contains $n_0$ colony forming units (CFUs), a -->
<!-- series of $J$ dilutions are made sequentially each with a dilution factor -->
<!-- $\alpha$. From each of the J dilutions a fraction $\alpha_p^{-1}$ is taken and -->
<!-- spread (plated) on an agar plate (assay) where colonies are counted. Thus, in -->
<!-- general there are two dilution factors: $\alpha$ and $\alpha_p$. For example, -->
<!-- $\alpha = 10$ indicates a 10-fold dilution, e.g., by diluting successively 0.1 -->
<!-- ml of sample into 0.9 ml of media; and $\alpha_p = 1$ means that the entire -->
<!-- volume is spread (plated) on the agar plate. For an experiment with a larger -->
<!-- dilution factor $\alpha_p$, multiple plates may be spread at the same dilution -->
<!-- stage. For example, $\alpha_p = 20$ represent a 5% plating of the dilution, and -->
<!-- thus up to 20 replicates could be created. At each dilution the true number of -->
<!-- colonies is $n_j = n_0 \alpha^{-j} \alpha_p^{-1}$ and the estimated number is -->
<!-- $\hat{n_j}$. The estimated quantities are denoted with a 'hat' (estimated -->
<!-- quantities can be measured quantities, or quantities that are derived from -->
<!-- measured or sampled quantities); symbols without a 'hat' denote true quantities -->
<!-- (also known as population values in statistics) that do not contain any sampling -->
<!-- or measurement error. In this work both $n_j$ and $n_0$ are 'counts', i.e., -->
<!-- number of colonies. Knowing the aliquot volume, one can easily convert counts to -->
<!-- concentration (for example CFU/ml)." [@ben2014estimation] -->

<!-- > "All respondents [from labs working on tuberculosis] use statistical  -->
<!-- methods in conjunction with their animal trials and most do not consult with -->
<!-- a statistician. Treatment effects are mostly analyzed by a one-way ANOVA,  -->
<!-- followed by a T-test, Tukey or Dunnett's test. For relapse studies a  -->
<!-- Fisher Exact or Chi-square test is applied to compare relapse proportions -->
<!-- between groups." [@franzblau2012comprehensive] -->

<!-- > "Statistical methods are of key importance and different methods are used -->
<!-- depending on the question asked. Methods used were found to be very similar -->
<!-- across laboratories, and often assistance of a statistician was provided to  -->
<!-- answer new questions. Power analysis prior to the experiments is required -->
<!-- to determine the number of animals used in the experiment. The primary data -->
<!-- analysis for mouse models is usually a one-way analysis of variance (ANOVA) -->
<!-- of the log-10 CF bacterial loads, with t-distribution based contrasts  -->
<!-- comparing individual treatments. A Dunnett's test is an appropriate method -->
<!-- for comparing all new compounds to untreated controls, while controlling the -->
<!-- overall error rate in that set of ccomparisons is set at the usual 0.05 -->
<!-- level. Also Bonferroni and Tukey statistical tests are appropriate tests for -->
<!-- a pairwise comparison between treatment groups. Evidence of differential  -->
<!-- relapse based on detection (yes/no) of TB bacteria would be established using -->
<!-- a Fisher's exact test comparing rates of relapse between two experimental -->
<!-- groups. In experiments with n = 5--10 per group, power to identify  -->
<!-- significantly different relapse rates is very low. Therefore in order to  -->
<!-- increase the statistical power, more treatment groups are implemented -->
<!-- with various lengths of treatment, or a higher relapse rate is aimed -->
<!-- for in order to see significant differences between different treatment  -->
<!-- regimens. Relapse information obtained from mouse models should always be -->
<!-- interpreted with great care and seen as trends in relapse differences between -->
<!-- treatments." [@franzblau2012comprehensive] -->


# References
