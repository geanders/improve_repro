## Example: Creating a reproducible data pre-processing protocol

We will walk through an example of creating a reproducible protocol for the
automated gating of flow cytometry data for a project on the immunology of
tuberculosis lead by one of our Co-Is. This data pre-processing protocol was
created using RMarkdown and allows the efficient, transparent, and reproducible
gating of flow cytometry data for all experiments in the research group. We will
walk the trainees through how we developed the protocol initially, the final
pre-processing protocol, how we apply this protocol to new experimental data.

**Objectives.** After this module, the trainee will be able to:

- Explain how a reproducible data pre-processing protocol can be integrated into
a real research project
- Understand how to design and implement a data pre-processing protocol to
replace manual or point-and-click data pre-processing tools

### Subsection 1

In this module, we'll provide advicen and an example of how you can use the 
tools for knitted documents to create a reproducible data preprocessing 
protocol. This module builds on ideas and techniques that were introduced 
in the last two modules, to help you put them into practical use for 
data preprocessing that you do repeatedly for research data in your 
laboratory.

### Advice on designing a pre-processing protocol

Before you write your protocol in a knitted document, you should decide on 
the content to include in the protocol. 

[More on laboratory protocols?]

The first thing to decide on are what the starting point will be for the
protocol (the data input) and what will be the ending point (the data output).
It may make sense to design a separate protocol for each major type of 
data that you collect in your research laboratory. Your input data for the
protocol, under this design, might be the data that is output from a 
specific type of equipment (e.g., flow cytometer) or from a certain 
type of sample or measurement (e.g., metabolomics run on a mass spectrometer), 
even if it is a fairly simple type of data (e.g., CFUs from plating data).
For the data output, it often makes sense to plan for data in a format 
that is appropriate for data analysis and for merging with other types of
data collected from the experiment.

For example, say you are working with data from a flow cytometer, metabolomics
data measuremd with a mass spectrometer, and bacterial load data measured by 
plating data and counting colony forming units (CFUs). In this case, you may 
want to create three pre-processing protocols: one for the flow data, one for 
the metabolomics data, and one for the CFU data. 

The pre-processing protocol may be very simple for the CFU data. This protocol
would input data collected in a plain-text delimited file (a csv file, for
example). Within the protocol, there would be steps to convert initial
measurements from plating at different dilutions into estimates of the bacterial
load in each original sample. There may also be sections in the protocol for
exploratory data analysis, to allow for quality assessment and control of the
collected data as part of the preprocessing. The output would be a simple data
object (a dataframe, for example) with the bacterial load for each sample. This
data could then be used in tables and figures in the research report or
manuscript, as well as merged with other data from each experimental animal to
explore associations with the experimental design details (e.g., comparing
bacterial load in treated versus untreated animals) or with other types of data
(e.g., comparing immune cell populations, as measured with flow cytometry data,
with bacterial loads, as measured from plating and counting CFUs).

The preprocessing protocols would be more extensive for the flow cytometry and 
metabolomics data. For example, the flow cytometry data might need to be 
preprocessed through a number of steps. First, the raw data from the flow 
cytometer will need to be input to R. [Common file format for flow data? R 
packages to read in this data?]. Once the data is input, it will need to be
gated, to [identify and count the immune cell populations that you're interested
in?]. [Tools for automated gating in R.] [Other pre-processing steps? 
Normalizations? Transformations? Others?]

For the metabolomics data, there will similarly be an extensive set of steps to 
preprocess the data, to convert it from the format output by the laboratory 
equipment into a format that can be used for data analysis and to merge with 
other types of data from the experiment. [More on pre-processing steps for 
metabolomics data.]


[Splitting pre-processing into "modules" of processes that need to happen---for
example, standardizing across samples, transforming data to satisfy distribution
requirements for statistical models / tests, removing extraneous data (dead
cells in flow cytometry, for example), ...]

[For each module, consider the options you could take in pre-processing. For
open-source software, like Bioconductor packages, these options are likely
embedded either in your choice of functions (across a package), or even choice
of packages in some cases, and then at a finer level through the parameters in a
package. You can use vigettes and package manuals to identify the different
functions you can choose and then use the helpfile for a function to determine
all of its parameters and the choices you can select for each. In the protocol,
show the code that you use to implement this choice and also explain clearly in
the text why you made this choice and what alternatives should be considered if
data characteristics are different. Write this as if you are explaining to a new
research group member (or your future self) how to think about this step in the
pre-processing, why you're doing it the way your doing it, and what code is used
to do it that way. You should also include references that justify choices when
they are available---include these using BibTex. By doing this, you will make it
much easier on yourself when you write the Methods section of papers that report
on the data you have pre-processed, as you'll already have draft information on
your pre-processing methods in your protocol.]

[Throughout, use an example dataset, preferably from your own research lab. You
likely want to select one for project that you have already published or are
getting ready to publish, so you won't feel awkard about making the data
available for people to practice with. You can include the data and the
RMarkdown in its own RStudio Project and post this either publicly or privately
on GitHub. This creates a "packet" of everything that a reader needs to use to
recreate what you did---they can download the whole GitHub repository and will
have a nice project directory on their computer with everything they need to try
out the protocol. If you don't have an example dataset from your own laboratory,
you can explore example datasets that are already available, either as data
included with existing R packages or through open repositories, included those
hosted through national research institutions like the NIH. In this case, be
sure to cite the source of the data and include any available information about
the equipment that was used to collect it and the settings used when the data
were collected.]

### Subsection 2

### Practice quiz

# References
