<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="3.1 Principles and benefits of scripted pre-processing of experimental data | Improving the Reproducibility of Experimental Data Recording and Pre-Processing" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing." />
<meta name="github-repo" content="rstudio/bookdown-demo" />

<meta name="author" content="Brooke Anderson, Michael Lyons, Mercedes Gonzalez-Juarrero, Marcela Henao-Tamayo, and Gregory Robertson" />



<meta name="description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing.">

<title>3.1 Principles and benefits of scripted pre-processing of experimental data | Improving the Reproducibility of Experimental Data Recording and Pre-Processing</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>




<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#overview"><span class="toc-section-number">1</span> Overview</a><ul>
<li><a href="1-1-license.html#license"><span class="toc-section-number">1.1</span> License</a></li>
</ul></li>
<li class="has-sub"><a href="2-experimental-data-recording.html#experimental-data-recording"><span class="toc-section-number">2</span> Experimental Data Recording</a><ul>
<li class="has-sub"><a href="2-1-separating-data-recording-and-analysis.html#separating-data-recording-and-analysis"><span class="toc-section-number">2.1</span> Separating data recording and analysis</a><ul>
<li><a href="2-1-separating-data-recording-and-analysis.html#data-recording-versus-data-analysis"><span class="toc-section-number">2.1.1</span> Data recording versus data analysis</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#hazards-of-combining-recording-and-analysis"><span class="toc-section-number">2.1.2</span> Hazards of combining recording and analysis</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#approaches-to-separate-recording-and-analysis"><span class="toc-section-number">2.1.3</span> Approaches to separate recording and analysis</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#discussion-questions"><span class="toc-section-number">2.1.4</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="2-2-principles-and-power-of-structured-data-formats.html#principles-and-power-of-structured-data-formats"><span class="toc-section-number">2.2</span> Principles and power of structured data formats</a><ul>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#data-recording-standards"><span class="toc-section-number">2.2.1</span> Data recording standards</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#defining-data-standards-for-a-research-group"><span class="toc-section-number">2.2.2</span> Defining data standards for a research group</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#two-dimensional-structured-data-format"><span class="toc-section-number">2.2.3</span> Two-dimensional structured data format</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#saving-two-dimensional-structured-data-in-plain-text-file-formats"><span class="toc-section-number">2.2.4</span> Saving two-dimensional structured data in plain text file formats</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#occassions-for-more-complex-data-structures-and-file-formats"><span class="toc-section-number">2.2.5</span> Occassions for more complex data structures and file formats</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#levels-of-standardizationresearch-group-to-research-community"><span class="toc-section-number">2.2.6</span> Levels of standardization—research group to research community</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#applied-exercise"><span class="toc-section-number">2.2.7</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="2-3-the-tidy-data-format.html#the-tidy-data-format"><span class="toc-section-number">2.3</span> The ‘tidy’ data format</a><ul>
<li><a href="2-3-the-tidy-data-format.html#what-makes-data-tidy"><span class="toc-section-number">2.3.1</span> What makes data “tidy”?</a></li>
<li><a href="2-3-the-tidy-data-format.html#why-make-your-data-tidy"><span class="toc-section-number">2.3.2</span> Why make your data “tidy”?</a></li>
<li><a href="2-3-the-tidy-data-format.html#using-tidyverse-tools-with-data-in-the-tidy-data-format"><span class="toc-section-number">2.3.3</span> Using tidyverse tools with data in the “tidy data” format</a></li>
<li><a href="2-3-the-tidy-data-format.html#practice-quiz"><span class="toc-section-number">2.3.4</span> Practice quiz</a></li>
</ul></li>
<li class="has-sub"><a href="2-4-designing-templates-for-tidy-data-collection.html#designing-templates-for-tidy-data-collection"><span class="toc-section-number">2.4</span> Designing templates for “tidy” data collection</a><ul>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#creating-the-rules-for-collecting-data-in-the-same-time-each-time"><span class="toc-section-number">2.4.1</span> Creating the rules for collecting data in the same time each time</a></li>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">2.4.2</span> Subsection 1</a></li>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#dont-repeat-yourself"><span class="toc-section-number">2.4.3</span> Don’t Repeat Yourself!</a></li>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#dont-repeat-your-report-writing"><span class="toc-section-number">2.4.4</span> Don’t repeat your report-writing!</a></li>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#automating-reports"><span class="toc-section-number">2.4.5</span> Automating reports</a></li>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#scripts-and-automated-reports-as-simple-pipelines"><span class="toc-section-number">2.4.6</span> Scripts and automated reports as simple pipelines</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#applied-exercise"><span class="toc-section-number">2.4.7</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#example-creating-a-template-for-tidy-data-collection"><span class="toc-section-number">2.5</span> Example: Creating a template for “tidy” data collection</a><ul>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">2.5.1</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">2.5.2</span> Subsection 2</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#example-datasets"><span class="toc-section-number">2.5.3</span> Example datasets</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#issues-with-these-data-sets"><span class="toc-section-number">2.5.4</span> Issues with these data sets</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#final-tidy-examples"><span class="toc-section-number">2.5.5</span> Final “tidy” examples</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#options-for-recording-tidy-data"><span class="toc-section-number">2.5.6</span> Options for recording tidy data</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#examples-of-how-tidy-data-can-be-easily-analyzed-visualized"><span class="toc-section-number">2.5.7</span> Examples of how “tidy” data can be easily analyzed / visualized</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#discussion-questions"><span class="toc-section-number">2.5.8</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="2-6-power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files.html#power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files"><span class="toc-section-number">2.6</span> Power of using a single structured ‘Project’ directory for storing and tracking research project files</a><ul>
<li><a href="2-6-power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files.html#organizing-project-files-through-the-file-system"><span class="toc-section-number">2.6.1</span> Organizing project files through the file system</a></li>
<li><a href="2-6-power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files.html#organizing-files-within-a-project-directory"><span class="toc-section-number">2.6.2</span> Organizing files within a project directory</a></li>
<li><a href="2-6-power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files.html#using-rstudio-projects-with-project-file-directories"><span class="toc-section-number">2.6.3</span> Using RStudio Projects with project file directories</a></li>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">2.6.4</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">2.6.5</span> Subsection 2</a></li>
<li><a href="2-3-the-tidy-data-format.html#practice-quiz"><span class="toc-section-number">2.6.6</span> Practice quiz</a></li>
</ul></li>
<li class="has-sub"><a href="2-7-creating-project-templates.html#creating-project-templates"><span class="toc-section-number">2.7</span> Creating ‘Project’ templates</a><ul>
<li><a href="2-7-creating-project-templates.html#making-an-existing-file-directory-an-rstudio-project"><span class="toc-section-number">2.7.1</span> Making an existing file directory an RStudio Project</a></li>
<li><a href="2-7-creating-project-templates.html#making-an-rstudio-project-template"><span class="toc-section-number">2.7.2</span> Making an RStudio Project Template</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#discussion-questions"><span class="toc-section-number">2.7.3</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="2-8-example-creating-a-project-template.html#example-creating-a-project-template"><span class="toc-section-number">2.8</span> Example: Creating a ‘Project’ template</a><ul>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">2.8.1</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">2.8.2</span> Subsection 2</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#applied-exercise"><span class="toc-section-number">2.8.3</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="2-9-harnessing-version-control-for-transparent-data-recording.html#harnessing-version-control-for-transparent-data-recording"><span class="toc-section-number">2.9</span> Harnessing version control for transparent data recording</a><ul>
<li><a href="2-9-harnessing-version-control-for-transparent-data-recording.html#what-is-version-control"><span class="toc-section-number">2.9.1</span> What is version control?</a></li>
<li><a href="2-9-harnessing-version-control-for-transparent-data-recording.html#recording-data-in-the-laboratoryfrom-paper-to-computers"><span class="toc-section-number">2.9.2</span> Recording data in the laboratory—from paper to computers</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#discussion-questions"><span class="toc-section-number">2.9.3</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="2-10-enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms.html#enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms"><span class="toc-section-number">2.10</span> Enhance the reproducibility of collaborative research with version control platforms</a><ul>
<li><a href="2-10-enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms.html#git-and-github-features"><span class="toc-section-number">2.10.1</span> git and GitHub features</a></li>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">2.10.2</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">2.10.3</span> Subsection 2</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#discussion-questions"><span class="toc-section-number">2.10.4</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="2-11-using-git-and-gitlab-to-implement-version-control.html#using-git-and-gitlab-to-implement-version-control"><span class="toc-section-number">2.11</span> Using git and GitLab to implement version control</a><ul>
<li><a href="2-11-using-git-and-gitlab-to-implement-version-control.html#how-to-use-version-control"><span class="toc-section-number">2.11.1</span> How to use version control</a></li>
<li><a href="2-11-using-git-and-gitlab-to-implement-version-control.html#leveraging-git-and-github-as-a-project-director"><span class="toc-section-number">2.11.2</span> Leveraging git and GitHub as a project director</a></li>
<li><a href="2-11-using-git-and-gitlab-to-implement-version-control.html#leveraging-git-and-github-as-a-scientist-who-programs"><span class="toc-section-number">2.11.3</span> Leveraging git and GitHub as a scientist who programs</a></li>
<li><a href="2-11-using-git-and-gitlab-to-implement-version-control.html#notes"><span class="toc-section-number">2.11.4</span> Notes</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#applied-exercise"><span class="toc-section-number">2.11.5</span> Applied exercise</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="3-experimental-data-preprocessing.html#experimental-data-preprocessing"><span class="toc-section-number">3</span> Experimental Data Preprocessing</a><ul>
<li class="has-sub"><a href="3-1-principles-and-benefits-of-scripted-pre-processing-of-experimental-data.html#principles-and-benefits-of-scripted-pre-processing-of-experimental-data"><span class="toc-section-number">3.1</span> Principles and benefits of scripted pre-processing of experimental data</a><ul>
<li><a href="3-1-principles-and-benefits-of-scripted-pre-processing-of-experimental-data.html#what-is-pre-processing"><span class="toc-section-number">3.1.1</span> What is pre-processing?</a></li>
<li><a href="3-1-principles-and-benefits-of-scripted-pre-processing-of-experimental-data.html#approaches-to-simple-preprocessing-tasks"><span class="toc-section-number">3.1.2</span> Approaches to simple preprocessing tasks</a></li>
<li><a href="3-1-principles-and-benefits-of-scripted-pre-processing-of-experimental-data.html#approaches-to-more-complex-preprocessing-tasks"><span class="toc-section-number">3.1.3</span> Approaches to more complex preprocessing tasks</a></li>
<li><a href="3-1-principles-and-benefits-of-scripted-pre-processing-of-experimental-data.html#scripting-preprocessing-tasks"><span class="toc-section-number">3.1.4</span> Scripting preprocessing tasks</a></li>
<li><a href="3-1-principles-and-benefits-of-scripted-pre-processing-of-experimental-data.html#potential-quotes"><span class="toc-section-number">3.1.5</span> Potential quotes</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#discussion-questions"><span class="toc-section-number">3.1.6</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="3-2-introduction-to-scripted-data-pre-processing-in-r.html#introduction-to-scripted-data-pre-processing-in-r"><span class="toc-section-number">3.2</span> Introduction to scripted data pre-processing in R</a><ul>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">3.2.1</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">3.2.2</span> Subsection 2</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#applied-exercise"><span class="toc-section-number">3.2.3</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="3-3-simplify-scripted-pre-processing-through-rs-tidyverse-tools.html#simplify-scripted-pre-processing-through-rs-tidyverse-tools"><span class="toc-section-number">3.3</span> Simplify scripted pre-processing through R’s ‘tidyverse’ tools</a><ul>
<li><a href="3-3-simplify-scripted-pre-processing-through-rs-tidyverse-tools.html#limitations-of-object-oriented-programming"><span class="toc-section-number">3.3.1</span> Limitations of object-oriented programming</a></li>
<li><a href="3-3-simplify-scripted-pre-processing-through-rs-tidyverse-tools.html#the-tidyverse-approach"><span class="toc-section-number">3.3.2</span> The “tidyverse” approach</a></li>
<li><a href="3-3-simplify-scripted-pre-processing-through-rs-tidyverse-tools.html#how-to-tidyverse"><span class="toc-section-number">3.3.3</span> How to “tidyverse”</a></li>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">3.3.4</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">3.3.5</span> Subsection 2</a></li>
<li><a href="2-3-the-tidy-data-format.html#practice-quiz"><span class="toc-section-number">3.3.6</span> Practice quiz</a></li>
</ul></li>
<li class="has-sub"><a href="3-4-complex-data-types-in-experimental-data-pre-processing.html#complex-data-types-in-experimental-data-pre-processing"><span class="toc-section-number">3.4</span> Complex data types in experimental data pre-processing</a><ul>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">3.4.1</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">3.4.2</span> Subsection 2</a></li>
<li><a href="3-4-complex-data-types-in-experimental-data-pre-processing.html#subsection-3"><span class="toc-section-number">3.4.3</span> Subsection 3</a></li>
<li><a href="2-3-the-tidy-data-format.html#practice-quiz"><span class="toc-section-number">3.4.4</span> Practice quiz</a></li>
</ul></li>
<li class="has-sub"><a href="3-5-complex-data-types-in-r-and-bioconductor.html#complex-data-types-in-r-and-bioconductor"><span class="toc-section-number">3.5</span> Complex data types in R and Bioconductor</a><ul>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">3.5.1</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">3.5.2</span> Subsection 2</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#applied-exercise"><span class="toc-section-number">3.5.3</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="3-6-example-converting-from-complex-to-tidy-data-formats.html#example-converting-from-complex-to-tidy-data-formats"><span class="toc-section-number">3.6</span> Example: Converting from complex to ‘tidy’ data formats</a><ul>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">3.6.1</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">3.6.2</span> Subsection 2</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#applied-exercise"><span class="toc-section-number">3.6.3</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="3-7-introduction-to-reproducible-data-pre-processing-protocols.html#introduction-to-reproducible-data-pre-processing-protocols"><span class="toc-section-number">3.7</span> Introduction to reproducible data pre-processing protocols</a><ul>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">3.7.1</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">3.7.2</span> Subsection 2</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#discussion-questions"><span class="toc-section-number">3.7.3</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="3-8-rmarkdown-for-creating-reproducible-data-pre-processing-protocols.html#rmarkdown-for-creating-reproducible-data-pre-processing-protocols"><span class="toc-section-number">3.8</span> RMarkdown for creating reproducible data pre-processing protocols</a><ul>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">3.8.1</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">3.8.2</span> Subsection 2</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#applied-exercise"><span class="toc-section-number">3.8.3</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="3-9-example-creating-a-reproducible-data-pre-processing-protocol.html#example-creating-a-reproducible-data-pre-processing-protocol"><span class="toc-section-number">3.9</span> Example: Creating a reproducible data pre-processing protocol</a><ul>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">3.9.1</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">3.9.2</span> Subsection 2</a></li>
<li><a href="2-3-the-tidy-data-format.html#practice-quiz"><span class="toc-section-number">3.9.3</span> Practice quiz</a></li>
</ul></li>
</ul></li>
<li><a href="4-references.html#references"><span class="toc-section-number">4</span> References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="principles-and-benefits-of-scripted-pre-processing-of-experimental-data" class="section level2">
<h2><span class="header-section-number">3.1</span> Principles and benefits of scripted pre-processing of experimental data</h2>
<p>The experimental data collected for biomedical research often requires
pre-processing before it can be analyzed (e.g., gating of flow cytometry data,
feature finding / quantification for mass spectrometry data). Use of
point-and-click software can limit the transparency and reproducibility of this
analysis stage and is time-consuming for repeated tasks. We will explain how
scripted pre-processing, especially using open source software, can improve
transparency and reproducibility.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Define ‘pre-processing’ of experimental data</li>
<li>Describe an open source code script and explain how it can increase
reproducibility of data pre-processing</li>
</ul>
<div id="what-is-pre-processing" class="section level3">
<h3><span class="header-section-number">3.1.1</span> What is pre-processing?</h3>
<p>Some data collected through laboratory experiments is very straightforward and
requires little or no pre-processing before it’s used in analysis. For example,
[example]. Other data may require some minimal pre-processing. For example, if
you plate bacteria from a sample at a variety of dilutions, you might count each
plate and determine a measure of Colony Forming Units from the set of plates
with different dilutions by deciding which dilution provides the clearest count
and then back-calculating based on its dilution to get the total number of
colony-forming units in the original sample.</p>
<p>This step of pre-processing data can become much more complex with data that was
collected using complex equipment, like a flow cytometer or a mass spectrometer.
In these cases, there are often steps required to extract from the machine’s
readings a biologically-relevant measurement. For example, the data output from
a mass spectrometer must be processed to move from measurements of mass and
retention time to estimates of concentrations of different molecules in the
sample. If you want to compare across multiple samples, then the preprocessing
will also involve steps to align the different samples (in terms of …), as
well as to standardize the measurements for each sample, to make the
measurements from the different samples comparable. For data collected from a
flow cytometer, preprocessing may include steps to disentangle the florescence
from different markers to ensure that the read for one marker isn’t inflated by
spillover florescence from a different marker.</p>
</div>
<div id="approaches-to-simple-preprocessing-tasks" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Approaches to simple preprocessing tasks</h3>
<p>There are several approaches for tackling this type of data preprocessing, to
get from the data that you initial observe (or that is measured by a piece of
laboratory equipment) to meaningful biological measurements that can be analyzed
and presented to inform explorations of a scientific hypothesis. While there are
a number of approaches that don’t involve writing code scripts for this
preprocessing, there are some large advantages to scripting preprocessing any
time you are preprocessing experimental data prior to including it in figures or
further analysis. In this section, we’ll describe some common non-scripted
approaches and discuss the advantages that would be brought by instead using a
code script. In the next module, we’ll walk through an example of how scripts
for preprocessing can be created and applied in laboratory research.</p>
<p>In cases where the pre-processing is mathematically straightforward and the
dataset is relatively small, many researchers do the preprocessing by hand in a
laboratory notebook or through an equation or macro embedded in a spreadsheet.
For example, if you have plated samples at different dilutions and are trying to
calculate from these the CFUs in the original sample, this calculation is simple
enough that it could be done by hand. However, there are advantages to instead
writing a code script to do this simple preprocessing.</p>
<p>When you write a script to do a task with data, it is like writing a recipe that
can be applied again and again. By writing a script, you encode the process a
single time, so you can take the time to check and recheck to make sure that
you’ve encoded the process correctly. This helps in avoiding small errors when
you do the preprocessing—if you are punching numbers into a calculator over
and over, it’s easy to mistype a number or forget a step every now and then,
while the code will ensure that the same process is run every time and that it
faithfully uses the numbers saved in the data for each step, rather than relying
on a person correctly entering each number in the calculation.</p>
<p>Scripts can be used across projects, as well, and so they can ensure consistency
in the calculation across projects. If different people do the calculation in
the lab for different projects or experiments, and they are doing the
calculations by hand, they might each do the calculation slightly differently,
even if it’s only in small details like how they report rounded numbers. A
script will do the exact same thing every time it is applied. You can even share
your script with colleagues at other labs, if you want to ensure that your data
preprocessing is comparable for experiments conducted in different research
groups, and many scientific journals will allow supplemental material with
code used for data preprocessing and analysis, or links within the manuscript
to a repository of this code posted online.</p>
<p>There are also gains in efficiency when you use a script. For small
pre-processing steps, these might seem small for each experiment, and certainly
when you first write the script, it will likely take longer to write and test
the script than it would to just do the calculation by hand (even more if
you’re just starting to learn how to write code scripts). However, since the
script can be applied again and again, with very little extra work to apply it
to new data, you’ll save yourself time in the future, and over a lot of
experiments and projects, this can add up. This makes it particularly useful to
write scripts for preprocessing tasks that you find yourself doing again and
again in the lab.</p>
</div>
<div id="approaches-to-more-complex-preprocessing-tasks" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Approaches to more complex preprocessing tasks</h3>
<p>Other preprocessing tasks can be much more complex, particularly those that need
to conduct a number of steps to extract biologically meaningful measurements
from the measurements made by a complex piece of laboratory equipment, as well
as steps to make sure these measurements can be meaningfully compared across
samples.</p>
<p>For these more complex tasks, the equipment manufacturer will often provide
software that can be used for the preprocessing. This software might conduct
some steps using defaults, and others based on the user’s specifications. These
are often provided through “GUIs” (graphical user interfaces), where the user
does a series of point-and-click steps to process the data. In some software,
this series of point-and-click steps is recorded as the user does them, so that
these steps can be “re-run” later or on a different dataset.</p>
<p>For many types of biological data, including output from equipment like flow
cytometers and mass spectrometers, open-source software has been developed
that can be used for this preprocessing. Often, the most cutting edge methods
for data preprocessing are first available through open-source software packages,
if the methods are developed by researchers rather than by the companies, and
often many of the algorithms that are made available through the equipment
manufacturer’s proprietary software are encoded versions of an algorithm
first shared by researchers as open-source software.</p>
<p>It can take a while to develop a code script for preprocessing the raw data from
a piece of complex equipment like a mass spectrometer. However, the process of
developing this script requires a thoughtful consideration of the steps of
preprocessing, and so this is often time well-spent. Again, this initial time
investment will pay off later, as the script can then be efficiently applied to
future data you collect from the equipment, saving you time in pointing and
clicking through the GUI software. Further, it’s easier to teach someone else
how to conduct the preprocessing that you’ve done, and apply it to future
experiments, because the script serves as a recipe.</p>
<p>When you conduct data preprocessing in a script, this also gives you access to
all the other tools in the scripting language. For example, as you work through
preprocessing steps for a dataset, if you are doing it through an R script, you
can use any of the many visualization tools that are available through R. By
contrast, in GUI software, you are restricted to the visualization and other
tools included in that particular set of software, and those software developers
may not have thought of something that you’d like to do. Open-source scripting
languages like R, Python, and Julia include a huge variety of tools, and once
you have loaded your data in any of these platforms, you can use any of these
tools.</p>
<p>If you have developed a script for preprocessing your raw data, it also becomes
much easier to see how changes in choices in preprocessing might influence your
final results. It can be tricky to guess whether your final results are sensitive,
for example, to what choice you make for a particular tranform for part of your
data, or in how you standardize data in one sample to make different samples
easier to compare. If the preprocessing is in a script, then you can test making
these changes and running all preprocessing and analysis scripts, to see if it
makes a difference in the final conclusions. If it does, then it helps you
identify parts of preprocessing that need to be deeply thought through for the
type of data you’re collecting, and you may want to explore the documentation on
that particular step of preprocessing to determine what choice is best for your
data, rather than relying on defaults.</p>
</div>
<div id="scripting-preprocessing-tasks" class="section level3">
<h3><span class="header-section-number">3.1.4</span> Scripting preprocessing tasks</h3>
<p>Code scripts can be developed for any open-source scripting languages, including
Python, R, and Julia. These can be embedded in or called from literate programming
documents, like RMarkdown and Julia, which are described in other modules. The
word “script” is a good one here—it really is as if you are providing the script
for a play. In an interactive mode, you can send requests to run in the programming
language step by step using a console, while in a script you provide the whole list
of all of your “lines” in that conversation, and the programming language will run
them all in order without you needing to interact from the console.</p>
<p>For preprocessing the data, the script will have a few predictible parts. First,
you’ll need to read the data in. There are different functions that can be used
to read in data from different file formats. For example, data that is stored in
an Excel spreadsheet can be loaded into R using functions in a package called
<code>readxl</code>. Data that is stored in a plain-text delimited format (like a csv file)
can be loaded into R using functions in the <code>readr</code> package.</p>
<p>When preprocessing data from complex equipment, you can determine how to read the
data into R by investigating the file type that is output by the equipment.
Fortunately, many types of scientific equipment follow standardized file formats.
This means that open-source developers can develop a single package that can
load data from equipment from multiple manufacturers. For example, flow cytometry
data is often stored in [file format]. Other biological datasets use file
formats that are appropriate for very large datasets and that allow R to work
with parts of the data at a time, without loading the full data in. [netCDF?]
In these cases, the first step in a script might not be to load in all the data,
but rather to provide R with a connection to the larger datafile, so it can
pull in data as it needs it.</p>
<p>Once the data is loaded or linked in the script, the script can proceed through
steps required to preprocess this data. These steps will often depend on the type
of data, especially the methods and equipment used to collect it. For example, for
mass spectrometry data, these steps will include … . For flow cytometry data,
these steps would include … .</p>
<p>The functions for doing these steps will often come from extensions that
different researchers have made for R. Base R is a simpler collection of data
processing and statistics tools, but the open-source framework of R has allowed
users to make and share their own extensions. In R, these are often referred to
as “packages”. Many of these are shared through the Comprehensive R Archive
Network (CRAN), and packages on CRAN can be directly installed using the
<code>install.packages</code> function in R, along with the package’s names. While CRAN
is the common spot for sharing general-purpose packages, there is a specialized
repository that is used for many genomics and other biology-related R packages
called Bioconductor. These packages can also be easily installed through a call
in R, but in this case it requires an installation function from the <code>BiocManager</code>
package. Many of the functions that are useful for preprocessing biological
data from laboratory experiments are available through Bioconductor.</p>
<p>Table [x] includes some of the primary R packages on Bioconductor that can be
used in preprocessing different types of biological data. There are often
multiple choices, developed by different research groups, but this list provides
a starting point of several of the standard choices that you may want to
consider as you start developing code.</p>
<p>Much of the initial preprocessing might use very specific functions that are
tailored to the format that the data takes once it is loaded. Later in the
script, there will often be a transfer to using more general-purpose tools in
that coding language. For example, once data is stored in a “dataframe” format
in R, it can be processed using a powerful set of general purpose tools
collected in a suite of packages called the “tidyverse”. This set of packages
includes functions for filtering to specific subsets of the data, merging
separate datasets, adding new measurements for each observation that are
functions of the initial measurements, summarizing, and visualizing. The
tidyverse suite of R tools is very popular in general R use and is widely
taught, including through numerous free online resources. By moving from
specific tools to these more general tools as soon as possible in the script, a
researcher can focus his or her time in learning these general purpose tools
well, as these can be widely applied across many types of data.</p>
<p>By the end of the script, data will be in a format that has extracted
biologically relevant measurements. Ideally, this data will be in a general
purpose format, like a dataframe, to make it easier to work with using general
purpose tools in the scripting language when the data is used in further data
analysis or to create figures for reports, papers, and presentations. Often, you
will want to save a version of this preprocessed version of the data in your
project files, and so the last step of the script might be to write out the
cleaned data in a file that can be loaded in later scripts for analysis and
visualization. This is especially useful if these data preprocessing steps are
time consuming, as is often the case for the large raw datasets output by
laboratory equipment like flow cytometers and mass spectrometers.</p>
<p>Figure [x] gives an example of a data preprocessing script, highlighting these
different common areas that often show up in these scripts.</p>
</div>
<div id="potential-quotes" class="section level3">
<h3><span class="header-section-number">3.1.5</span> Potential quotes</h3>
<blockquote>
<p>For bioinformatics, “all too often the software is developed without
thought toward future interoperability with other software products. As a
result, the bioinformatics software landscape is currently characterized
by fragmentation and silos, in which each research group develops and uses
only the tools created within their lab.” <span class="citation">(Barga et al. 2011)</span></p>
</blockquote>
<blockquote>
<p>“The group also noted the lack of agility. Although they may be aware of
a new or better algorithm they cannot easily integrate it into their
analysis pipelines given the lack of standards across both data formats
and tools. It typically requires a complete rewrite of the code in order
to take advntge of a new technique or algorithm, requiring time and often
funding to hire developers.” <span class="citation">(Barga et al. 2011)</span></p>
</blockquote>
<blockquote>
<p>“The benefit of working with a programming language is that you have the code in
a file. This means that you can easily reuse that code. If the code has
parameters it can even be applied to problems that follow a similar pattern.”
<span class="citation">(Janssens 2014)</span></p>
</blockquote>
<blockquote>
<p>“Data exploration in spreadsheet software is typically conducted via menus and
dialog boxes, which leaves no record of the steps taken.” <span class="citation">(Murrell 2009)</span></p>
</blockquote>
<blockquote>
<p>“One reason Unix developers have been cool toward GUI interfaces is that, in their
designers’ haste to make them ‘user-friendly’ each one often becomes frustratingly
opaque to anyone who has to solve user problems—or, indeed, interact with it anywhere
outside the narrow range predicted by the user-interface designer.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Many operating systems touted as more ‘modern’ or ‘user friendly’ than Unix achieve their
surface glossiness by locking users and developers into one interface policy, and offer an
application-programming interface that for all its elaborateness is rather narrow and rigid.
On such systems, tasks the designers have anticipated are very easy—but tasks they have
not anticipated are often impossible or at best extremely painful. Unix, on the other hand, has
flexibility in depth. The many ways Unix provides to glue together programs means that components
of its basic toolkit can be combined to produce useful effects that the designers of the individual
toolkit parts never anticipated.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“The good news is that a computer is a general-purpose machine, capable of performing
any computation. Although it only has a few kinds of instructions to work with, it can
do them blazingly fast, and it can largely control its own operation. The bad news is
that it doesn’t do anything itself unless someone tells it what to do, in excruciating
detail. A computer is the ultimate sorcere’s apprentice, able to follow instructions
tirelessly and without error, but requiring painstaking accuracy in the
specification of what to do.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“<em>Software</em> is the general term for sequences of instructions that make a computer
do something useful. It’s ‘soft’ in contrast with ‘hard’ hardware, because it’s
intangible, not easy to put your hands on. Hardware is quite tangible: if you drop
a computer on your foot, you’ll notice. Not true for software.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“Modern system increasingly use general purpose hardware—a processor, some memory,
and connections to the environment—and create specific behaviors by software. The
conventional wisdom is that software is cheaper, more flexible, and easier to change than
hardware is (especially once some device has left the factory).” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“An algorithm is a precise and unambiguous recipe. It’s expressed in terms of a fixed
set of basic operations whose meanings are completely known and specified; it spells out
a sequence of steps using those operations, with all possible situations covered; it’s
guaranteed to stop eventually. On the other hand, a <em>program</em> is the opposite of
abstract—it’s a concrete statement of the steps that a real computer must perform to
accomplish a task. The distinction between an algorithm and a program is like the difference
between a blueprint and a building; one is an idealization and the other is the real thing.”
<span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“One way to view a program is as one or more algorithms expressed in a form that a computer
can process directly. A program has to worry about practical problems like inadequate memory,
limited processor speed, invalid and even malicious input data, faulty hardware, broken
network connections, and (in the background and often exacerbating the other problems)
human frailty. So if an algorithm is an idealized recipe, a program is the instructions for
a cooking robot preparing a month of meals for an army while under enemy attack.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“During the late 1950s and early 1960s, another step was taken towards getting the
computer to do more for programmers, arguably the most important step in the history of
programming. This was the development of ‘high-level’ programming languages that were
independent of any particular CPU architecture. High-level languages make it possible to
express computations in terms that are closer to the way a person might express them.”
<span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“Programming in the real world tends to happen on a large scale. The strategy is similar
to what one might use to write a book or undertake any other big project: figure out what
to do, starting with a broad specification that is broken into smaller and smaller pieces,
then work on the pieces separately, while making sure that they hang together. In programming,
pieces tend to be of a size such that one person can write the precise computational steps
in some programming language. Ensuring that the pieces written by different programmers
work together is challenging, and failing to get this right is a major source of errors.
For instance, NASA’s Mars Climate Orbiter failed in 1999 because the flight system software
used metric units for thrust, but course correction data was entered in English units,
causing an erroneous trajectory that brought the Orbiter too close to the planet’s
surface.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“If you’re going to build a house today, you don’t start by cutting down trees to make
lumber and digging clay to make your own bricks. Instead, you buy prefabricated pieces like
doors, windows, plumbing fixtures, a furnace, and a water heater. House construction is still
a big job, but it’s manageable because you can build on the work of many others and rely
on an infrastructure, indeed an entire industry, that will help. The same is true of
programming. Hardly any significant program is created from nothing. Many components written
by others can be taken off the shelf and used. For instance, if you’re writing a program for
Windows or a Mac, there are libraries of prefabricated menus, buttons, text editors, graphics,
network connections, database access, and so on. Much of the job is understanding the components
and gluing them together in your own way. Of course, many of these components in turn rest on
other simpler and more basic ones, often for several layers. Below that, everything runs on
the operating system, a program that manages the hardware and controls everything that happens.”
<span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“At the simplest level, programming languages provide a mechanism called functions that make
it possible for one programmer to write code that performs a useful a useful task, then package
it in a form that other programmers can use in their programs without having to know how it
works.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“A function has a name and a set of input data values that it needs to do its job; it does
a computation and returns a result to the part of the program that called it. … Functions
make it possible to create a program by building on components that have been created separately
and can be used as necessary by all programmers. A collection of related functions is usually
called a <em>library</em>. … The services that a function library provides are described to programmers
in terms of an <em>Application Programming Interface</em>, or <em>API</em>, which lists the functions, what
they do, how to use them in a program, what input data they require, and what values they
produce. The API might also describe data structures—the organization of data that is passed
back and forth—and various other bits and pieces that all together define what a programmer
has to do to request services and what will be computed as a result. This specification must
be detailed and precise, since in the end the program will be interpreted by a dumb literal
computer, not by a friendly and accomodating human.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“The code that a programmer writes, whether in assembly language or (much more likely) in
a high-level language, is called <em>source code</em>. … Source code is readable by other programmers,
though perhaps with some effort, so it can be studied and adapted, and any innovations or ideas
it contains are visible.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“In early times, most software was developed by companies and most source code was
unavailable, a trade secret of whoever developed it.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“An <em>operating system</em> is the software underpinning that manages the hardware of a
computer and makes it possible to run other programs, which are called <em>applications</em>.
… It’s a clumsy but standard terminology for programs that are more or less self-contained
and focused on a single task.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“Software, like many other things in computing, is organized into layers, analogous to
geological strata, that separate one concern from another. Layering is one of the important
ideas that help programmers to manage complexity.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“I think that it’s important for a well-informed person to know something about
programming, perhaps only that it can be surprisingly difficult to get very simple
programs working properly. There is nothing like doing battle with a computer to teach
this lesson, but also to give people a taste of the wonderful feeling of accomplishment
when a program does work for the first time. It may also be valuable to have enough
programming experience that you are cautious when someone says that programming is easy,
or that there are no errors in a program. If you have trouble making 10 lines of code
work after a day of struggle, you might be legitimately skeptical of someone who claims
that a million-line program will be delivered on time and bug-free.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“Programming languages share certain basic ideas, since they are all notations for spelling
out a computation as a sequence of steps. Every programming language thus will provide ways
to get input data upon which to compute; do arithmetic; store and retrieve intermediate
values as computation proceeds; display results along the way; decide how to proceed on the basis
of previous computations; and save results when the computation is finished. Languages have
<em>syntax</em>, that is, rules that define what is grammatically legal and what is not.
Programming languages are picky on the grammatical side: you have to say it right or there
will be a complaint. Languages also have <em>semantics</em>, that is, a defined meaning for every
construction in the language.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“In programming, a <em>library</em> is a collection of related pieces of code. A library typically
includes the code in compiled form, along with needed source code declarations [for C++].
Libraries can include stand-alone functions, classes, type declarations, or anything else that
can appear in code.” <span class="citation">(Spraul 2012)</span></p>
</blockquote>
<blockquote>
<p>“One way to write R code is simply to enter it interactively at the command line… This
interactivity is beneficial for experimenting with R or for exploring a data set in a casual
manner. … However, interactively typing code at the R command line is a very bad approach from
the perspective of recording and documenting code because the code is lost when R is shut down.
A superior approach in general is to write R code in a file and get R to read the code from the file.” <span class="citation">(Murrell 2009)</span></p>
</blockquote>
<blockquote>
<p>“The features of R are organized into separate bundles called <em>packages</em>. The standard R
installation includes about 25 of those packages, but many more can be downloaded from CRAN and
installed to expand the things that R can do. … Once a package is installed, it must be
<em>loaded</em> within an R session to make the extra features available. … Of the 25 packages
that are installed by default, nine packages are <em>loaded</em> by default when we start a new
R session; these provide the basic functionality of R. All other packages must be loaded
before the relevant features can be used.” <span class="citation">(Murrell 2009)</span></p>
</blockquote>
<blockquote>
<p>“The R environment is the software used to run R code.” <span class="citation">(Murrell 2009)</span></p>
</blockquote>
</div>
<div id="discussion-questions" class="section level3">
<h3><span class="header-section-number">3.1.6</span> Discussion questions</h3>

</div>
</div>
<p style="text-align: center;">
<a href="3-experimental-data-preprocessing.html"><button class="btn btn-default">Previous</button></a>
<a href="3-2-introduction-to-scripted-data-pre-processing-in-r.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
