<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="3.9 Example: Creating a reproducible data pre-processing protocol | Improving the Reproducibility of Experimental Data Recording and Pre-Processing" />
<meta property="og:type" content="book" />

<meta property="og:description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing." />
<meta name="github-repo" content="rstudio/bookdown-demo" />

<meta name="author" content="Brooke Anderson, Michael Lyons, Mercedes Gonzalez-Juarrero, Marcela Henao-Tamayo, and Gregory Robertson" />



<meta name="description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing.">

<title>3.9 Example: Creating a reproducible data pre-processing protocol | Improving the Reproducibility of Experimental Data Recording and Pre-Processing</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#overview-of-these-modules" id="toc-overview-of-these-modules"><span class="toc-section-number">1</span> Overview of these modules</a></li>
<li><a href="2-experimental-data-recording.html#experimental-data-recording" id="toc-experimental-data-recording"><span class="toc-section-number">2</span> Experimental Data Recording</a></li>
<li><a href="3-experimental-data-preprocessing.html#experimental-data-preprocessing" id="toc-experimental-data-preprocessing"><span class="toc-section-number">3</span> Experimental Data Preprocessing</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="module20" class="section level2" number="3.9">
<h2><span class="header-section-number">3.9</span> Example: Creating a reproducible data pre-processing protocol</h2>
<p>We will walk through an example of creating a reproducible data pre-processing
protocol. As an example, we will look at how to pre-process and analyze data
that are collected in the laboratory to estimate bacterial load in samples.
These data come from plating samples from an immunological experiment at serial
dilutions, using data from an experiment lead by one of the coauthors. This data
pre-processing protocol was created using RMarkdown and allows the efficient,
transparent, and reproducible pre-processing of plating data for all experiments
in the research group. We will go through how RMarkdown techniques can be
applied to develop this type of data pre-processing protocol for a laboratory
research group.</p>
<p><strong>Objectives.</strong> After this module, you should be able to:</p>
<ul>
<li>Explain how a reproducible data pre-processing protocol can be developed for
a real research project</li>
<li>Understand how to design and implement a data pre-processing protocol to
replace manual or point-and-click data pre-processing tools</li>
<li>Apply techniques in RMarkdown to develop your own reproducible data
pre-processing protocols</li>
</ul>
<div id="introduction-and-example-data" class="section level3" number="3.9.1">
<h3><span class="header-section-number">3.9.1</span> Introduction and example data</h3>
<p>In this module, we’ll provide advice and an example of how you can use the
tools for knitted documents to create a reproducible data pre-processing
protocol. This module builds on ideas and techniques that were introduced
in the last two modules (3.7 and 3.8), to help you put them into practical use for
data pre-processing that you do repeatedly for research data in your
laboratory.</p>
<p>In this module, we will use an example of a common pre-processing task in
immunological research: estimating the bacterial load in samples by plating at
different dilutions. For this type of experiment, the laboratory researcher
plates each of the samples at several dillutions, identifies a good dilution for
counting colony-forming units (CFUs), and then back-calculates the estimated
bacterial load in the original sample based on the colonies counted at this “good”
dilution. This experimental technique dates back to the late 1800s, with Robert
Koch, and continues to be widely used in microbiology research and applications
today <span class="citation">(Ben-David and Davidson 2014)</span>. These data are originally from an experiment in one
of our authors’ laboratory and are also available as example data for an R
package called <code>bactcountr</code>, currently under development at
<a href="https://github.com/aef1004/bactcountr/tree/master/data" class="uri">https://github.com/aef1004/bactcountr/tree/master/data</a>.</p>
<p>These data are representative of data often collected in immunological research.
For example, you may be testing out some drugs against an infectious bacteria
and want to know how successful different drugs are in limiting bacterial load.
You run an experiment and have samples from animals treated with different drugs
or under control and would then want to know how much viable (i.e., replicating)
bacteria are in each of your samples.</p>
<p>You can find out by plating the sample at different dilutions and
counting the colony-forming units (CFUs) that are cultured on each plate.
You put a sample on a plate with a medium they can grow on and then give them
time to grow. The idea is that individual bacteria from the original sample end
up randomly around the surface of the plate, and any that are viable (able to
reproduce) will form a new colony that, after a while, you’ll be able to see.</p>
<p>To get a good estimate of bactieral load from this process, you need to count
CFUs on a “countable” plate—one with a “just right” dilution (and you
typically won’t know which dilution this is for a sample until after plating).
If you have too high of a dilution (i.e., one with very few viable bacteria),
randomness will play a big role in the CFU count, and you’ll estimate the
original bacterial load with more variability. If you have too low of a dilution (i.e., one
with lots of viable bacteria), it will be difficult to identify separate
colonies, and they may complete for resources. To translate from diluted
concentration to original concentration, you can then do a back-calculation,
incorporating both the number of colonies counted at that dilution and how
dilute the sample was. There is therefore some pre-processing required (although
it is fairly simple) to prepare the data collected to get an estimate of
bacterial load in the original sample. This estimate of bacterial load can then be used in
statistical testing and combined with other experimental data to explore
questions like whether a candidate vaccine reduces bacterial load when a research
animal is challenged with a pathogen.</p>
<p>We will use this example of a common data pre-processing task to show how to
create a reproducible pre-processing protocol in this module. If you would like,
you can access all the components of the example pre-processing protocol and
follow along, re-rendering it yourself on your own computer. The example data
are available as a csv file, downloadable
<a href="https://raw.githubusercontent.com/geanders/improve_repro/master/data/bactcountr_example_data/cfu_data.csv">here</a>.
You can open this file using spreadsheet software, or look at it directly in
RStudio. The final pre-processing protocol for these data can also be
downloaded, including both <a href="https://raw.githubusercontent.com/geanders/improve_repro/master/data/bactcountr_example_data/example_protocol.Rmd">the original RMarkdown
file</a>
and <a href="https://github.com/geanders/improve_repro/raw/master/data/bactcountr_example_data/example_protocol.pdf">the output PDF
document</a>.
Throughout this module, we will walk through elements of this document, to
provide an example as we explain the process of developing data pre-processing
modules for common tasks in your research group. We recommend that you go ahead and
read through the output PDF document, to get an idea for the example protocol that
we’re creating.</p>
<p>This example is intentionally simple, to allow a basic introduction to the
process using pre-processing tasks that are familiar to many laboratory-based
scientists and easy to explain to anyone who has not used plating in experimental
work. However, the same general process can also be used to create
pre-processing protocols for data that are much larger or more complex or for
pre-processing pipelines that are much more involved.
For example, this process could be used to create data pre-processing protocols
for automated gating of flow cytometry data or for pre-processing data
collected through single cell RNA sequencing.</p>
</div>
<div id="advice-on-designing-a-pre-processing-protocol" class="section level3" number="3.9.2">
<h3><span class="header-section-number">3.9.2</span> Advice on designing a pre-processing protocol</h3>
<p>Before you write your protocol in a knitted document, you should decide on the
content to include in the protocol. This section provides tips on this design
process. In this section, we’ll describe some key steps in designing a
data pre-processing protocol:</p>
<ol style="list-style-type: decimal">
<li>Defining input and output data for the protocol;</li>
<li>Setting up a project directory for the protocol;</li>
<li>Outlining key tasks in pre-processing the input data; and</li>
<li>Adding code for pre-processing.</li>
</ol>
<p>We will illustrate these design steps using the example protocol on
pre-processing plating data.</p>
<p><strong>Defining input and output data for the protocol.</strong></p>
<p>The first step in designing the data pre-processing protocol is to decide on the
starting point for the protocol (the data input) and the ending point (the data
output). It may make sense to design a separate protocol for each major type of
data that you collect in your research laboratory. Your input data for the
protocol, under this design, might be the data that is output from a specific
type of equipment (e.g., flow cytometer) or from a certain type of sample or
measurement (e.g., metabolomics run on a mass spectrometer), even if it is a
fairly simple type of data (e.g., CFUs from plating data, as used in the example
protocol for this module). For example, say you are working with three types of
data for a research experiment: data from a flow cytometer, metabolomics data
measured with a mass spectrometer, and bacterial load data measured by plating
data and counting colony forming units (CFUs). In this case, you may want to
create three pre-processing protocols: one for the flow data, one for the
metabolomics data, and one for the CFU data. These protocols are modular and can
be re-used with other experiments that use any of these three types of data.</p>
<p>With an example dataset, you can begin to create a pre-processing protocol
before you collect any of your own research data for a new experiment. If the
format of the initial data is similar to the format you anticipate for your
data, you can create the code and explanations for key steps in your
pre-processing for that type of data. Often, you will be able to adapt the
RMarkdown document to change it from inputting the example data to inputting
your own experimental data with minimal complications, once your data comes in.
By thinking through and researching data pre-processing options before the data
is collected, you can save time in analyzing and presenting your project results
once you’ve completed the experimental data collection for the project. Further,
with an example dataset, you can get a good approximation of the format in which
you will output data from the pre-processing steps. This will allow you to begin
planning the analysis and visualization that you will use to combine the
different types of data from your experiment and use it to investigate important
research hypotheses. Again, if data follow standardized formats across steps in
your process, it will often be easy to adapt the code in the protocol to input
the new dataset that you created, without major changes to the code developed
with the example dataset.</p>
<p>While pre-processing protocols for some types of data might be very complex,
others might be fairly simple. However, it is still worthwhile to develop a
protocol even for simple pre-processing tasks, as it allows you to pass along
some of the details of pre-processing the data that might have become “common
sense” to longer-tenured members of your research group. For example, the
pre-processing tasks in the example protocol are fairly simple. This protocol
inputs data collected in a plain-text delimited file (a csv file, in the
example). Within the protocol, there are steps to convert initial measurements
from plating at different dilutions into an estimate of the bacterial load in
each sample. There are also sections in the protocol for exploratory data
analysis, to allow for quality assessment and control of the collected data as
part of the pre-processing. The output of the protocol is a simple data object (a
dataframe, in this example) with the bacterial load for each original sample.
These data are now ready to be used in tables and figures in the research report
or manuscript, as well as to explore associations with the experimental design
details (e.g., comparing bacterial load in treated versus untreated animals) or
merged with other types of experimental data (e.g., comparing immune cell
populations, as measured with flow cytometry data, with bacterial loads, as
measured from plating and counting CFUs).</p>
<p>Once you have identified the input data type to use for the protocol, you should
identify an example dataset from your laboratory that you can use to create the
protocol. This could be a dataset that you currently need to pre-process, in
which case the development of the protocol will serve a second purpose, allowing
you to complete this task at the same time. However, you may not have a new set
of data of this type that you currently need to pre-process, and in this case
you can build your protocol using a dataset from a previous experiment in your
laboratory. In this case, you may already have a record of the steps that you
used to pre-process the data previously, and these can be helpful as a starting
point as you draft the more thorough pre-processing protocol. You may want to
select an example dataset that you have already published or are getting ready
to publish, so you won’t feel awkard about making the data available for people
to practice with. If you don’t have an example dataset from your own laboratory,
you can explore example datasets that are already available, either as data
included with existing R packages or through open repositories, including those
hosted through national research institutions like the NIH. In this case, be
sure to cite the source of the data and include any available information about
the equipment that was used to collect it, including equipment settings used
when the data were collected.</p>
<p>For the example protocol for this module, we want to pre-process data that were
collected “by hand” by counting CFUs on plates in the laboratory. These counts
were recorded in a plain text delimited file (a csv file) using spreadsheet
software. The spreadsheet was set up to ensure the data can easily be converted
to a “tidy” format, as described in module 2.3. The first few rows of the input
data look like this:</p>
<pre><code>## # A tibble: 6 × 6
##   group replicate dilution_0 dilution_1 dilution_2 dilution_3
##   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;
## 1     2 2-A       26         10                  0          0
## 2     2 2-B       TNTC       52                 10          5
## 3     2 2-C       0          0                   0          0
## 4     3 3-A       0          0                   0          0
## 5     3 3-B       TNTC       TNTC               30         10
## 6     3 3-C       0          0                   0          0</code></pre>
<p>Each row represents the number of bacterial colonies counted after plating a
certain sample, where each sample represents one experimental animal and several
experimental animals (replicates) were considered for each experimental group.
Columns are included with values for the experimental group of the sample
(<code>group</code>), the specific ID of the sample within that experimental group
(<code>replicate</code>, e.g., <code>2-A</code> is mouse A in experimental group 2), and the
colony-forming units (CFUs) counted at each of several dilutions. If a cell has
the value “TNTC”, this indicates that CFUs were too numerous to count for that
sample at that dilution.</p>
<p>When you have identified the input data type you will use for the protocol,
as well as selected an example dataset of this type to use to create the
protocol, you can include a section in the protocol
that describes these input data, what file format they are in, and how they
can be read into R for pre-processing (Figure <a href="3.9-module20.html#fig:protocoldatainput">3.14</a>).</p>
<div class="figure fullwidth"><span style="display:block;" id="fig:protocoldatainput"></span>
<img src="figures/protocol_data_input.png" alt="Providing details on input data in the pre-processing protocol. Once you have an example data file for the type of data that will be input for the protocol, you can add a section that provides the code to read the data into R. You can also add code that will show the first few rows of the example dataset, as well as a description of the data. This figure shows examples of how these elements can be added to an RMarkdown file for a pre-processing protocol, and the associated elements in the final pdf of the protocol, using the example protocol for this module." width="\textwidth"  />
<p class="caption marginnote shownote">
Figure 3.14: Providing details on input data in the pre-processing protocol. Once you have an example data file for the type of data that will be input for the protocol, you can add a section that provides the code to read the data into R. You can also add code that will show the first few rows of the example dataset, as well as a description of the data. This figure shows examples of how these elements can be added to an RMarkdown file for a pre-processing protocol, and the associated elements in the final pdf of the protocol, using the example protocol for this module.
</p>
</div>
<p>For the data output, it often makes sense to plan for data in a format that is
appropriate for data analysis and for merging with other types of data collected
from the experiment. The aim of pre-processing is to get the data from the
format in which they were collected into a format that is meaningful for
combining with other types of data from the experiment and using in statistical
hypothesis testing.</p>
<p>In the example pre-processing protocol, we ultimately
output a simple dataset, with one row for each of the original samples. The
first few rows of this output data are:</p>
<pre><code>## # A tibble: 6 × 3
##   group replicate cfu_in_organ
##   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;
## 1     2 2-A                260
## 2     2 2-B               2500
## 3     2 2-C                  0
## 4     3 3-A                  0
## 5     3 3-B               7500
## 6     3 3-C                  0</code></pre>
<p>For each original sample, an estimate of the CFUs of <em>Mycobacterium
tuberculosis</em> in the full spleen is given (<code>cfu_in_organ</code>). These data
can now be merged with other data collected about each animal in the experiment.
For example, they could be joined with data that provide measures of the
immune cell populations for each animal, to explore if certain immune
cells are associated with bacterial load. They could also be joined with
experimental information and then used in hypothesis testing. For example,
these data could be merged with a table that describes which groups were
controls versus which used a certain vaccine, and then a test could be
conducted exploring evidence that bacterial loads in animals given a
vaccine were lower than in control animals.</p>
<p><strong>Setting up a project directory for the protocol</strong></p>
<p>Once you have decided on the input and output data formats, you will next want
to set up a file directory for storing all the inputs needed in the protocol.
You can include the project files for the protocol in an RStudio Project (see
module 2.6) and post this either publicly or privately on GitHub (see modules
2.9–2.11). This creates a “packet” of everything that a reader needs to use to
recreate what you did—they can download the whole GitHub repository and will
have a nice project directory on their computer with everything they need to try
out the protocol.</p>
<p>Part of the design of the protocol involves deciding on the files that should be
included in this project directory. Figure <a href="3.9-module20.html#fig:protocolprojectfiles">3.15</a>
provides an example of the initial files included in the project directory for
the example protocol for this module. The left side of the figure shows the
files that are initially included, while the left side shows the files in the
project after the code in the protocol is run.</p>
<p>Generally, in the project directory you should include a file with the input
example data, in whatever file format you will usually collect this type of
data. You will also include an RMarkdown file where the protocol is written. If
you are planning to cite articles and other references, you can include a BibTeX
file, with the bibliographical information for each source you plan to cite (see module 3.8).
Finally, if you would like to include photographs or graphics, you can include
these image files in the project directory. Often, you might want to group these
together in a subdirectory of the project named something like “figures”.</p>
<p>Once you run the RMarkdown file for the protocol, you will generate additional
files in the project. Two typical files you will generate will be the output
file for the protocol (in the example, this is output to a pdf file). Usually,
the code in the protocol will also result in output data, which is pre-processed
through the protocol code and written into a file to be used in further
analysis.</p>
<div class="figure"><span style="display:block;" id="fig:protocolprojectfiles"></span>
<p class="caption marginnote shownote">
Figure 3.15: Example of files in the project directory for a data pre-processing protocol. On the left are the files initially included in the project directory for the example protocol for this module. These include a file with the input data (cfu_data.csv), a BibTeX file with bibliographical information for references (example_bib.bib), the RMarkdown file for the protocol (example_protocol.Rmd), and a subdirectory with figures to include in the protocol (figures). On the right is shown the directory after the code in the protocol RMarkdown document is run, which creates an output pdf with the protocol (example_protocol.pdf) as well as the output data (processed_cfu_estimates.csv).
</p>
<img src="figures/protocol_project_files.png" alt="Example of files in the project directory for a data pre-processing protocol. On the left are the files initially included in the project directory for the example protocol for this module. These include a file with the input data (cfu\_data.csv), a BibTeX file with bibliographical information for references (example\_bib.bib), the RMarkdown file for the protocol (example\_protocol.Rmd), and a subdirectory with figures to include in the protocol (figures). On the right is shown the directory after the code in the protocol RMarkdown document is run, which creates an output pdf with the protocol (example\_protocol.pdf) as well as the output data (processed\_cfu\_estimates.csv)." width="\textwidth"  />
</div>
<p><strong>Outlining key tasks in pre-processing the input data.</strong></p>
<p>The next step is to outline the key tasks that are involved in moving from the
data input to the desired data output. For the plating data we are using for our
example, the key tasks to be included in the pre-processing protocol are:</p>
<ol style="list-style-type: decimal">
<li>Read the data into R</li>
<li>Explore the data and perform some quality checks</li>
<li>Identify a “good” dilution for each sample—one at which you have a
countable plate</li>
<li>Estimate the bacterial load in each original sample based on the CFUs counted
at that dilution</li>
<li>Output data with the estimated bacterial load for each sample</li>
</ol>
<p>Once you have this basic design, you can set up the RMarkdown file for the
pre-processing protocol to include a separate section for each task, as well as
an “Overview” section at the beginning to describe the overall protocol, the
data being pre-processed, and the laboratory procedures used to collect those
data. In RMarkdown, you can create first-level section headers by putting the
text for the header on its own line and beginning that line with <code>#</code>, followed
by a space. You should include a blank line before and after the line with this
header text. Figure <a href="3.9-module20.html#fig:protocolsections">3.16</a> shows how this is done in the
example protocol for this module, showing how text in the plain text RMarkdown
file for the protocol align with section headers in the final pdf output of the
protocol.</p>
<div class="figure fullwidth"><span style="display:block;" id="fig:protocolsections"></span>
<img src="figures/protocol_sections.png" alt="Dividing an RMarkdown data pre-processing protocol into sections. This shows an example of creating section headers in a data pre-processing protocol created with RMarkdown, showing section headers in the example pre-procotcol for this module." width="\textwidth"  />
<p class="caption marginnote shownote">
Figure 3.16: Dividing an RMarkdown data pre-processing protocol into sections. This shows an example of creating section headers in a data pre-processing protocol created with RMarkdown, showing section headers in the example pre-procotcol for this module.
</p>
</div>
<p><strong>Adding code for pre-processing.</strong></p>
<p>For many of these steps, you likely have code—or can start drafting the
code—required for that step.
In RMarkdown, you can test this code as you write it. You insert each piece
of executable code within a special section, separated from the regular
text with special characters, as described in previous modules.</p>
<p>For any pre-processing steps that are straightforward (e.g., calculating the
dilution factor in the example module, which requires only simple mathematical
operations), you can directly write in the code required for the step.
For other pre-processing steps, however, the algorithm may be a bit more
complex. For example, complex algorithms have been developed for steps like
peak identification and alignment that are required when
pre-processing data from a mass spectrometer.</p>
<p>For these more complex tasks, you can start to explore available R packages for
performing the task. There are thousands of packages available that extend the
basic functionality of R, providing code implementations of algorithms in a
variety of scientific fields. Many of the R packages relevant for biological
data—especially high-throughput biological data—are available through a
repository called Bioconductor. These packages are all open-source (so you can
explore their code if you want to) and free. You can use vignettes and package
manuals for Bioconductor packages to identify the different functions you can
use for your pre-processing steps. Once you have identified a function for the
task, you can use the helpfile for the function to see how to use it. This help
documentation will allow you to determine all of the function’s parameters and
the choices you can select for each.</p>
<p>You can add each piece of code in the RMarkdown version of the protocol using
the standard method for RMarkdown (module 3.8). Figure <a href="3.9-module20.html#fig:protocolcode">3.17</a>
shows an example from the example protocol for this module. Here, we are using
code to help identify a “good” dilution for counting CFUs for each sample. The
code in included in an executable code chunk, and so it will be run each time
the protocol is rendered. Code comments are included in the code to provide
finer-level details about what the code is doing.</p>
<div class="figure fullwidth"><span style="display:block;" id="fig:protocolcode"></span>
<img src="figures/protocol_code.png" alt="Example of including code in a data pre-processing protocol created with RMarkdown. This figure shows how code can be included in the RMarkdown file for a pre-processing protocol (right), and the corresponding output in the final pdf of the protocol (left), for the code to identify a 'good' dilution for counting CFUs for each sample. Code comments are included to provide finer-level details on the code." width="\textwidth"  />
<p class="caption marginnote shownote">
Figure 3.17: Example of including code in a data pre-processing protocol created with RMarkdown. This figure shows how code can be included in the RMarkdown file for a pre-processing protocol (right), and the corresponding output in the final pdf of the protocol (left), for the code to identify a ‘good’ dilution for counting CFUs for each sample. Code comments are included to provide finer-level details on the code.
</p>
</div>
<p>For each step of the protocol, you can also include potential problems
that might come up in specific instances of the data you get from
future experiments. This can help you adapt the code in the protocol in
thoughtful ways as you apply it in the future to new data collected
for new studies and projects.</p>
</div>
<div id="writing-data-pre-processing-protocols" class="section level3" number="3.9.3">
<h3><span class="header-section-number">3.9.3</span> Writing data pre-processing protocols</h3>
<p>Now that you have planned out the key components of the pre-processing protocol,
you can use RMarkdown’s functionality to flesh it out into a full pre-processing
protocol. This gives you the chance to move beyond a simple code script, and
instead include more thorough descriptions of what you’re doing at each step and
why you’re doing it. You can also include discussions of potential limitations
of the approach that you are taking in the pre-processing, as well as areas
where other research groups might use a different approach. These details can
help when it is time to write the Methods section for the paper describing your
results from an experiment using these data. They can also help your research
group identify pre-processing choices that might differ from other research
groups, which opens the opportunity to perform sensitivity analyses regarding
these pre-processing choices and ensure that your final conclusions are robust
across multiple reasonable pre-processing approaches.</p>
<p>Protocols are common for wet lab techniques, where they provide a “recipe” that
ensures consistency and reproducibility in those processes. Computational tasks,
including data pre-processing, can also be standardized through the creation and
use of protocol in your research group. While code scripts are becoming more
common as a means of recording data pre-processing steps, they are often not
as clear as a traditional protocol, in particular in terms of providing a
thorough description of what is being done at each step and why it is being
done that way. Data pre-processing protocols can provide these more thorough
descriptions, and by creating them with RMarkdown or with similar types
of “knitted” documents (modules 3.7 and 3.8), you can combine the executable code
used to pre-process the data with extensive documentation. As a further
advantage, the creation of these protocols will ensure that your research
group has thought carefully about each step of the process, rather than
relying on cobbling together bits and pieces of code they’ve found but don’t
fully understand. Just as the creation of a research protocol for a
clinical trial requires a careful consideration of each step of the ultimate
trial <span class="citation">(Al-JunDi and SAkkA 2016)</span>, the creation of data pre-processing protocols ensure
that each step in the process is carefully considered, and so helps to
ensure that each step of this process is conducted as carefully as the
steps taken in designing the experiment as a whole and each wet lab technique
conducted for the experiment.</p>
<p><label for="tufte-mn-3" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-3" class="margin-toggle"><span class="marginnote"><span style="display: block;">“Writing a research proposal is probably one of the most challenging
and difficult task as research is a new area for the majority of
postgraduates and new researchers. … Protocol writing allows the
researcher to review and critically evaluate the published literature on
the interested topic, plan and review the project steps and serves as a
guide throughout the investigation.”</span>
<span style="display: block;"><span class="citation"><span class="citation">(Al-JunDi and SAkkA 2016)</span></span></span></span></p>
<p>A data pre-processing protocol, in the sense we use it here, is essentially an
annotated recipe for each step in preparing your data from the initial, “raw”
state that is output from the laboratory equipment (or collected by hand) to a
state that is useful for answering important research questions. The exact
implementation of each step is given in code that can be re-used and adapted
with new data of a similar format. However, the code script is often not enough
to helpfully understand, share, and collaborate on the process. Instead, it’s
critical to also include descriptions written by humans and for humans. These
annotations can include descriptions of the code and how certain parameters are
standardized the algorithms in the code. They can also be used to justify
choices, and link them up both with characteristics of the data and equipment
for your experiment as well as with scientific principles that underlie the
choices. Protocols like this are critical to allow you to standardize the
process you use across many samples from one experiment, across different
experiments and projects in your research laboratory, and even across different
research laboratories.</p>
<p>As you begin adding text to your pre-processing protocol, you should keep in
mind these general aims. First, a good protocol provides adequate detail that
another researcher can fully reproduce the procedure <span class="citation">(Al-JunDi and SAkkA 2016)</span>. For a
protocol for a trial or wet lab technique, this means that the protocol should
allow another researcher to reproduce the process and get results that are
<em>comparable</em> to your results <span class="citation">(Al-JunDi and SAkkA 2016)</span>; for a data pre-processing
protocol, the protocol must include adequate details that another researcher,
provided they start with the same data, gets <em>identical</em> results (short of any
pre-processing steps that include some element of sampling or random-number
generation, e.g., Monte Carlo methods). This idea—being able to exactly
re-create the computational results from an earlier project—is referred to as
<strong>computational reproducibility</strong> and is considered a key component in
ensuring that research is fully reproducible.</p>
<p><label for="tufte-mn-4" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-4" class="margin-toggle"><span class="marginnote"><span style="display: block;">“Now, all scientific research involves the use of powerful computers,
whether it is for the data collection, the data analysis, or both. … We
are all computational scientists now, and thus the concept of
reproducibility is relevant to all scientists.”</span>
<span style="display: block;"><span class="citation"><span class="citation">(R. D. Peng and Hicks 2021)</span></span></span></span></p>
<p>By creating the data pre-processing protocol as a knitted document
using a tool like RMarkdown (modules 3.7 and 3.8), you can ensure that the protocol is
computationally reproducible. In an RMarkdown document, you include the code
examples as <em>executable</em> code—this means that the code is run every time you
render the document. You are therefore “checking” your code every time that you
run it. As the last step of your pre-processing protocol, you should output the
copy of the pre-processed data that you will use for any further analysis for
the project. You can use functions in R to output this to a plain text format,
for example a comma-separated delimited file (modules 2.4 and 2.5). Each time you render
the protocol, you will re-write this output file, and so this provides assurance
that the code in your protocol can be used to reproduce your output data (since
that’s how you yourself created that form of the data).</p>
<p>Figure <a href="3.9-module20.html#fig:protocoloutput">3.18</a> provides an example from the example protocol
for this module. The RMarkdown file for the protocol includes code to write out
the final, pre-processed data to a comma-separated plain text file called
“processed_cfu_estimates.csv”. This code writes the output file into the same
directory where you’ve saved the RMarkdown file. Each time the RMarkdown file is
rendered to create the pdf version of the protocol, the input data will be
pre-processed from scratch, using the code throughout the protocol, and this
file will be overwritten with the data generated. This guarantees that the code
in the protocol can be used by anyone—you or other researchers—to reproduce
the final data from the protocol, and so guarantees that these data are
computationally reproducible.</p>
<div class="figure fullwidth"><span style="display:block;" id="fig:protocoloutput"></span>
<img src="figures/protocol_output_data.png" alt="Example of using code in pre-processing protocol to output the final, pre-processed data that will be used in further analysis for the research project. This example comes from the example protocol for this module, showing both the executable code included in the RMarkdown file for the protocol (right) and how this code is included in the final pdf of the protocol. Outputting the pre-processed data into a plain text file as the last step of the protocol helps ensure computational reproducibility for this step of working with experimental data." width="\textwidth"  />
<p class="caption marginnote shownote">
Figure 3.18: Example of using code in pre-processing protocol to output the final, pre-processed data that will be used in further analysis for the research project. This example comes from the example protocol for this module, showing both the executable code included in the RMarkdown file for the protocol (right) and how this code is included in the final pdf of the protocol. Outputting the pre-processed data into a plain text file as the last step of the protocol helps ensure computational reproducibility for this step of working with experimental data.
</p>
</div>
<p>In your data pre-processing protocol, show the code that you use to implement
this choice and also explain clearly in the text why you made this choice and
what alternatives should be considered if data characteristics are different.
Write this as if you are explaining to a new research group member (or your
future self) how to think about this step in the pre-processing, why you’re
doing it the way your doing it, and what code is used to do it that way. You
should also include references that justify choices when they are
available—include these using BibTeX (module 3.8). By doing this, you will make it much
easier on yourself when you write the Methods section of papers that report on
the data you have pre-processed, as you’ll already have draft information on
your pre-processing methods in your protocol.</p>
<p>Good protocols include not only <em>how</em> (for data pre-processing protocols, this
is the code), but also <em>why</em> each step is taken. This includes explanations that are both higher-level
(i.e., why a larger question is being asked) and also at a fine level, for each
step in the process. A protocol should include some background, the
aims of the work, hypotheses to be tested, materials and methods, methods of
data collection and equipment to analyze samples <span class="citation">(Al-JunDi and SAkkA 2016)</span>.</p>
<p>This step of documentation and explanation is very important to creating a
useful data pre-processing protocol. Yes, the code itself allows someone else to
replicate what you did. However, only those who are very, very familiar with the
software program, including any of the extension packages you include, can
“read” the code directly to understand what it’s doing. Further, even if you
understand the code very well when you create it, it is unlikely that you will
stay at that same level of comprehension in the future, as other tasks and
challenges take over that brain space. Explaining for humans, in text that
augments and accompanies the code, is also important because function names and
parameter names in code often are not easy to decipher. While excellent
programmers can sometimes create functions with clear and transparent names,
easy to translate to determine the task each is doing, this is difficult in
software development and is rare in practice. Human annotations, written by and
for humans, are critical to ensure that the steps will be clear to you and
others in the future when you revisit what was done with this data and what you
plan to do with future data.</p>
<p>The process of writing a protocol in this way forces you to think about each
step in the process, why you do it a certain way (include parameters you choose
for certain functions in a pipeline of code), and include justifications from
the literature for this reasoning. If done well, it should allow you to quickly
and thoroughly write the associated sections of Methods in research reports and
manuscripts and help you answer questions and challenges from reviewers. Writing
the protocol will also help you identify steps for which you are uncertain how
to proceed and what choices to make in customizing an analysis for your research
data. These are areas where you can search more deeply in the literature to
understand implications of certain choices and, if needed, contact the
researchers who developed and maintained associated software packages to get
advice.</p>
<p>For example, the example protocol for this module explains how to pre-process
data collected from counting CFUs after plating serial dilutions of samples. One
of the steps of pre-processing is to identify a dilution for each sample at
which you have a “countable” plate. The protocol includes an explanation of why
it is important to identify the dilution for a countable plate and also gives
the rules that are used to pick a dilution for each sample, before including the
code that implements those rules. This allows the protocol to provide research
group members with the logic behind the pre-processing, so that they can adapt
if needed in future experiments. For example, the count range of CFUs used for
the protocol to find a good dilution is about a quarter of the typically
suggested range for this process, and this is because this experiment plated
each sample on a quarter of a plate, rather than using the full plate. By
explaining this reasoning, in the future the protocol could be adapted when
using a full plate rather than a quarter of a plate for each sample.</p>
<p>One tool in Rmarkdown that is helpful for this process is its built-in
referencing system. In the previous module, we showed how you can include
bibliographical references in an Rmarkdown file. When you write a protocol
within RMarkdown, you can include references in this way to provide background
and support as you explain why you are conducting each step of the
pre-processing. Figure <a href="3.9-module20.html#fig:protocolreferences">3.19</a> shows an example of the
elements you use to do this, showing each element in the example protocol for
this module.</p>
<div class="figure fullwidth"><span style="display:block;" id="fig:protocolreferences"></span>
<img src="figures/protocol_references.png" alt="Including references in a data pre-processing protocol created with RMarkdown. RMarkdown has a built-in referencing system that you can use, based on the BibTeX system for LaTeX. This figure shows examples from the example protocol for this module of the elements used for referencing. You create a BibTeX file with information about each reference, and then use the key for the reference within the text to cite that reference. All cited references will be printed at the end of the document; you can chose the header that you want for this reference section in the RMarkdown file ('References' in this example). In the YAML of the RMarkdown file, you specify the path to the BibTeX file (with the 'bibliography: ' key), so it can be linked in when the RMarkdown file is rendered." width="\textwidth"  />
<p class="caption marginnote shownote">
Figure 3.19: Including references in a data pre-processing protocol created with RMarkdown. RMarkdown has a built-in referencing system that you can use, based on the BibTeX system for LaTeX. This figure shows examples from the example protocol for this module of the elements used for referencing. You create a BibTeX file with information about each reference, and then use the key for the reference within the text to cite that reference. All cited references will be printed at the end of the document; you can chose the header that you want for this reference section in the RMarkdown file (‘References’ in this example). In the YAML of the RMarkdown file, you specify the path to the BibTeX file (with the ‘bibliography:’ key), so it can be linked in when the RMarkdown file is rendered.
</p>
</div>
<p>Other helpful tools in RMarkdown are tools for creating equations and tables. As
described in the previous module, RMarkdown includes a number of formatting
tools. You can create simple tables through basic formatting, or more complex
tables using add-on packages like <code>kableExtra</code>. Math can be typeset using
conventions developed in the LaTeX mark-up language. The previous module
provided advice and links to resources on using these types of tools. Figure
<a href="3.9-module20.html#fig:protocolequations">3.20</a> gives an example of them in use within the example
protocol for this module.</p>
<div class="figure fullwidth"><span style="display:block;" id="fig:protocolequations"></span>
<img src="figures/protocol_equations_tables.png" alt="Example of including tables and equations in an RMarkdown data pre-processing protocol." width="\textwidth"  />
<p class="caption marginnote shownote">
Figure 3.20: Example of including tables and equations in an RMarkdown data pre-processing protocol.
</p>
</div>
<p>You can also include figures, either figures created in R or outside figure files.
Any figures that are created by code in the RMarkdown document will automatically
be included in the protocol. For other graphics, you can include image files
(e.g., png and jpeg files) using the <code>include_graphics</code> function from the
<code>knitr</code> package. You can use options in the code chunk options to specify
the size of the figure in the document and to include a figure caption. The
figures will be automatically numbered in the order they appear in the protocol.</p>
<p>Figure <a href="3.9-module20.html#fig:protocolfigures">3.21</a> shows an example of how external figure
files were included in the example protocol. In this case, the functionality
allowed us to include an overview graphic that we created in PowerPoint and
saved as an image as well as a photograph taken by a member of our research
group.</p>
<div class="figure fullwidth"><span style="display:block;" id="fig:protocolfigures"></span>
<img src="figures/protocol_figures.png" alt="Example of including figures from image files in an RMarkdown data pre-processing protocol." width="\textwidth"  />
<p class="caption marginnote shownote">
Figure 3.21: Example of including figures from image files in an RMarkdown data pre-processing protocol.
</p>
</div>
<p>Finally, you can try out even more complex functionality for RMarkdown as you
continue to build data pre-processing protocols for your research group. Figure
<a href="3.9-module20.html#fig:protocolyaml">3.22</a> shows an example of using R code within the YAML of the
example protocol for this module; this allows us to include a “Last edited” date
that is updated with the day’s date each time the protocol is re-rendered.</p>
<div class="figure fullwidth"><span style="display:block;" id="fig:protocolyaml"></span>
<img src="figures/protocol_yaml_date.png" alt="Example of using more advanced RMarkdown functionality within a data pre-processing protocol. In this example, R code is incorporated into the YAML of the document to include the date that the document was last rendered, marking this on the pdf output as the *Last edited* date of the protocol." width="\textwidth"  />
<p class="caption marginnote shownote">
Figure 3.22: Example of using more advanced RMarkdown functionality within a data pre-processing protocol. In this example, R code is incorporated into the YAML of the document to include the date that the document was last rendered, marking this on the pdf output as the <em>Last edited</em> date of the protocol.
</p>
</div>
</div>
<div id="applied-exercise-2" class="section level3" number="3.9.4">
<h3><span class="header-section-number">3.9.4</span> Applied exercise</h3>
<p>To wrap up this module, try downloading both the source file and the output of this example
data pre-processing protocol. Again, you can find the source code (the RMarkdown file)
<a href="https://raw.githubusercontent.com/geanders/improve_repro/master/data/bactcountr_example_data/example_protocol.Rmd">here</a> and the output file <a href="https://github.com/geanders/improve_repro/raw/master/data/bactcountr_example_data/example_protocol.pdf">here</a>. If you would like to try re-running the file, you can get all the additional files
you’ll need (the original data file, figure files, etc.) <a href="https://github.com/geanders/improve_repro/tree/master/data/bactcountr_example_data">here</a>. See if
you can compare the elements of the RMarkdown file with the output they produce in the
PDF file. Read through the descriptions of the protocol. Do you think that you could recreate
the process if your laboratory ran a new experiment that involved plating samples to
estimate bacterial load?</p>

<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div class="csl-entry">
Al-JunDi, AzzAm, and SAlAh SAkkA. 2016. <span>“Protocol Writing in Clinical Research.”</span> <em>Journal of Clinical and Diagnostic Research: JCDR</em> 10 (11): ZE10.
</div>
<div class="csl-entry">
AlTarawneh, Ghada, and Simon Thorne. 2017. <span>“A Pilot Study Exploring Spreadsheet Risk in Scientific Research.”</span> <em>arXiv Preprint arXiv:1703.09785</em>.
</div>
<div class="csl-entry">
Altman, Douglas G., and J. Martin Bland. 1997. <span>“Statistical Notes: Units of Analysis.”</span> <em>BMJ</em> 314: 1874.
</div>
<div class="csl-entry">
Altschul, Stephen, Barry Demchak, Richard Durbin, Robert Gentleman, Martin Krzywinski, Heng Li, Anton Nekrutenko, et al. 2013. <span>“The Anatomy of Successful Computational Biology Software.”</span> <em>Nature Biotechnology</em> 31 (10): 894–97.
</div>
<div class="csl-entry">
Anderson, Nicholas R, E Sally Lee, J Scott Brockenbrough, Mark E Minie, Sherrilynne Fuller, James Brinkley, and Peter Tarczy-Hornoch. 2007. <span>“Issues in Biomedical Research Data Management and Analysis: Needs and Barriers.”</span> <em>Journal of the American Medical Informatics Association</em> 14 (4): 478–88.
</div>
<div class="csl-entry">
Arnold, Taylor. 2017. <span>“<span class="nocase">A Tidy Data Model for Natural Language Processing using cleanNLP</span>.”</span> <em><span>The R Journal</span></em> 9 (2): 248–67.
</div>
<div class="csl-entry">
Bacher, Rhonda, Li-Fang Chu, Ning Leng, Audrey P Gasch, James A Thomson, Ron M Stewart, Michael Newton, and Christina Kendziorski. 2017. <span>“SCnorm: Robust Normalization of Single-Cell RNA-Seq Data.”</span> <em>Nature Methods</em> 14 (6): 584–86.
</div>
<div class="csl-entry">
Baker, Monya. 2016. <span>“How Quality Control Could Save Your Science.”</span> <em>Nature</em> 529 (7587): 456–59.
</div>
<div class="csl-entry">
Barga, Roger, Bill Howe, David Beck, Stuart Bowers, William Dobyns, Winston Haynes, Roger Higdon, et al. 2011. <span>“Bioinformatics and Data-Intensive Scientific Discovery in the Beginning of the 21st Century.”</span> <em>Omics: A Journal of Integrative Biology</em> 15 (4): 199–201.
</div>
<div class="csl-entry">
Barnett, David, Brooke Walker, Alan Landay, and Thomas N Denny. 2008. <span>“CD4 Immunophenotyping in HIV Infection.”</span> <em>Nature Reviews Microbiology</em> 6 (11): S7–15.
</div>
<div class="csl-entry">
Barry, Clifton E, and Maija S Cheung. 2009. <span>“New Tactics Against Tuberculosis.”</span> <em>Scientific American</em> 300 (3): 62–69.
</div>
<div class="csl-entry">
Bass, Andrew J., David G. Robinson, Steve Lianoglou, Emily Nelson, John D. Storey, and with contributions from Laurent Gatto. 2020. <em>Biobroom: Turn Bioconductor Objects into Tidy Data Frames</em>. <a href="https://github.com/StoreyLab/biobroom">https://github.com/StoreyLab/biobroom</a>.
</div>
<div class="csl-entry">
Baumer, Ben. 2015. <span>“A Data Science Course for Undergraduates: Thinking with Data.”</span> <em>The American Statistician</em> 69 (4): 334–42.
</div>
<div class="csl-entry">
Baumer, Benjamin S, Daniel T Kaplan, and Nicholas J Horton. 2017. <em>Modern Data Science with r</em>. Boca Raton: CRC Press.
</div>
<div class="csl-entry">
Ben-David, Avishai, and Charles E Davidson. 2014. <span>“Estimation Method for Serial Dilution Experiments.”</span> <em>Journal of Microbiological Methods</em> 107: 214–21.
</div>
<div class="csl-entry">
Benoist, Christophe, and Nir Hacohen. 2011. <span>“Flow Cytometry, Amped Up.”</span> <em>Science</em> 332 (6030): 677–78.
</div>
<div class="csl-entry">
Bertin, Audrey M, and Benjamin S Baumer. 2021. <span>“Creating Optimal Conditions for Reproducible Data Analysis in r with Fertile.”</span> <em>Stat</em> 10 (1): e332.
</div>
<div class="csl-entry">
Birch, David, David Lyford-Smith, and Yike Guo. 2018. <span>“The Future of Spreadsheets in the Big Data Era.”</span> <em>arXiv Preprint arXiv:1801.10231</em>.
</div>
<div class="csl-entry">
Blischak, John D, Peter Carbonetto, and Matthew Stephens. 2019. <span>“Creating and Sharing Reproducible Research Code the Workflowr Way.”</span> <em>F1000Research</em> 8: 1749.
</div>
<div class="csl-entry">
Blischak, John D, Emily R Davenport, and Greg Wilson. 2016. <span>“A Quick Introduction to Version Control with Git and GitHub.”</span> <em>PLoS Computational Biology</em> 12 (1).
</div>
<div class="csl-entry">
Brazma, Alvis, Maria Krestyaninova, and Ugis Sarkans. 2006. <span>“Standards for Systems Biology.”</span> <em>Nature Reviews Genetics</em> 7 (8): 593.
</div>
<div class="csl-entry">
Broman, Karl W, and Kara H Woo. 2018. <span>“Data Organization in Spreadsheets.”</span> <em>The American Statistician</em> 72 (1): 2–10.
</div>
<div class="csl-entry">
Brown, Zack. 2018. <span>“A Git Origin Story.”</span> <em>Linux Journal</em>.
</div>
<div class="csl-entry">
Bryan, Jennifer. 2018. <span>“Excuse Me, Do You Have a Moment to Talk about Version Control?”</span> <em>The American Statistician</em> 72 (1): 20–27.
</div>
<div class="csl-entry">
Bryan, Jennifer, and Hadley Wickham. 2017. <span>“Data Science: A Three Ring Circus or a Big Tent?”</span> <em>Journal of Computational and Graphical Statistics</em> 26 (4): 784–85.
</div>
<div class="csl-entry">
Buffalo, Vince. 2015. <em>Bioinformatics Data Skills: Reproducible and Robust Research with Open Source Tools</em>. " O’Reilly Media, Inc.".
</div>
<div class="csl-entry">
Burns, Patrick. 2011. <em>The r Inferno</em>. Lulu. com.
</div>
<div class="csl-entry">
Butler, Declan. 2005. <span>“Electronic Notebooks: A New Leaf.”</span> <em>Nature</em> 436 (7047): 20–22.
</div>
<div class="csl-entry">
Campbell-Kelly, Martin. 2007. <span>“Number Crunching Without Programming: The Evolution of Spreadsheet Usability.”</span> <em>IEEE Annals of the History of Computing</em> 29 (3): 6–19.
</div>
<div class="csl-entry">
Chatfield, Chris. 1995. <em>Problem Solving: A Statistician’s Guide</em>. CRC Press.
</div>
<div class="csl-entry">
Chen, Yunshun, Davis McCarthy, Mark Robinson, and Gordon K Smyth. 2014. <span>“edgeR: Differential Expression Analysis of Digital Gene Expression Data User’s Guide.”</span> <em>Bioconductor User’s Guide. Available Online: Http://Www. Bioconductor. Org/Packages/Release/Bioc/Vignettes/edgeR/Inst/Doc/edgeRUsersGuide.pdf (Accessed on 15 February 2021)</em>.
</div>
<div class="csl-entry">
Creeth, Richard. 1985. <span>“Microcomputer Spreadsheets: Their Uses and Abuses.”</span> <em>Journal of Accountancy (Pre-1986)</em> 159 (000006): 90.
</div>
<div class="csl-entry">
Edwards, Paul N, Matthew S Mayernik, Archer L Batcheller, Geoffrey C Bowker, and Christine L Borgman. 2011. <span>“Science Friction: Data, Metadata, and Collaboration.”</span> <em>Social Studies of Science</em> 41 (5): 667–90.
</div>
<div class="csl-entry">
Ellis, Shannon E, and Jeffrey T Leek. 2018. <span>“How to Share Data for Collaboration.”</span> <em>The American Statistician</em> 72 (1): 53–57.
</div>
<div class="csl-entry">
Flicek, Paul, and Ewan Birney. 2009. <span>“Sense from Sequence Reads: Methods for Alignment and Assembly.”</span> <em>Nature Methods</em> 6 (Suppl 11): S6–12.
</div>
<div class="csl-entry">
Fox, Amy, Taru S Dutt, Burton Karger, Mauricio Rojas, Andrés Obregón-Henao, G Brooke Anderson, and Marcela Henao-Tamayo. 2020. <span>“Cyto-Feature Engineering: A Pipeline for Flow Cytometry Analysis to Uncover Immune Populations and Associations with Disease.”</span> <em>Scientific Reports</em> 10 (1): 1–12.
</div>
<div class="csl-entry">
Gatto, Laurent. 2013. <span>“MSnbase Development.”</span>
</div>
<div class="csl-entry">
Ghosh, Samik, Yukiko Matsuoka, Yoshiyuki Asai, Kun-Yi Hsin, and Hiroaki Kitano. 2011. <span>“Software for Systems Biology: From Tools to Integrated Platforms.”</span> <em>Nature Reviews Genetics</em> 12 (12): 821.
</div>
<div class="csl-entry">
Gibb, Bruce C. 2014. <span>“Reproducibility.”</span> <em>Nature Chemistry</em> 6 (8): 653–54.
</div>
<div class="csl-entry">
Giles, Jim. 2012. <span>“The Digital Lab: Lab-Management Software and Electronic Notebooks Are Here–and This Time, It’s More Than Just Talk.”</span> <em>Nature</em> 481 (7382): 430–32.
</div>
<div class="csl-entry">
Gillespie, Colin, and Robin Lovelace. 2016. <em>Efficient r Programming: A Practical Guide to Smarter Programming</em>. " O’Reilly Media, Inc.".
</div>
<div class="csl-entry">
Goodman, Alyssa, Alberto Pepe, Alexander W Blocker, Christine L Borgman, Kyle Cranmer, Merce Crosas, Rosanne Di Stefano, et al. 2014. <span>“Ten Simple Rules for the Care and Feeding of Scientific Data.”</span> Public Library of Science.
</div>
<div class="csl-entry">
Hamming, Richard R. 1997. <em>The Art of Doing Science and Engineering: Learning to Learn</em>. CRC Press.
</div>
<div class="csl-entry">
Haque, Ashraful, Jessica Engel, Sarah A Teichmann, and Tapio Lönnberg. 2017. <span>“A Practical Guide to Single-Cell RNA-Sequencing for Biomedical Research and Clinical Applications.”</span> <em>Genome Medicine</em> 9 (1): 1–12.
</div>
<div class="csl-entry">
Hermans, Felienne, Bas Jansen, Sohon Roy, Efthimia Aivaloglou, Alaaeddin Swidan, and David Hoepelman. 2016. <span>“Spreadsheets Are Code: An Overview of Software Engineering Approaches Applied to Spreadsheets.”</span> In <em>2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)</em>, 5:56–65. IEEE.
</div>
<div class="csl-entry">
Hermans, Felienne, and Emerson Murphy-Hill. 2015. <span>“Enron’s Spreadsheets and Related Emails: A Dataset and Analysis.”</span> In <em>2015 IEEE/ACM 37th IEEE International Conference on Software Engineering</em>, 2:7–16. IEEE.
</div>
<div class="csl-entry">
Hicks, Stephanie C, and Rafael A Irizarry. 2017. <span>“A Guide to Teaching Data Science.”</span> <em>The American Statistician</em> In Press. <a href="https://doi.org/10.1080/00031305.2017.1356747">https://doi.org/10.1080/00031305.2017.1356747</a>.
</div>
<div class="csl-entry">
Hicks, Stephanie C, Ruoxi Liu, Yuwei Ni, Elizabeth Purdom, and Davide Risso. 2021. <span>“Mbkmeans: Fast Clustering for Single Cell Data Using Mini-Batch k-Means.”</span> <em>PLOS Computational Biology</em> 17 (1): e1008625.
</div>
<div class="csl-entry">
Holmes, Susan, and Wolfgang Huber. 2018. <em>Modern Statistics for Modern Biology</em>. Cambridge University Press.
</div>
<div class="csl-entry">
Hsieh, TC, KH Ma, and Anne Chao. 2016. <span>“<span class="nocase">iNEXT: an R package for rarefaction and extrapolation of species diversity (Hill numbers)</span>.”</span> <em>Methods in Ecology and Evolution</em> 7 (12): 1451–56.
</div>
<div class="csl-entry">
Huber, Wolfgang, Vincent J Carey, Robert Gentleman, Simon Anders, Marc Carlson, Benilton S Carvalho, Hector Corrada Bravo, et al. 2015. <span>“Orchestrating High-Throughput Genomic Analysis with Bioconductor.”</span> <em>Nature Methods</em> 12 (2): 115.
</div>
<div class="csl-entry">
Ilicic, Tomislav, Jong Kyoung Kim, Aleksandra A Kolodziejczyk, Frederik Otzen Bagger, Davis James McCarthy, John C Marioni, and Sarah A Teichmann. 2016. <span>“Classification of Low Quality Cells from Single-Cell RNA-Seq Data.”</span> <em>Genome Biology</em> 17 (1): 1–15.
</div>
<div class="csl-entry">
Irizarry, Rafael A., and Michael I. Love. 2016. <em>Data Analysis for the Life Sciences with r</em>. Chapman; Hall.
</div>
<div class="csl-entry">
Irving, Francis. 2011. <span>“Astonishments, Ten, in the History of Version Control.”</span> <a href="https://www.flourish.org/2011/12/astonishments-ten-in-the-history-of-version-control/">https://www.flourish.org/2011/12/astonishments-ten-in-the-history-of-version-control/</a>.
</div>
<div class="csl-entry">
Janssens, Jeroen. 2014. <em>Data Science at the Command Line: Facing the Future with Time-Tested Tools</em>. " O’Reilly Media, Inc.".
</div>
<div class="csl-entry">
Johnston, Luke. 2022. <em>Prodigenr: Research Project Directory Generator</em>. <a href="https://CRAN.R-project.org/package=prodigenr">https://CRAN.R-project.org/package=prodigenr</a>.
</div>
<div class="csl-entry">
Judkins, Rod. 2016. <em>The Art of Creative Thinking</em>. Perigee.
</div>
<div class="csl-entry">
Kaplan, Daniel. 2018. <span>“Teaching Stats for Data Science.”</span> <em>The American Statistician</em> 72 (1): 89–96.
</div>
<div class="csl-entry">
Keller, Sallie, Gizem Korkmaz, Mark Orr, Aaron Schroeder, and Stephanie Shipp. 2017. <span>“The Evolution of Data Quality: Understanding the Transdisciplinary Origins of Data Quality Concepts and Approaches.”</span> <em>Annu. Rev. Stat. Appl</em> 4: 85–108.
</div>
<div class="csl-entry">
Kernighan, Brian W. 2011. <em>D Is for Digital: What a Well-Informed Person Should Know about Computers and Communications</em>. CreateSpace Independent Publishing Platform.
</div>
<div class="csl-entry">
Kernighan, Brian W, and Rob Pike. 1984. <em>The UNIX Programming Environment</em>. Vol. 270. Prentice-Hall Englewood Cliffs, NJ.
</div>
<div class="csl-entry">
Klemens, Ben. 2014. <em>21st Century c: C Tips from the New School</em>. " O’Reilly Media, Inc.".
</div>
<div class="csl-entry">
Krishnan, Sanjay, Daniel Haas, Michael J Franklin, and Eugene Wu. 2016. <span>“Towards Reliable Interactive Data Cleaning: A User Survey and Recommendations.”</span> In <em>Proceedings of the Workshop on Human-in-the-Loop Data Analytics</em>, 9. ACM.
</div>
<div class="csl-entry">
Kwok, Roberta. 2018. <span>“Lab Notebooks Go Digital.”</span> <em>Nature</em> 560 (7717): 269–70.
</div>
<div class="csl-entry">
Lawrence, Michael, and Martin Morgan. 2014. <span>“Scalable Genomics with r and Bioconductor.”</span> <em>Statistical Science: A Review Journal of the Institute of Mathematical Statistics</em> 29 (2): 214.
</div>
<div class="csl-entry">
LEIPS, JEFF. 2010. <span>“At the Helm: Leading Your Laboratory.”</span> <em>Genetics Research</em> 92 (4): 325–26.
</div>
<div class="csl-entry">
Levy, Steven. 1984. <span>“A Spreadsheet Way of Knowledge.”</span> <em>Harpers</em> 269: 58–64.
</div>
<div class="csl-entry">
Lithgow, Gordon J, Monica Driscoll, and Patrick Phillips. 2017. <span>“A Long Journey to Reproducible Results.”</span> <em>Nature</em> 548 (7668): 387–88.
</div>
<div class="csl-entry">
Lowndes, Julia S Stewart, Benjamin D Best, Courtney Scarborough, Jamie C Afflerbach, Melanie R Frazier, Casey C O’Hara, Ning Jiang, and Benjamin S Halpern. 2017. <span>“Our Path to Better Science in Less Time Using Open Data Science Tools.”</span> <em>Nature Ecology &amp; Evolution</em> 1 (6): 160.
</div>
<div class="csl-entry">
Lynch, Clifford. 2008. <span>“Big Data: How Do Your Data Grow?”</span> <em>Nature</em> 455 (7209): 28.
</div>
<div class="csl-entry">
Madhavan, Guru. 2015. <em>Applied Minds: How Engineers Think</em>. W. W. Norton.
</div>
<div class="csl-entry">
Maecker, Holden T, J Philip McCoy, and Robert Nussenblatt. 2012. <span>“Standardizing Immunophenotyping for the Human Immunology Project.”</span> <em>Nature Reviews Immunology</em> 12 (3): 191–200.
</div>
<div class="csl-entry">
Majumder, Erica L-W, Elizabeth M Billings, H Paul Benton, Richard L Martin, Amelia Palermo, Carlos Guijas, Markus M Rinschen, et al. 2021. <span>“Cognitive Analysis of Metabolomics Data for Systems Biology.”</span> <em>Nature Protocols</em> 16 (3): 1376–1418.
</div>
<div class="csl-entry">
Mak, H Craig. 2011. <span>“John Storey.”</span> <em>Nature Biotechnology</em> 29 (4): 331–33.
</div>
<div class="csl-entry">
Mangiola, Stefano, Ramyar Molania, Ruining Dong, Maria A Doyle, and Anthony T Papenfuss. 2021. <span>“Tidybulk: An r Tidy Framework for Modular Transcriptomic Data Analysis.”</span> <em>Genome Biology</em> 22: 1–15.
</div>
<div class="csl-entry">
Marwick, Ben, Carl Boettiger, and Lincoln Mullen. 2018. <span>“Packaging Data Analytical Work Reproducibly Using <span>R</span> (and Friends).”</span> <em>The American Statistician</em> 72 (1): 80–88.
</div>
<div class="csl-entry">
Mascarelli, Amanda. 2014. <span>“Research Tools: Jump Off the Page.”</span> <em>Nature</em> 507 (7493): 523–25.
</div>
<div class="csl-entry">
McCarthy, Davis J, Kieran R Campbell, Aaron TL Lun, and Quin F Wills. 2017. <span>“Scater: Pre-Processing, Quality Control, Normalization and Visualization of Single-Cell RNA-Seq Data in r.”</span> <em>Bioinformatics</em> 33 (8): 1179–86.
</div>
<div class="csl-entry">
McCullough, B D, and Berry Wilson. 2002. <span>“On the Accuracy of Statistical Procedures in Microsoft Excel 2000 and Excel XP.”</span> <em>Computational Statistics &amp; Data Analysis</em> 40 (4): 713–21.
</div>
<div class="csl-entry">
McCullough, BD. 2001. <span>“Does Microsoft Fix Errors in Excel?”</span> In <em>Proceedings of the 2001 Joint Statistical Meetings</em>.
</div>
<div class="csl-entry">
McCullough, Bruce D. 1999. <span>“Assessing the Reliability of Statistical Software: Part II.”</span> <em>The American Statistician</em> 53 (2): 149–59.
</div>
<div class="csl-entry">
McCullough, Bruce D, and David A Heiser. 2008. <span>“On the Accuracy of Statistical Procedures in Microsoft Excel 2007.”</span> <em>Computational Statistics &amp; Data Analysis</em> 52 (10): 4570–78.
</div>
<div class="csl-entry">
McCullough, Bruce D, and Berry Wilson. 1999. <span>“On the Accuracy of Statistical Procedures in Microsoft Excel 97.”</span> <em>Computational Statistics &amp; Data Analysis</em> 31 (1): 27–37.
</div>
<div class="csl-entry">
———. 2005. <span>“On the Accuracy of Statistical Procedures in Microsoft Excel 2003.”</span> <em>Computational Statistics &amp; Data Analysis</em> 49 (4): 1244–52.
</div>
<div class="csl-entry">
McMurdie, Paul J, and Susan Holmes. 2013. <span>“Phyloseq: An <span>R</span> Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data.”</span> <em>PloS One</em> 8 (4): e61217.
</div>
<div class="csl-entry">
McNamara, Amelia. 2016. <span>“On the State of Computing in Statistics Education: Tools for Learning and for Doing.”</span> <em>arXiv Preprint arXiv:1610.00984</em>.
</div>
<div class="csl-entry">
Mélard, Guy. 2014. <span>“On the Accuracy of Statistical Procedures in Microsoft Excel 2010.”</span> <em>Computational Statistics</em> 29 (5): 1095–1128.
</div>
<div class="csl-entry">
Metz, Cade. 2015. <span>“How GitHub Conquered Google, Microsoft, and Everyone Else.”</span> <em>Wired Magazine</em>.
</div>
<div class="csl-entry">
Michener, William K. 2015. <span>“Ten Simple Rules for Creating a Good Data Management Plan.”</span> <em>PLoS Computational Biology</em> 11 (10): e1004525.
</div>
<div class="csl-entry">
Murrell, Paul. 2009. <em>Introduction to Data Technologies</em>. Chapman; Hall/CRC.
</div>
<div class="csl-entry">
Myneni, Sahiti, and Vimla L Patel. 2010. <span>“Organization of Biomedical Data for Collaborative Scientific Research: A Research Information Management System.”</span> <em>International Journal of Information Management</em> 30 (3): 256–64.
</div>
<div class="csl-entry">
Nardi, Bonnie A, and James R Miller. 1990. <span>“The Spreadsheet Interface: A Basis for End User Programming.”</span> In <em>Proceedings of the IFIP TC13 Third Interational Conference on Human-Computer Interaction</em>, 977–83. North-Holland Publishing Co.
</div>
<div class="csl-entry">
Nash, JC. 2006. <span>“Spreadsheets in Statistical Practice—Another Look.”</span> <em>The American Statistician</em> 60 (3): 287–89.
</div>
<div class="csl-entry">
Neff, Ellen P. 2021. <span>“On the Past, Present, and Future of in Vivo Science.”</span> <em>Lab Animal</em> 50 (10): 273–76.
</div>
<div class="csl-entry">
Nekrutenko, Anton, and James Taylor. 2012. <span>“Next-Generation Sequencing Data Interpretation: Enhancing Reproducibility and Accessibility.”</span> <em>Nature Reviews Genetics</em> 13 (9): 667–72.
</div>
<div class="csl-entry">
Noble, William Stafford. 2009. <span>“A Quick Guide to Organizing Computational Biology Projects.”</span> <em>PLoS Computational Biology</em> 5 (7): e1000424.
</div>
<div class="csl-entry">
Osann, Isabell, Lena Mayer, and Inga Wiele. 2020. <em>The Design Thinking Quick Start Guide: A 6-Step Process for Generating and Implementing Creative Solutions</em>. John Wiley &amp; Sons.
</div>
<div class="csl-entry">
Pawlik, Aleksandra, Celia WG van Gelder, Aleksandra Nenadic, Patricia M Palagi, Eija Korpelainen, Philip Lijnzaad, Diana Marek, Susanna-Assunta Sansone, John Hancock, and Carole Goble. 2017. <span>“Developing a Strategy for Computational Lab Skills Training Through <span class="nocase">Software and Data Carpentry</span>: Experiences from the <span>ELIXIR Pilot</span> Action.”</span> <em>F1000Research</em> 6: ELIXIR–1040.
</div>
<div class="csl-entry">
Peng, Roger. 2018. <span>“Teaching r to New Users—from Tapply to the Tidyverse.”</span> <em>Simply Statistics</em>.
</div>
<div class="csl-entry">
Peng, Roger D. 2016. <em>R Programming for Data Science</em>. Leanpub.
</div>
<div class="csl-entry">
Peng, Roger D, and Stephanie C Hicks. 2021. <span>“Reproducible Research: A Retrospective.”</span> <em>Annual Review of Public Health</em> 42: 79–93.
</div>
<div class="csl-entry">
Perez-Riverol, Yasset, Laurent Gatto, Rui Wang, Timo Sachsenberg, Julian Uszkoreit, Felipe da Veiga Leprevost, Christian Fufezan, et al. 2016. <span>“Ten Simple Rules for Taking Advantage of Git and GitHub.”</span> <em>PLoS Computational Biology</em> 12 (7).
</div>
<div class="csl-entry">
Perkel, Jeffrey. 2018. <span>“Git: The Reproducibility Tool Scientists Love to Hate.”</span> <em>Naturejobs Blog</em>.
</div>
<div class="csl-entry">
Perkel, Jeffrey M. 2011. <span>“Coding Your Way Out of a Problem.”</span> Nature Publishing Group.
</div>
<div class="csl-entry">
———. 2017. <span>“Single-Cell Sequencing Made Simple.”</span> <em>Nature</em> 547 (7661): 125–26.
</div>
<div class="csl-entry">
———. 2018. <span>“THE FUTURE OF SCIENTIFIC FIGURES.”</span> <em>Nature</em> 554 (7690): 133–34.
</div>
<div class="csl-entry">
Powell, Kendall. 2012. <span>“A Lab App for That.”</span> <em>Nature</em> 484 (7395): 553–55.
</div>
<div class="csl-entry">
Powell, Stephen G, Kenneth R Baker, and Barry Lawson. 2009. <span>“Errors in Operational Spreadsheets: A Review of the State of the Art.”</span> In <em>2009 42nd Hawaii International Conference on System Sciences</em>, 1–8. IEEE.
</div>
<div class="csl-entry">
Quintelier, Katrien, Artuur Couckuyt, Annelies Emmaneel, Joachim Aerts, Yvan Saeys, and Sofie Van Gassen. 2021. <span>“Analyzing High-Dimensional Cytometry Data Using FlowSOM.”</span> <em>Nature Protocols</em> 16 (8): 3775–3801.
</div>
<div class="csl-entry">
Raymond, Eric. 2009. <span>“Understanding Version-Control Systems (DRAFT).”</span> <a href="http://www.catb.org/~esr/writings/version-control/version-control.html">http://www.catb.org/~esr/writings/version-control/version-control.html</a>.
</div>
<div class="csl-entry">
Raymond, Eric S. 2003. <em>The Art of Unix Programming</em>. Addison-Wesley Professional.
</div>
<div class="csl-entry">
Robinson, David. 2014. <span>“Broom: An r Package for Converting Statistical Analysis Objects into Tidy Data Frames.”</span> <em>arXiv Preprint arXiv:1412.3565</em>.
</div>
<div class="csl-entry">
———. 2017. <span>“Teach the Tidyverse to Beginners.”</span> <em>Variance Explained</em>.
</div>
<div class="csl-entry">
Robinson, Mark D, Davis J McCarthy, and Gordon K Smyth. 2010. <span>“edgeR: A Bioconductor Package for Differential Expression Analysis of Digital Gene Expression Data.”</span> <em>Bioinformatics</em> 26 (1): 139–40. <a href="https://doi.org/10.1093/bioinformatics/btp616">https://doi.org/10.1093/bioinformatics/btp616</a>.
</div>
<div class="csl-entry">
Ross, Zev, Hadley Wickham, and David Robinson. 2017. <span>“Declutter Your <span>R</span> Workflow with Tidy Tools.”</span> <em>PeerJ Preprints</em> 5: e3180v1.
</div>
<div class="csl-entry">
<span>“<span>RStudio Project Templates</span>.”</span> 2021. <a href="https://rstudio.github.io/rstudio-extensions/rstudio_project_templates.html" class="uri">https://rstudio.github.io/rstudio-extensions/rstudio_project_templates.html</a>.
</div>
<div class="csl-entry">
Sansone, Susanna-Assunta, Philippe Rocca-Serra, Dawn Field, Eamonn Maguire, Chris Taylor, Oliver Hofmann, Hong Fang, et al. 2012. <span>“Toward Interoperable Bioscience Data.”</span> <em>Nature Genetics</em> 44 (2): 121.
</div>
<div class="csl-entry">
Savage, Adam. 2020. <em>Every Tool’s a Hammer: Life Is What You Make It</em>. Atria Books.
</div>
<div class="csl-entry">
Schadt, Eric E, Michael D Linderman, Jon Sorenson, Lawrence Lee, and Garry P Nolan. 2010. <span>“Computational Solutions to Large-Scale Data Management and Analysis.”</span> <em>Nature Reviews Genetics</em> 11 (9): 647.
</div>
<div class="csl-entry">
Schrode, Nadine, Carina Seah, PJ Michael Deans, Gabriel Hoffman, and Kristen J Brennand. 2021. <span>“Analysis Framework and Experimental Design for Evaluating Synergy-Driving Gene Expression.”</span> <em>Nature Protocols</em> 16 (2): 812–40.
</div>
<div class="csl-entry">
Sedgwick, Philip. 2014. <span>“Unit of Observation and Unit of Analysis.”</span> <em>BMJ</em> 348: g3840.
</div>
<div class="csl-entry">
Silge, Julia, and David Robinson. 2016. <span>“Tidytext: Text Mining and Analysis Using Tidy Data Principles in <span>R</span>.”</span> <em>The Journal of Open Source Software</em> 1 (3).
</div>
<div class="csl-entry">
———. 2017. <em>Text Mining with r: A Tidy Approach</em>. Sebastopol: O’Reilly Media.
</div>
<div class="csl-entry">
Spidlen, Josef, Wayne Moore, David Parks, Michael Goldberg, Kim Blenman, James S Cavenaugh, ISAC Data Standards Task Force, and Ryan Brinkman. 2021. <span>“Data File Standard for Flow Cytometry, Version FCS 3.2.”</span> <em>Cytometry Part A</em> 99 (1): 100–102.
</div>
<div class="csl-entry">
Stander, Julian, and Luciana Dalla Valle. 2017. <span>“On Enthusing Students about Big Data and Social Media Visualization and Analysis Using <span class="nocase">R, RStudio, and RMarkdown</span>.”</span> <em>Journal of Statistics Education</em> 25 (2): 60–67.
</div>
<div class="csl-entry">
Stark, Philip B. 2018. <span>“Before Reproducibility Must Come Preproducibility.”</span> <em>Nature</em> 557 (7706): 613–14.
</div>
<div class="csl-entry">
Target, Sinclair. 2018. <span>“Version Control Before Git with CVS.”</span> <a href="https://twobithistory.org/2018/07/07/cvs.html">https://twobithistory.org/2018/07/07/cvs.html</a>.
</div>
<div class="csl-entry">
Teixeira, Ricardo, and Vasco Amaral. 2016. <span>“On the Emergence of Patterns for Spreadsheets Data Arrangements.”</span> In <em>Federation of International Conferences on Software Technologies: Applications and Foundations</em>, 333–45. Springer.
</div>
<div class="csl-entry">
Thomas, Kathy, and Mary Beth Farrell. 2015. <span>“How to Write a Protocol: Part 1.”</span> <em>Journal of Nuclear Medicine Technology</em> 43 (1): 1–7.
</div>
<div class="csl-entry">
Tippmann, Sylvia. 2014. <span>“My Digital Toolbox: Nuclear Engineer Katy Huff on Version-Control Systems.”</span> <em>Nature News</em>.
</div>
<div class="csl-entry">
Topaloglou, Thodoros, Susan B Davidson, HV Jagadish, Victor M Markowitz, Evan W Steeg, and Mike Tyers. 2004. <span>“Biological Data Management: Research, Practice and Opportunities.”</span> In <em>Proceedings of the Thirtieth International Conference on Very Large Data Bases-Volume 30</em>, 1233–36. VLDB Endowment.
</div>
<div class="csl-entry">
Tyner, Sam, François Briatte, and Heike Hofmann. 2017. <span>“<span class="nocase">Network Visualization with ggplot2</span>.”</span> <em><span>The R Journal</span></em> 9 (1): 27–59.
</div>
<div class="csl-entry">
U.S. Department of Health and Human Services, National Institutes of Health. 2016. <span>“<span>NIH-Wide Strategic Plan, Fiscal Years 2016-2020: Turning Discovery Into Health</span>.”</span> <a href="https://www.nih.gov/sites/default/files/about-nih/strategic-plan-fy2016-2020-508.pdf">https://www.nih.gov/sites/default/files/about-nih/strategic-plan-fy2016-2020-508.pdf</a>.
</div>
<div class="csl-entry">
———. 2018. <span>“<span class="nocase">NIH Strategic Plan for Data Science</span>.”</span> <a href="https://datascience.nih.gov/sites/default/files/NIH_Strategic_Plan_for_Data_Science_Final_508.pdf">https://datascience.nih.gov/sites/default/files/NIH_Strategic_Plan_for_Data_Science_Final_508.pdf</a>.
</div>
<div class="csl-entry">
Vuorre, Matti, and Matthew JC Crump. 2021. <span>“Sharing and Organizing Research Products as r Packages.”</span> <em>Behavior Research Methods</em> 53: 792–802.
</div>
<div class="csl-entry">
Welsh, Eric A, Paul A Stewart, Brent M Kuenzi, and James A Eschrich. 2017. <span>“Escape Excel: A Tool for Preventing Gene Symbol and Accession Conversion Errors.”</span> <em>PloS One</em> 12 (9): e0185207.
</div>
<div class="csl-entry">
Wendt, Caroline J, and G Brooke Anderson. 2022. <span>“Ten Simple Rules for Finding and Selecting r Packages.”</span> <em>PLoS Computational Biology</em> 18 (3): e1009884.
</div>
<div class="csl-entry">
Wickham, Hadley. 2014. <span>“Tidy Data.”</span> <em>Journal of Statistical Software</em> 59 (10): 1–23.
</div>
<div class="csl-entry">
———. 2016. <em>Ggplot2: Elegant Graphics for Data Analysis</em>. 2nd ed. New York: Springer.
</div>
<div class="csl-entry">
———. 2017. <span>“The Tidy Tools Manifesto.”</span> <em>CRAN Vignette</em>.
</div>
<div class="csl-entry">
Wickham, Hadley, and Garrett Grolemund. 2016. <em>R for Data Science: Import, Tidy, Transform, Visualize, and Model Data</em>. sebastopol: O’Reilly Media.
</div>
<div class="csl-entry">
Wilkinson, Mark D, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. <span>“The FAIR Guiding Principles for Scientific Data Management and Stewardship.”</span> <em>Scientific Data</em> 3.
</div>
<div class="csl-entry">
Willekens, Frans. 2013. <span>“Chronological Objects in Demographic Research.”</span> <em>Demographic Research</em> 28: 649–80.
</div>
<div class="csl-entry">
Wilson, G. 2014. <span>“<span>Software Carpentry</span>: Lessons Learned.”</span> <em>F1000Research</em> 3: 62–62.
</div>
<div class="csl-entry">
Winchester, Catherine. 2018. <span>“Give Every Paper a Read for Reproducibility.”</span> <em>Nature</em> 557 (7706): 281–82.
</div>
<div class="csl-entry">
Xie, Yihui, Joseph J Allaire, and Garrett Grolemund. 2018. <em>R Markdown: The Definitive Guide</em>. CRC Press.
</div>
<div class="csl-entry">
Xie, Yihui, Christophe Dervieux, and Emily Riederer. 2020. <em>R Markdown Cookbook</em>. Chapman; Hall/CRC.
</div>
<div class="csl-entry">
Yin, Tengfei, Dianne Cook, and Michael Lawrence. 2012. <span>“Ggbio: An <span>R</span> Package for Extending the Grammar of Graphics for Genomic Data.”</span> <em>Genome Biology</em> 13 (8): R77.
</div>
<div class="csl-entry">
Zeeberg, Barry R, Joseph Riss, David W Kane, Kimberly J Bussey, Edward Uchio, W Marston Linehan, J Carl Barrett, and John N Weinstein. 2004. <span>“Mistaken Identifiers: Gene Name Errors Can Be Introduced Inadvertently When Using <span>Excel</span> in Bioinformatics.”</span> <em>BMC Bioinformatics</em> 5 (1): 80.
</div>
<div class="csl-entry">
Ziemann, Mark, Yotam Eren, and Assam El-Osta. 2016. <span>“Gene Name Errors Are Widespread in the Scientific Literature.”</span> <em>Genome Biology</em> 17 (1): 177.
</div>
</div>
</div>
</div>
<!-- </div> -->
<p style="text-align: center;">
<a href="3.8-module19.html"><button class="btn btn-default">Previous</button></a>
</p>
</div>
</div>



</body>
</html>
