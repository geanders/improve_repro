<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Experimental Data Preprocessing | Improving the Reproducibility of Experimental Data Recording and Pre-Processing</title>
  <meta name="description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Experimental Data Preprocessing | Improving the Reproducibility of Experimental Data Recording and Pre-Processing" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Experimental Data Preprocessing | Improving the Reproducibility of Experimental Data Recording and Pre-Processing" />
  
  <meta name="twitter:description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing." />
  

<meta name="author" content="Brooke Anderson, Michael Lyons, Mercedes Gonzalez-Juarrero, Marcela Henao-Tamayo, and Gregory Robertson" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="experimental-data-recording.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Visualization in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Overview</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>1.1</b> License</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html"><i class="fa fa-check"></i><b>2</b> Experimental Data Recording</a><ul>
<li class="chapter" data-level="2.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#separating-data-recording-and-analysis"><i class="fa fa-check"></i><b>2.1</b> Separating data recording and analysis</a><ul>
<li class="chapter" data-level="2.1.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#data-recording-versus-data-analysis"><i class="fa fa-check"></i><b>2.1.1</b> Data recording versus data analysis</a></li>
<li class="chapter" data-level="2.1.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#hazards-of-combining-recording-and-analysis"><i class="fa fa-check"></i><b>2.1.2</b> Hazards of combining recording and analysis</a></li>
<li class="chapter" data-level="2.1.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#approaches-to-separate-recording-and-analysis"><i class="fa fa-check"></i><b>2.1.3</b> Approaches to separate recording and analysis</a></li>
<li class="chapter" data-level="2.1.4" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#discussion-questions"><i class="fa fa-check"></i><b>2.1.4</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#principles-and-power-of-structured-data-formats"><i class="fa fa-check"></i><b>2.2</b> Principles and power of structured data formats</a><ul>
<li class="chapter" data-level="2.2.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#data-recording-standards"><i class="fa fa-check"></i><b>2.2.1</b> Data recording standards</a></li>
<li class="chapter" data-level="2.2.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#defining-data-standards-for-a-research-group"><i class="fa fa-check"></i><b>2.2.2</b> Defining data standards for a research group</a></li>
<li class="chapter" data-level="2.2.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#two-dimensional-structured-data-format"><i class="fa fa-check"></i><b>2.2.3</b> Two-dimensional structured data format</a></li>
<li class="chapter" data-level="2.2.4" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#saving-two-dimensional-structured-data-in-plain-text-file-formats"><i class="fa fa-check"></i><b>2.2.4</b> Saving two-dimensional structured data in plain text file formats</a></li>
<li class="chapter" data-level="2.2.5" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#occassions-for-more-complex-data-structures-and-file-formats"><i class="fa fa-check"></i><b>2.2.5</b> Occassions for more complex data structures and file formats</a></li>
<li class="chapter" data-level="2.2.6" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#levels-of-standardizationresearch-group-to-research-community"><i class="fa fa-check"></i><b>2.2.6</b> Levels of standardization—research group to research community</a></li>
<li class="chapter" data-level="2.2.7" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#applied-exercise"><i class="fa fa-check"></i><b>2.2.7</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#the-tidy-data-format"><i class="fa fa-check"></i><b>2.3</b> The ‘tidy’ data format</a><ul>
<li class="chapter" data-level="2.3.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#what-makes-data-tidy"><i class="fa fa-check"></i><b>2.3.1</b> What makes data “tidy”?</a></li>
<li class="chapter" data-level="2.3.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#why-make-your-data-tidy"><i class="fa fa-check"></i><b>2.3.2</b> Why make your data “tidy”?</a></li>
<li class="chapter" data-level="2.3.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#using-tidyverse-tools-with-data-in-the-tidy-data-format"><i class="fa fa-check"></i><b>2.3.3</b> Using tidyverse tools with data in the “tidy data” format</a></li>
<li class="chapter" data-level="2.3.4" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#practice-quiz"><i class="fa fa-check"></i><b>2.3.4</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#designing-templates-for-tidy-data-collection"><i class="fa fa-check"></i><b>2.4</b> Designing templates for “tidy” data collection</a><ul>
<li class="chapter" data-level="2.4.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#creating-the-rules-for-collecting-data-in-the-same-time-each-time"><i class="fa fa-check"></i><b>2.4.1</b> Creating the rules for collecting data in the same time each time</a></li>
<li class="chapter" data-level="2.4.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1"><i class="fa fa-check"></i><b>2.4.2</b> Subsection 1</a></li>
<li class="chapter" data-level="2.4.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#dont-repeat-yourself"><i class="fa fa-check"></i><b>2.4.3</b> Don’t Repeat Yourself!</a></li>
<li class="chapter" data-level="2.4.4" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#dont-repeat-your-report-writing"><i class="fa fa-check"></i><b>2.4.4</b> Don’t repeat your report-writing!</a></li>
<li class="chapter" data-level="2.4.5" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#automating-reports"><i class="fa fa-check"></i><b>2.4.5</b> Automating reports</a></li>
<li class="chapter" data-level="2.4.6" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#scripts-and-automated-reports-as-simple-pipelines"><i class="fa fa-check"></i><b>2.4.6</b> Scripts and automated reports as simple pipelines</a></li>
<li class="chapter" data-level="2.4.7" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#applied-exercise-1"><i class="fa fa-check"></i><b>2.4.7</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#example-creating-a-template-for-tidy-data-collection"><i class="fa fa-check"></i><b>2.5</b> Example: Creating a template for “tidy” data collection</a><ul>
<li class="chapter" data-level="2.5.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-1"><i class="fa fa-check"></i><b>2.5.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.5.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2"><i class="fa fa-check"></i><b>2.5.2</b> Subsection 2</a></li>
<li class="chapter" data-level="2.5.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#example-datasets"><i class="fa fa-check"></i><b>2.5.3</b> Example datasets</a></li>
<li class="chapter" data-level="2.5.4" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#issues-with-these-data-sets"><i class="fa fa-check"></i><b>2.5.4</b> Issues with these data sets</a></li>
<li class="chapter" data-level="2.5.5" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#final-tidy-examples"><i class="fa fa-check"></i><b>2.5.5</b> Final “tidy” examples</a></li>
<li class="chapter" data-level="2.5.6" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#options-for-recording-tidy-data"><i class="fa fa-check"></i><b>2.5.6</b> Options for recording tidy data</a></li>
<li class="chapter" data-level="2.5.7" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#examples-of-how-tidy-data-can-be-easily-analyzed-visualized"><i class="fa fa-check"></i><b>2.5.7</b> Examples of how “tidy” data can be easily analyzed / visualized</a></li>
<li class="chapter" data-level="2.5.8" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#discussion-questions-1"><i class="fa fa-check"></i><b>2.5.8</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files"><i class="fa fa-check"></i><b>2.6</b> Power of using a single structured ‘Project’ directory for storing and tracking research project files</a><ul>
<li class="chapter" data-level="2.6.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-2"><i class="fa fa-check"></i><b>2.6.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.6.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2-1"><i class="fa fa-check"></i><b>2.6.2</b> Subsection 2</a></li>
<li class="chapter" data-level="2.6.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#practice-quiz-1"><i class="fa fa-check"></i><b>2.6.3</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#creating-project-templates"><i class="fa fa-check"></i><b>2.7</b> Creating ‘Project’ templates</a><ul>
<li class="chapter" data-level="2.7.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-3"><i class="fa fa-check"></i><b>2.7.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.7.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2-2"><i class="fa fa-check"></i><b>2.7.2</b> Subsection 2</a></li>
<li class="chapter" data-level="2.7.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#discussion-questions-2"><i class="fa fa-check"></i><b>2.7.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#example-creating-a-project-template"><i class="fa fa-check"></i><b>2.8</b> Example: Creating a ‘Project’ template</a><ul>
<li class="chapter" data-level="2.8.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-4"><i class="fa fa-check"></i><b>2.8.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.8.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2-3"><i class="fa fa-check"></i><b>2.8.2</b> Subsection 2</a></li>
<li class="chapter" data-level="2.8.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#applied-exercise-2"><i class="fa fa-check"></i><b>2.8.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#harnessing-version-control-for-transparent-data-recording"><i class="fa fa-check"></i><b>2.9</b> Harnessing version control for transparent data recording</a><ul>
<li class="chapter" data-level="2.9.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#what-is-version-control"><i class="fa fa-check"></i><b>2.9.1</b> What is version control?</a></li>
<li class="chapter" data-level="2.9.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#recording-data-in-the-laboratoryfrom-paper-to-computers"><i class="fa fa-check"></i><b>2.9.2</b> Recording data in the laboratory—from paper to computers</a></li>
<li class="chapter" data-level="2.9.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#discussion-questions-3"><i class="fa fa-check"></i><b>2.9.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms"><i class="fa fa-check"></i><b>2.10</b> Enhance the reproducibility of collaborative research with version control platforms</a><ul>
<li class="chapter" data-level="2.10.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#git-and-github-features"><i class="fa fa-check"></i><b>2.10.1</b> git and GitHub features</a></li>
<li class="chapter" data-level="2.10.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-5"><i class="fa fa-check"></i><b>2.10.2</b> Subsection 1</a></li>
<li class="chapter" data-level="2.10.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2-4"><i class="fa fa-check"></i><b>2.10.3</b> Subsection 2</a></li>
<li class="chapter" data-level="2.10.4" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#discussion-questions-4"><i class="fa fa-check"></i><b>2.10.4</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#using-git-and-gitlab-to-implement-version-control"><i class="fa fa-check"></i><b>2.11</b> Using git and GitLab to implement version control</a><ul>
<li class="chapter" data-level="2.11.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#how-to-use-version-control"><i class="fa fa-check"></i><b>2.11.1</b> How to use version control</a></li>
<li class="chapter" data-level="2.11.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#leveraging-git-and-github-as-a-project-director"><i class="fa fa-check"></i><b>2.11.2</b> Leveraging git and GitHub as a project director</a></li>
<li class="chapter" data-level="2.11.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#leveraging-git-and-github-as-a-scientist-who-programs"><i class="fa fa-check"></i><b>2.11.3</b> Leveraging git and GitHub as a scientist who programs</a></li>
<li class="chapter" data-level="2.11.4" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#notes"><i class="fa fa-check"></i><b>2.11.4</b> Notes</a></li>
<li class="chapter" data-level="2.11.5" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#applied-exercise-3"><i class="fa fa-check"></i><b>2.11.5</b> Applied exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html"><i class="fa fa-check"></i><b>3</b> Experimental Data Preprocessing</a><ul>
<li class="chapter" data-level="3.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#principles-and-benefits-of-scripted-pre-processing-of-experimental-data"><i class="fa fa-check"></i><b>3.1</b> Principles and benefits of scripted pre-processing of experimental data</a><ul>
<li class="chapter" data-level="3.1.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-6"><i class="fa fa-check"></i><b>3.1.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.1.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-5"><i class="fa fa-check"></i><b>3.1.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.1.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#discussion-questions-5"><i class="fa fa-check"></i><b>3.1.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#introduction-to-scripted-data-pre-processing-in-r"><i class="fa fa-check"></i><b>3.2</b> Introduction to scripted data pre-processing in R</a><ul>
<li class="chapter" data-level="3.2.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-7"><i class="fa fa-check"></i><b>3.2.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.2.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-6"><i class="fa fa-check"></i><b>3.2.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.2.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-4"><i class="fa fa-check"></i><b>3.2.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#simplify-scripted-pre-processing-through-rs-tidyverse-tools"><i class="fa fa-check"></i><b>3.3</b> Simplify scripted pre-processing through R’s ‘tidyverse’ tools</a><ul>
<li class="chapter" data-level="3.3.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-8"><i class="fa fa-check"></i><b>3.3.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.3.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-7"><i class="fa fa-check"></i><b>3.3.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.3.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#practice-quiz-2"><i class="fa fa-check"></i><b>3.3.3</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#complex-data-types-in-experimental-data-pre-processing"><i class="fa fa-check"></i><b>3.4</b> Complex data types in experimental data pre-processing</a><ul>
<li class="chapter" data-level="3.4.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-9"><i class="fa fa-check"></i><b>3.4.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.4.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-8"><i class="fa fa-check"></i><b>3.4.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.4.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#practice-quiz-3"><i class="fa fa-check"></i><b>3.4.3</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#complex-data-types-in-r-and-bioconductor"><i class="fa fa-check"></i><b>3.5</b> Complex data types in R and Bioconductor</a><ul>
<li class="chapter" data-level="3.5.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-10"><i class="fa fa-check"></i><b>3.5.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.5.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-9"><i class="fa fa-check"></i><b>3.5.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.5.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-5"><i class="fa fa-check"></i><b>3.5.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#example-converting-from-complex-to-tidy-data-formats"><i class="fa fa-check"></i><b>3.6</b> Example: Converting from complex to ‘tidy’ data formats</a><ul>
<li class="chapter" data-level="3.6.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-11"><i class="fa fa-check"></i><b>3.6.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.6.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-10"><i class="fa fa-check"></i><b>3.6.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.6.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-6"><i class="fa fa-check"></i><b>3.6.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#introduction-to-reproducible-data-pre-processing-protocols"><i class="fa fa-check"></i><b>3.7</b> Introduction to reproducible data pre-processing protocols</a><ul>
<li class="chapter" data-level="3.7.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-12"><i class="fa fa-check"></i><b>3.7.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.7.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-11"><i class="fa fa-check"></i><b>3.7.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.7.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#discussion-questions-6"><i class="fa fa-check"></i><b>3.7.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#rmarkdown-for-creating-reproducible-data-pre-processing-protocols"><i class="fa fa-check"></i><b>3.8</b> RMarkdown for creating reproducible data pre-processing protocols</a><ul>
<li class="chapter" data-level="3.8.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-13"><i class="fa fa-check"></i><b>3.8.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.8.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-12"><i class="fa fa-check"></i><b>3.8.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.8.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-7"><i class="fa fa-check"></i><b>3.8.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#example-creating-a-reproducible-data-pre-processing-protocol"><i class="fa fa-check"></i><b>3.9</b> Example: Creating a reproducible data pre-processing protocol</a><ul>
<li class="chapter" data-level="3.9.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-14"><i class="fa fa-check"></i><b>3.9.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.9.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-13"><i class="fa fa-check"></i><b>3.9.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.9.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#practice-quiz-4"><i class="fa fa-check"></i><b>3.9.3</b> Practice quiz</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>4</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Improving the Reproducibility of Experimental Data Recording and Pre-Processing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="experimental-data-preprocessing" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Experimental Data Preprocessing</h1>
<div id="principles-and-benefits-of-scripted-pre-processing-of-experimental-data" class="section level2">
<h2><span class="header-section-number">3.1</span> Principles and benefits of scripted pre-processing of experimental data</h2>
<p>The experimental data collected for biomedical research often requires
pre-processing before it can be analyzed (e.g., gating of flow cytometry data,
feature finding / quantification for mass spectrometry data). Use of
point-and-click software can limit the transparency and reproducibility of this
analysis stage and is time-consuming for repeated tasks. We will explain how
scripted pre-processing, especially using open source software, can improve
transparency and reproducibility.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Define ‘pre-processing’ of experimental data</li>
<li>Describe an open source code script and explain how it can increase
reproducibility of data pre-processing</li>
</ul>
<div id="subsection-1-6" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Subsection 1</h3>
<blockquote>
<p>For bioinformatics, “all too often the software is developed without
thought toward future interoperability with other software products. As a
result, the bioinformatics software landscape is currently characterized
by fragmentation and silos, in which each research group develops and uses
only the tools created within their lab.” <span class="citation">(Barga et al. 2011)</span></p>
</blockquote>
<blockquote>
<p>“The group also noted the lack of agility. Although they may be aware of
a new or better algorithm they cannot easily integrate it into their
analysis pipelines given the lack of standards across both data formats
and tools. It typically requires a complete rewrite of the code in order
to take advntge of a new technique or algorithm, requiring time and often
funding to hire developers.” <span class="citation">(Barga et al. 2011)</span></p>
</blockquote>
<blockquote>
<p>“The benefit of working with a programming language is that you have the code in
a file. This means that you can easily reuse that code. If the code has
parameters it can even be applied to problems that follow a similar pattern.”
<span class="citation">(Janssens 2014)</span></p>
</blockquote>
<blockquote>
<p>“Data exploration in spreadsheet software is typically conducted via menus and
dialog boxes, which leaves no record of the steps taken.” <span class="citation">(Murrell 2009)</span></p>
</blockquote>
<blockquote>
<p>“One reason Unix developers have been cool toward GUI interfaces is that, in their
designers’ haste to make them ‘user-friendly’ each one often becomes frustratingly
opaque to anyone who has to solve user problems—or, indeed, interact with it anywhere
outside the narrow range predicted by the user-interface designer.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Many operating systems touted as more ‘modern’ or ‘user friendly’ than Unix achieve their
surface glossiness by locking users and developers into one interface policy, and offer an
application-programming interface that for all its elaborateness is rather narrow and rigid.
On such systems, tasks the designers have anticipated are very easy—but tasks they have
not anticipated are often impossible or at best extremely painful. Unix, on the other hand, has
flexibility in depth. The many ways Unix provides to glue together programs means that components
of its basic toolkit can be combined to produce useful effects that the designers of the individual
toolkit parts never anticipated.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
</div>
<div id="subsection-2-5" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Subsection 2</h3>
</div>
<div id="discussion-questions-5" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Discussion questions</h3>

</div>
</div>
<div id="introduction-to-scripted-data-pre-processing-in-r" class="section level2">
<h2><span class="header-section-number">3.2</span> Introduction to scripted data pre-processing in R</h2>
<p>We will show how to implement scripted pre-processing of experimental data
through R scripts. We will demonstrate the difference between interactive coding
and code scripts, using R for examples. We will then demonstrate how to create,
save, and run an R code script for a simple data cleaning task.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Describe what an R code script is and how it differs from interactive
coding in R</li>
<li>Create and save an R script to perform a simple data pre-processing task</li>
<li>Run an R script</li>
<li>List some popular packages in R for pre-processing biomedical data</li>
</ul>
<div id="subsection-1-7" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Subsection 1</h3>
</div>
<div id="subsection-2-6" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Subsection 2</h3>
</div>
<div id="applied-exercise-4" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Applied exercise</h3>

</div>
</div>
<div id="simplify-scripted-pre-processing-through-rs-tidyverse-tools" class="section level2">
<h2><span class="header-section-number">3.3</span> Simplify scripted pre-processing through R’s ‘tidyverse’ tools</h2>
<p>The R programming language now includes a collection of ‘tidyverse’ extension
packages that enable user-friendly yet powerful work with experimental data,
including pre-processing and exploratory visualizations. The principle behind
the ‘tidyverse’ is that a collection of simple, general tools can be joined
together to solve complex problems, as long as a consistent format is used for
the input and output of each tool (the ‘tidy’ data format taught in other
modules). In this module, we will explain why this ‘tidyverse’ system is so
powerful and how it can be leveraged within biomedical research, especially for
reproducibly pre-processing experimental data.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Define R’s ‘tidyverse’ system</li>
<li>Explain how the ‘tidyverse’ collection of packages can be both user-friendly
and powerful in solving many complex tasks with data</li>
<li>Describe the difference between base R and R’s ‘tidyverse’.</li>
</ul>
<div id="subsection-1-8" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Subsection 1</h3>
<blockquote>
<p>“There is a now-old trope in the world of programming. It’s called the ‘worse is
better’ debate; it seeks to explain why the Unix operating systems (which include
Mac OS X these days), made up of so many little interchangeable parts, were so much
more successful in the marketplace than LISP systems, which were ideologically pure,
based on a single languagae (again, LISP), which itself was exceptionally simple,
a favorite of ‘serious’ hackers everywhere. It’s too complex to rehash here, but one
of the ideas inherent within ‘worse is better’ is thata systems made up of many
simple pieces that can be roped together, even if those pieces don’t share a consistent
interface, are likely to be more successful than systems that are designed with consistency
in every regard. And it strikes me that this is a fundamental drama of new technologies.
Unix beat out the LISP machines. If you consider mobile handsets, many of which run
descendants of Unit (iOS and Andriod), Unix beat out Windows as well. And HTML5 beat out
all of the various initiatives to create a single unified web. It nods to accessibility:
it doesn’t get in the way of those who want to make something huge and interconnected.
But it doesn’t enforce; it doesn’t seek to change the behavior of page creators in the
same way that such lost standards as XHTML 2.0 (which eremged from the offices of
the World Wide Web Consortium, and then disappeared under the weight of its own
intentions) once did. It’s not a bad place to end up. It means that there is no
single framework, no set of easy rules to lear, no overarching principles that,
once learned, can make the web appear like a golden statue atop a mountain. There
are just components: HTML to get the words on the page, forms to get people to
write in, videos and images to put up pictures, moving or otherwise, and
JavaScript to make everything dance.” <span class="citation">(Ford 2014)</span></p>
</blockquote>
<blockquote>
<p>“One of the fundamental contributions of the Unix system [is] the idea of a <em>pipe</em>.
A pipe is a way to connect the output of one program to the input of another program
without any temporary file; a <em>pipeline</em> is a connection of two or more programs through
pipes. … Any program that reads from a terminal can read from a pipe instead; any program
that writes on the terminal can write to a pipe. … The programs in a pipeline actually
run at the same time, not one after another. This means that the programs in a pipeline
can be interactive; the kernel looks after whatever scheduling and synchronization is needed
to make it all work. As you probably suspect by now, the shell arranges things when you
ask for a pipe; the individual programs are oblivious to the redirection.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“Even though the Unix system introduces a number of innovative programs and techniques,
no single program or idea makes it work well. Instead, what makes it effective is an approach
to programming, a philosophy of using the computer. Although that philosophy can’t be written
down in a single sentence, at its heart is the idea that the power of a system comes more from
the relationships among programs than from the programs themselves. Many Unix programs do
quite trivial things in isolation, but, combined with other programs, become general and
useful tools.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“What is ‘Unix’? In the narrowest sense, it is a time-sharing operating system <em>kernel</em>:
a program that controls the resources of a computer and allocates them among its users.
It lets users run their programs; it controls the peripheral devices (discs, terminals,
printers, and the like) connected to the machine; and it provides a file system that
manages the long-term storage of information such as programs, data, and documents.
In a broader sense, ‘Unix’ is often taken to include not only the kernel, but also
essential programs like compiles, editors, command languages, programs for copying and
printing files, and so on. Still more broadly, ‘Unix’ may even include programs
develpoed by you or others to be run on your system, such as tools for document
preparation, routines for statistical analysis, and graphics packages.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
</div>
<div id="subsection-2-7" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Subsection 2</h3>
</div>
<div id="practice-quiz-2" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Practice quiz</h3>

</div>
</div>
<div id="complex-data-types-in-experimental-data-pre-processing" class="section level2">
<h2><span class="header-section-number">3.4</span> Complex data types in experimental data pre-processing</h2>
<p>Raw data from many biomedical experiments, especially those that use
high-throughput techniques, can be very large and complex. Because of the scale
and complexity of these data, software for pre-processing the data in R often
uses complex, ‘untidy’ data formats. While these formats are necessary for
computational efficiency, they add a critical barrier for researchers wishing to
implement reproducibility tools. In this module, we will explain why use of
complex data formats is often necessary within open source pre-processing
software and outline the hurdles created in reproducibility tool use among
laboratory-based scientists.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Explain why R software for pre-processing biomedical data often stores
data in complex, ‘untidy’ formats</li>
<li>Describe how these complex data formats can create barriers to
laboratory-based researchers seeking to use reproducibility tools for
data pre-processing</li>
</ul>
<div id="subsection-1-9" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Subsection 1</h3>
</div>
<div id="subsection-2-8" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Subsection 2</h3>
</div>
<div id="practice-quiz-3" class="section level3">
<h3><span class="header-section-number">3.4.3</span> Practice quiz</h3>

</div>
</div>
<div id="complex-data-types-in-r-and-bioconductor" class="section level2">
<h2><span class="header-section-number">3.5</span> Complex data types in R and Bioconductor</h2>
<p>Many R extension packages for pre-processing experimental data use complex
(rather than ‘tidy’) data formats within their code, and many output data in
complex formats. Very recently, the <em>broom</em> and <em>biobroom</em> R
packages have been developed to extract a ‘tidy’ dataset from a complex data
format. These tools create a clean, simple connection between the complex data
formats often used in pre-processing experimental data and the ‘tidy’ format
required to use the ‘tidyverse’ tools now taught in many introductory R courses.
In this module, we will describe the ‘list’ data structure, the common backbone
for complex data structures in R and provide tips on how to explore and extract
data stored in R in this format, including through the <em>broom</em> and
<em>biobroom</em> packages.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Describe the structure of R’s ‘list’ data format</li>
<li>Take basic steps to explore and extract data stored in R’s complex, list-based
structures</li>
<li>Describe what the <em>broom</em> and <em>biobroom</em> R packages can do</li>
<li>Explain how converting data to a ‘tidy’ format can improve reproducibility</li>
</ul>
<div id="subsection-1-10" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Subsection 1</h3>
<blockquote>
<p>“Object-oriented design doesn’t have to be over-complicated design, but we’ve
observed that too often it is. Too many OO designs are spaghetti-like tangles of
is-a and has-a relationships, or feature thick layers of glue in which many of the
objects seem to exist simply to hold places in a steep-sided pyramid of abstractions.
Such designs are the opposite of transparent; they are (notoriously) opaque and
difficult to debug.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Unix programmers are the original zealots about modularity, but tend to go about it
in a quiter way [that with OOP]. Keeping glue layers thin is part of it; more generally,
our tradition teaches us to build lower, hugging the ground with algorithms and structures
that are designed to be simple and transparent.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
</div>
<div id="subsection-2-9" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Subsection 2</h3>
</div>
<div id="applied-exercise-5" class="section level3">
<h3><span class="header-section-number">3.5.3</span> Applied exercise</h3>

</div>
</div>
<div id="example-converting-from-complex-to-tidy-data-formats" class="section level2">
<h2><span class="header-section-number">3.6</span> Example: Converting from complex to ‘tidy’ data formats</h2>
<p>We will provide a detailed example of a case where data pre-processing in R
results in a complex, ‘untidy’ data format. We will walk through an example of
applying automated gating to flow cytometry data. We will demonstrate the
complex initial format of this pre-processed data and then show trainees how a
‘tidy’ dataset can be extracted and used for further data analysis and
visualization using the popular R ‘tidyverse’ tools. This example will use real
experimental data from one of our Co-Is research on the immunology of
tuberculosis.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Describe how tools like  were used in this real research
example to convert from the complex data format from pre-processing to a format
better for further data analysis and visualization</li>
<li>Understand how these tools would fit in their own research pipelines</li>
</ul>
<div id="subsection-1-11" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Subsection 1</h3>
</div>
<div id="subsection-2-10" class="section level3">
<h3><span class="header-section-number">3.6.2</span> Subsection 2</h3>
</div>
<div id="applied-exercise-6" class="section level3">
<h3><span class="header-section-number">3.6.3</span> Applied exercise</h3>

</div>
</div>
<div id="introduction-to-reproducible-data-pre-processing-protocols" class="section level2">
<h2><span class="header-section-number">3.7</span> Introduction to reproducible data pre-processing protocols</h2>
<p>Reproducibility tools can be used to create reproducible data pre-processing
protocols—documents that combine code and text in a ‘knitted’ document, which
can be re-used to ensure data pre-processing is consistent and reproducible
across research projects. In this module, we will describe how reproducible data
pre-processing protocols can improve reproducibility of pre-processing
experimental data, as well as to ensure transparency, consistency, and
reproducibility across the research projects conducted by a research team.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Define a ‘reproducible data pre-processing protocol’</li>
<li>Explain how such protocols improve reproducibility at the data pre-processing
phase</li>
<li>List other benefits, including improving efficiency and consistency of data
pre-processing</li>
</ul>
<div id="subsection-1-12" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Subsection 1</h3>
</div>
<div id="subsection-2-11" class="section level3">
<h3><span class="header-section-number">3.7.2</span> Subsection 2</h3>
</div>
<div id="discussion-questions-6" class="section level3">
<h3><span class="header-section-number">3.7.3</span> Discussion questions</h3>

</div>
</div>
<div id="rmarkdown-for-creating-reproducible-data-pre-processing-protocols" class="section level2">
<h2><span class="header-section-number">3.8</span> RMarkdown for creating reproducible data pre-processing protocols</h2>
<p>The R extension package RMarkdown can be used to create documents that combine
code and text in a ‘knitted’ document, and it has become a popular tool for
improving the computational reproducibility and efficiency of the data analysis
stage of research. This tool can also be used earlier in the research process,
however, to improve reproducibility of pre-processing steps. In this module, we
will provide detailed instructions on how to use RMarkdown in RStudio to create
documents that combine code and text. We will show how an RMarkdown document
describing a data pre-processing protocol can be used to efficiently apply the
same data pre-processing steps to different sets of raw data.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Define RMarkdown and the documents it can create</li>
<li>Explain how RMarkdown can be used to improve the reproducibility of research
projects at the data pre-processing phase</li>
<li>Create a document in RStudio using</li>
<li>Apply it to several different datasets with the same format</li>
</ul>
<div id="subsection-1-13" class="section level3">
<h3><span class="header-section-number">3.8.1</span> Subsection 1</h3>
<blockquote>
<p>“WordPerfect was always the best word processor. Because it allowed for insight into
its very structure. You could hit a certain key combination and suddenly the screen
would split and you’d reveal the codes, the bolds and italics, and so forth,
that would define your text when it was printed. It was beloved of legal secretaries
and journalists alike. Because when you work with words, at the practical, everyday
level, the ability to look under the hood is essential. Words are not simple. And
WordPerfect acknowledged that. Microsoft Word did not. Microsoft kept insisting that
what you saw on your screen was the way things <em>were</em>, and if your fonts just kept
sort of randonmly changing, well, you must have wanted it that way. Then along came
HTML, and what I remember most was that sense of being back inside the file. Sure,
HTML was a typographic nightmare, a bunch of unjustified Times New Roman in 12 pt on
screens with chiclet-size pixels, but under the hood you could see all the pieces.
Just like WordPerfect. That transparency was a wonderful thing, and it renewed
computing for me.” <span class="citation">(Ford 2014)</span></p>
</blockquote>
<blockquote>
<p>“TeX was created by Donald E. Knuth, a professor at Stanford University who has
achieved international renown as a mathematician and computer scientist.
Knuth also has an aesthetic sense uncommon in his field, and his work output is
truly phenomenal. TeX is a happy byproduct of Knuth’s mammoth enterprise,
<em>The Art of Computer Programming</em>. This series of reference books, designed
to cover the whole gamut of programming concepts and techniques, is a
<em>sine qua non</em> for all computer scientists.” <span class="citation">(Seroul 2012)</span></p>
</blockquote>
<blockquote>
<p>“Roughly speaking, text processors fall into two categories:
(1) WYSIWYG systems: what you see is what you get. You see on the screen at all
times what the printed document will look like, and what you type has immediate
effect on the appearance of the document. (2) markup systems, where you type your text
interspersed with formatting instructions, but don’t see their effect right away. You must run a program to examine the
resulting image, whether on paper or on the screen. In computer science jargon,
markup systems must compile the source file you type. WYSIWYG systems have the obvious
advantage of immediate feedback, but they
are not very precise: what is acceptable at a resolution of 300 dots per inch, for an
ephemeral publication such as a newsletter or flier, is no longer so for a book that
will be phototypeset at high resolution. The human eye is extraordinarily sensitive:
you can be bothered by the appearance of a text without being able to pinpoint why,
just as you can tell when someone plays the wrong note in an orchestra, without
being able to identify the CUlprit. One quickly leams in typesetting that the beauty,
legibility and comfortable reading of a text depend on minute details: each element
must be placed exactly right, within thousandths of an inch. For this type of work,
the advantage of immediate feedback vanishes: fine details of spacing, alignment,
and so on are much too small to be discernible at the screen’s relatively low
resolution, and even if it such were not the case, it would still be a monumental chore
to find the right place for everything by hand. For this reason it is not surprising that in the world of professional typesetting
markup systems are preferred. They automate the task of finding the right place
for each character with great precision. Naturally, this approach is less attractive for
beginners, since one can’t see the results as one types, and must develop a feeling
for what the system will do. But nowadays, you can have the best of both worlds
by using a markup system with a WYSIWYG <em>front end</em>; we’ll talk about such front
ends for TEX later on. TEX was developed in the late seventies and early eighties,
before WYSIWYG systems were widespread. But were it to be redesigned now, it would
still be a markup
language. To give you an idea of the precision with which TEX operates: the internal
unit it uses for its calculations is about a hundred times smaller than the
wavelength of visible light! (That’s right, a hundred times.) In other words, any
round-off error introduced in the calculations is invisible to the naked eye.”
<span class="citation">(Seroul 2012)</span></p>
</blockquote>
<blockquote>
<p>“You should be sure to understand the difference between a text editor and a text
processor. A text processor is a text editor together with formatting software that
allows you to switch fonts, do double columns, indent, and so on. A text editor
puts your text in a file on disk, and displays a portion of it on the screen. It doesn’t
format your text at all. We insist on the difference because those accustomed to WYSIWYG systems are
often not aware of it: they only know text processors. Where can you find a text
editor? Just about everywhere. Every text processor includes a text editor which
you can use. But if you use your text processor as a text editor, be sure to save your
file using a ‘save ASCII’ or ‘save text only’ option, so that the text processor’s own
formatting commands are stripped off. If you give TEX a file created without this
precaution, you’ll get garbage, because TEX cannot digest your text processor’s
commands.” <span class="citation">(Seroul 2012)</span></p>
</blockquote>
<blockquote>
<p>“TeX enabled authors to encode their precise intent into their manuscripts:
This block of text is a computer program, while this word is a keyword in that
program. The language it used, called TeX markup, formalized the slow,
error-prone communication that is normally carried out with the printer over
repeated galley proofs.” <span class="citation">(Apte, n.d.)</span></p>
</blockquote>
<blockquote>
<p>“The idea of writing markup inside text wasn’t especially novel; it has been
used from 1970’s runoff (the UNIX family of printer-preparation utilities) to
today’s HTML tags. TeX was new in that it captured key concepts necessary for
realistic typesetting and formalized them.” <span class="citation">(Apte, n.d.)</span></p>
</blockquote>
<blockquote>
<p>“With these higher-level commands, the free TeX engine, and the LaTeX book,
the use of TeX exploded. The macro file has since evolved and changed names, but
authors still typically run the program called latex or its variants. Hence,
most people who write TeX manuscripts know the program as LaTeX and the commands
they use as LaTeX commands.” <span class="citation">(Apte, n.d.)</span></p>
</blockquote>
<blockquote>
<p>“The effect of LaTeX on scientific and technical publishing has been profound.
Precise typesetting is critical, particularly for conveying concepts using
chemical and mathematical formulas, algorithms, and similar constructs. The
sheer volume of papers, journals, books, and other publications generated in the
modern world is far beyond the throughput possible via manual typesetting. And
TeX enables automation without losing precision. Thanks to LaTeX, book authors
can generate camera-ready copy on their own. Most academic and journal
publishers accept article manuscripts written in LaTeX, and there’s even an open
archive maintained by Cornell University where authors of papers in physics,
chemistry, and other disciplines can directly submit their LaTeX manuscripts for
open viewing. Over 10,000 manuscripts are submitted to this archive every month
from all over the world.” <span class="citation">(Apte, n.d.)</span></p>
</blockquote>
<blockquote>
<p>“For many users, a practical difficulty with typesetting using TeX is
preparing the manuscripts. When TeX was first developed, technical authors were
accustomed to using plain-text editors like WordStar, vi, or Emacs with a
computer keyboard. The idea of marking up their text with commands and running
the manuscript through a typesetting engine felt natural to them. Today’s
typesetters, particularly desktop publishers, have a different mental model.
They expect to see the output in graphical form and then to visually make edits
with a mouse and keyboard, as they would in any WYSIWYG program. They might not
be too picky about the quality of the output, but they appreciate design
capabilities, such as the ability to flow text around curved outlines. Many
print products are now produced with tools like Microsoft Word for this very
reason. TeX authors cannot do the same work as easily.” <span class="citation">(Apte, n.d.)</span></p>
</blockquote>
</div>
<div id="subsection-2-12" class="section level3">
<h3><span class="header-section-number">3.8.2</span> Subsection 2</h3>
</div>
<div id="applied-exercise-7" class="section level3">
<h3><span class="header-section-number">3.8.3</span> Applied exercise</h3>

</div>
</div>
<div id="example-creating-a-reproducible-data-pre-processing-protocol" class="section level2">
<h2><span class="header-section-number">3.9</span> Example: Creating a reproducible data pre-processing protocol</h2>
<p>We will walk through an example of creating a reproducible protocol for the
automated gating of flow cytometry data for a project on the immunology of
tuberculosis lead by one of our Co-Is. This data pre-processing protocol was
created using RMarkdown and allows the efficient, transparent, and reproducible
gating of flow cytometry data for all experiments in the research group. We will
walk the trainees through how we developed the protocol initially, the final
pre-processing protocol, how we apply this protocol to new experimental data.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Explain how a reproducible data pre-processing protocol can be integrated into
a real research project</li>
<li>Understand how to design and implement a data pre-processing protocol to
replace manual or point-and-click data pre-processing tools</li>
</ul>
<div id="subsection-1-14" class="section level3">
<h3><span class="header-section-number">3.9.1</span> Subsection 1</h3>
</div>
<div id="subsection-2-13" class="section level3">
<h3><span class="header-section-number">3.9.2</span> Subsection 2</h3>
</div>
<div id="practice-quiz-4" class="section level3">
<h3><span class="header-section-number">3.9.3</span> Practice quiz</h3>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="experimental-data-recording.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/12-scripted_preprocessing.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["improve_repro.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
