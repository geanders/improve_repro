<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 3 Benefits of a plain text format | Improving the Reproducibility of Experimental Data Recording and Pre-Processing</title>
  <meta name="description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 3 Benefits of a plain text format | Improving the Reproducibility of Experimental Data Recording and Pre-Processing" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Benefits of a plain text format | Improving the Reproducibility of Experimental Data Recording and Pre-Processing" />
  
  <meta name="twitter:description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing." />
  

<meta name="author" content="Brooke Anderson, Michael Lyons, Mercedes Gonzalez-Juarrero, Marcela Henao-Tamayo, and Gregory Robertson">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="experimental-data-recording.html">
<link rel="next" href="experimental-data-preprocessing.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Visualization in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Overview</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>1.1</b> License</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#extra-quotes-for-future-revisions"><i class="fa fa-check"></i><b>1.1.1</b> Extra quotes for future revisions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html"><i class="fa fa-check"></i><b>2</b> Experimental Data Recording</a><ul>
<li class="chapter" data-level="2.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#separating-data-recording-and-analysis"><i class="fa fa-check"></i><b>2.1</b> Separating data recording and analysis</a><ul>
<li class="chapter" data-level="2.1.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#data-recording-versus-data-analysis"><i class="fa fa-check"></i><b>2.1.1</b> Data recording versus data analysis</a></li>
<li class="chapter" data-level="2.1.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#hazards-of-combining-recording-and-analysis"><i class="fa fa-check"></i><b>2.1.2</b> Hazards of combining recording and analysis</a></li>
<li class="chapter" data-level="2.1.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#approaches-to-separate-recording-and-analysis"><i class="fa fa-check"></i><b>2.1.3</b> Approaches to separate recording and analysis</a></li>
<li class="chapter" data-level="2.1.4" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#discussion-questions"><i class="fa fa-check"></i><b>2.1.4</b> Discussion questions</a></li>
<li class="chapter" data-level="2.1.5" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#additional-notes-quotes-for-revisions"><i class="fa fa-check"></i><b>2.1.5</b> Additional notes / quotes for revisions</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#principles-and-power-of-structured-data-formats"><i class="fa fa-check"></i><b>2.2</b> Principles and power of structured data formats</a><ul>
<li class="chapter" data-level="2.2.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#focus-on-data-up-to-recording-less-on-for-post-recording"><i class="fa fa-check"></i><b>2.2.1</b> Focus on data up to recording, less on for post-recording</a></li>
<li class="chapter" data-level="2.2.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#characteristics-of-a-structured-data-format"><i class="fa fa-check"></i><b>2.2.2</b> Characteristics of a structured data format</a></li>
<li class="chapter" data-level="2.2.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#benefits-of-a-structured-data-format"><i class="fa fa-check"></i><b>2.2.3</b> Benefits of a structured data format</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html"><i class="fa fa-check"></i><b>3</b> Benefits of a plain text format</a><ul>
<li class="chapter" data-level="3.0.1" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#when-two-dimensional-structured-data-formats-might-not-work"><i class="fa fa-check"></i><b>3.0.1</b> When two-dimensional structured data formats might not work</a></li>
<li class="chapter" data-level="3.0.2" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#recording-expermental-data-in-a-structured-format"><i class="fa fa-check"></i><b>3.0.2</b> Recording expermental data in a structured format</a></li>
<li class="chapter" data-level="3.0.3" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#applied-exercise"><i class="fa fa-check"></i><b>3.0.3</b> Applied exercise</a></li>
<li class="chapter" data-level="3.1" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#the-tidy-data-format"><i class="fa fa-check"></i><b>3.1</b> The ‘tidy’ data format</a><ul>
<li class="chapter" data-level="3.1.1" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#the-tidy-data-format-1"><i class="fa fa-check"></i><b>3.1.1</b> The “tidy” data format</a></li>
<li class="chapter" data-level="3.1.2" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#the-tidy-data-format-as-a-structured-data-format"><i class="fa fa-check"></i><b>3.1.2</b> The “tidy” data format as a structured data format</a></li>
<li class="chapter" data-level="3.1.3" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#practice-quiz"><i class="fa fa-check"></i><b>3.1.3</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#designing-templates-for-tidy-data-collection"><i class="fa fa-check"></i><b>3.2</b> Designing templates for “tidy” data collection</a><ul>
<li class="chapter" data-level="3.2.1" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-1"><i class="fa fa-check"></i><b>3.2.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.2.2" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#applied-exercise-1"><i class="fa fa-check"></i><b>3.2.2</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#example-creating-a-template-for-tidy-data-collection"><i class="fa fa-check"></i><b>3.3</b> Example: Creating a template for “tidy” data collection</a><ul>
<li class="chapter" data-level="3.3.1" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-1-1"><i class="fa fa-check"></i><b>3.3.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.3.2" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-2"><i class="fa fa-check"></i><b>3.3.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.3.3" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#discussion-questions-1"><i class="fa fa-check"></i><b>3.3.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files"><i class="fa fa-check"></i><b>3.4</b> Power of using a single structured ‘Project’ directory for storing and tracking research project files</a><ul>
<li class="chapter" data-level="3.4.1" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-1-2"><i class="fa fa-check"></i><b>3.4.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.4.2" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-2-1"><i class="fa fa-check"></i><b>3.4.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.4.3" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#practice-quiz-1"><i class="fa fa-check"></i><b>3.4.3</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#creating-project-templates"><i class="fa fa-check"></i><b>3.5</b> Creating ‘Project’ templates</a><ul>
<li class="chapter" data-level="3.5.1" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-1-3"><i class="fa fa-check"></i><b>3.5.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.5.2" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-2-2"><i class="fa fa-check"></i><b>3.5.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.5.3" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#discussion-questions-2"><i class="fa fa-check"></i><b>3.5.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#example-creating-a-project-template"><i class="fa fa-check"></i><b>3.6</b> Example: Creating a ‘Project’ template</a><ul>
<li class="chapter" data-level="3.6.1" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-1-4"><i class="fa fa-check"></i><b>3.6.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.6.2" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-2-3"><i class="fa fa-check"></i><b>3.6.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.6.3" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#applied-exercise-2"><i class="fa fa-check"></i><b>3.6.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#harnessing-version-control-for-transparent-data-recording"><i class="fa fa-check"></i><b>3.7</b> Harnessing version control for transparent data recording</a><ul>
<li class="chapter" data-level="3.7.1" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-1-5"><i class="fa fa-check"></i><b>3.7.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.7.2" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-2-4"><i class="fa fa-check"></i><b>3.7.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.7.3" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#discussion-questions-3"><i class="fa fa-check"></i><b>3.7.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms"><i class="fa fa-check"></i><b>3.8</b> Enhance the reproducibility of collaborative research with version control platforms</a><ul>
<li class="chapter" data-level="3.8.1" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-1-6"><i class="fa fa-check"></i><b>3.8.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.8.2" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-2-5"><i class="fa fa-check"></i><b>3.8.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.8.3" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#discussion-questions-4"><i class="fa fa-check"></i><b>3.8.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#using-git-and-gitlab-to-implement-version-control"><i class="fa fa-check"></i><b>3.9</b> Using git and GitLab to implement version control</a><ul>
<li class="chapter" data-level="3.9.1" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-1-7"><i class="fa fa-check"></i><b>3.9.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.9.2" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#subsection-2-6"><i class="fa fa-check"></i><b>3.9.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.9.3" data-path="benefits-of-a-plain-text-format.html"><a href="benefits-of-a-plain-text-format.html#applied-exercise-3"><i class="fa fa-check"></i><b>3.9.3</b> Applied exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html"><i class="fa fa-check"></i><b>4</b> Experimental Data Preprocessing</a><ul>
<li class="chapter" data-level="4.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#principles-and-benefits-of-scripted-pre-processing-of-experimental-data"><i class="fa fa-check"></i><b>4.1</b> Principles and benefits of scripted pre-processing of experimental data</a><ul>
<li class="chapter" data-level="4.1.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-8"><i class="fa fa-check"></i><b>4.1.1</b> Subsection 1</a></li>
<li class="chapter" data-level="4.1.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-7"><i class="fa fa-check"></i><b>4.1.2</b> Subsection 2</a></li>
<li class="chapter" data-level="4.1.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#discussion-questions-5"><i class="fa fa-check"></i><b>4.1.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#introduction-to-scripted-data-pre-processing-in-r"><i class="fa fa-check"></i><b>4.2</b> Introduction to scripted data pre-processing in R</a><ul>
<li class="chapter" data-level="4.2.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-9"><i class="fa fa-check"></i><b>4.2.1</b> Subsection 1</a></li>
<li class="chapter" data-level="4.2.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-8"><i class="fa fa-check"></i><b>4.2.2</b> Subsection 2</a></li>
<li class="chapter" data-level="4.2.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-4"><i class="fa fa-check"></i><b>4.2.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#simplify-scripted-pre-processing-through-rs-tidyverse-tools"><i class="fa fa-check"></i><b>4.3</b> Simplify scripted pre-processing through R’s ‘tidyverse’ tools</a><ul>
<li class="chapter" data-level="4.3.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-10"><i class="fa fa-check"></i><b>4.3.1</b> Subsection 1</a></li>
<li class="chapter" data-level="4.3.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-9"><i class="fa fa-check"></i><b>4.3.2</b> Subsection 2</a></li>
<li class="chapter" data-level="4.3.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#practice-quiz-2"><i class="fa fa-check"></i><b>4.3.3</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#complex-data-types-in-experimental-data-pre-processing"><i class="fa fa-check"></i><b>4.4</b> Complex data types in experimental data pre-processing</a><ul>
<li class="chapter" data-level="4.4.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-11"><i class="fa fa-check"></i><b>4.4.1</b> Subsection 1</a></li>
<li class="chapter" data-level="4.4.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-10"><i class="fa fa-check"></i><b>4.4.2</b> Subsection 2</a></li>
<li class="chapter" data-level="4.4.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#practice-quiz-3"><i class="fa fa-check"></i><b>4.4.3</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#complex-data-types-in-r-and-bioconductor"><i class="fa fa-check"></i><b>4.5</b> Complex data types in R and Bioconductor</a><ul>
<li class="chapter" data-level="4.5.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-12"><i class="fa fa-check"></i><b>4.5.1</b> Subsection 1</a></li>
<li class="chapter" data-level="4.5.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-11"><i class="fa fa-check"></i><b>4.5.2</b> Subsection 2</a></li>
<li class="chapter" data-level="4.5.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-5"><i class="fa fa-check"></i><b>4.5.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#example-converting-from-complex-to-tidy-data-formats"><i class="fa fa-check"></i><b>4.6</b> Example: Converting from complex to ‘tidy’ data formats</a><ul>
<li class="chapter" data-level="4.6.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-13"><i class="fa fa-check"></i><b>4.6.1</b> Subsection 1</a></li>
<li class="chapter" data-level="4.6.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-12"><i class="fa fa-check"></i><b>4.6.2</b> Subsection 2</a></li>
<li class="chapter" data-level="4.6.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-6"><i class="fa fa-check"></i><b>4.6.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#introduction-to-reproducible-data-pre-processing-protocols"><i class="fa fa-check"></i><b>4.7</b> Introduction to reproducible data pre-processing protocols</a><ul>
<li class="chapter" data-level="4.7.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-14"><i class="fa fa-check"></i><b>4.7.1</b> Subsection 1</a></li>
<li class="chapter" data-level="4.7.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-13"><i class="fa fa-check"></i><b>4.7.2</b> Subsection 2</a></li>
<li class="chapter" data-level="4.7.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#discussion-questions-6"><i class="fa fa-check"></i><b>4.7.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#rmarkdown-for-creating-reproducible-data-pre-processing-protocols"><i class="fa fa-check"></i><b>4.8</b> RMarkdown for creating reproducible data pre-processing protocols</a><ul>
<li class="chapter" data-level="4.8.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-15"><i class="fa fa-check"></i><b>4.8.1</b> Subsection 1</a></li>
<li class="chapter" data-level="4.8.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-14"><i class="fa fa-check"></i><b>4.8.2</b> Subsection 2</a></li>
<li class="chapter" data-level="4.8.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-7"><i class="fa fa-check"></i><b>4.8.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#example-creating-a-reproducible-data-pre-processing-protocol"><i class="fa fa-check"></i><b>4.9</b> Example: Creating a reproducible data pre-processing protocol</a><ul>
<li class="chapter" data-level="4.9.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-16"><i class="fa fa-check"></i><b>4.9.1</b> Subsection 1</a></li>
<li class="chapter" data-level="4.9.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-15"><i class="fa fa-check"></i><b>4.9.2</b> Subsection 2</a></li>
<li class="chapter" data-level="4.9.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#practice-quiz-4"><i class="fa fa-check"></i><b>4.9.3</b> Practice quiz</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>5</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Improving the Reproducibility of Experimental Data Recording and Pre-Processing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="benefits-of-a-plain-text-format" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Benefits of a plain text format</h1>
<p>Structuring data in a gridded, two-dimensional format will be helpful even if it is
in a file format that is binary, like Excel. However, there are added benefits to
saving the structured data in a plain text format. A plain text format may take
more space (in terms of computer memory) and take longer to process within
other programs; however, its benefits typically outweigh these limitations
<span class="citation">(Hunt, Thomas, and Cunningham 2000)</span>. Advantages include: (1) humans can read the file, and
should always be able to, regardless of changes in and future obsolescence of
computer programs; (2) almost all software programs for analyzing and
processing files can input plain-text files; (3) the Unix system,
which has influenced many existing software programs, especially open-source
programs for data analysis, are based on inputting and outputtin line-based
plain-text files; and (4) plain-text files can be easily tracked with version
control <span class="citation">(Hunt, Thomas, and Cunningham 2000)</span>.
These advantages might become particularly important in cases where researchers
need to combine and integrate heterogeneous data, for example data coming from
different instruments.</p>
<p>Another advantage of storing data in a plain text format is that it makes
version control a much more powerful tool. With plain text files, you can
use version control to see the specific changes to a file. With binary files,
you can typically see if a file was changed, but it’s much harder to see exactly
what within the file was changed.</p>
<blockquote>
<p>“We believe that the best format for storing knowledge persistently is <em>plain text</em>.
With plain text, we give ourselves the ability to manipulate knowledge, both manually
and programmatically, using virtually every tool at our disposal.” <span class="citation">(Hunt, Thomas, and Cunningham 2000)</span></p>
</blockquote>
<blockquote>
<p>“<em>Plain text</em> is made up of printable characters in a form that can be read and
understood directly by people. … Plain text doesn’t mean that the text is
unstructured; XML, XGML, and HTML are great examples of plain text that has
a well-defined structure. You can do everything with plain text that you could
do with some binary format, including versioning.” <span class="citation">(Hunt, Thomas, and Cunningham 2000)</span></p>
</blockquote>
<blockquote>
<p>“The problem with most binary formats is that the context necessary to understand
the data is separate from the data itself. You are artifically divorcing the data
from its meaning. The data may as well be encrypted; it is absolutely meaningless
without the application logic to parse it. With plain text, however, you can
achieve a self-describing data stream that is independent of the application
that created it.” <span class="citation">(Hunt, Thomas, and Cunningham 2000)</span></p>
</blockquote>
<blockquote>
<p>“There are two major drawbacks to using plain text: (1) It may take
more space to store than a compressed binary format, and (2) it may be
computationally more expensive to interpret and process a plain text
file. Depending on your application, either or both of these situations
may be unacceptable—for example, when storing satellite telemetry data,
or as the internal format of a relational database. But even in these
situations, it may be acceptable to store <em>metadata</em> about the raw
data in plain text.” <span class="citation">(Hunt, Thomas, and Cunningham 2000)</span></p>
</blockquote>
<p>There are cases where it may not be best to store laboratory-generated data
in a plain text format. For example, the output from a flow cytometer is large
and would take up a lot (more) computer memory if stored in a plain text format,
and it would take much longer to read and work with the data in analysis software
if it were in that format. However, it will be easier to combine other data from the
experiment (e.g., CFUs counted by hand [?]) with the flow cytometry data if the
other data is in a plain text format.</p>
<blockquote>
<p>“Human-readable forms of data, and self-describing data, will outlive all
other forms of data and the applications that created them. Period. As long as
the data survives, you will have a chance to be able to use it—potentially
long after the original application that wrote it is defunct. You can parse
such a file with only partial knowledge of its format; with most binary files,
you must know all the details of the entire format in order to parse it
successfully.” <span class="citation">(Hunt, Thomas, and Cunningham 2000)</span></p>
</blockquote>
<blockquote>
<p>“Virtually every tool in the computing universe, from source code management
systems to compiler environments to editors and stand-alone filters, can operate on
plain text.” <span class="citation">(Hunt, Thomas, and Cunningham 2000)</span></p>
</blockquote>
<blockquote>
<p>“Unix is famous for being designed around the philosophy of small, sharp tools, each
intended to do one thing well. This philosophy is enabled by using a common underlying
format—the line-oriented, plain text file. Databases used for system administration
(users and passwords, network configuration, and so on) are all kept as plain
text files. … When a system crashes, you may be faced with only a minimal
environment to restore it (you may not be able to access graphics drivers,
for instance). Situations such as this can really make you appreciate the simplicity of
plain text.” <span class="citation">(Hunt, Thomas, and Cunningham 2000)</span></p>
</blockquote>
<blockquote>
<p>“Even in the future of XML-based intelligent agents that travel the wild and dangerous
Internet autonomously, negotiating data interchange among themselves, the ubiquitous
text file will still be there. In fact, in heterogeneous environments the advantages of
plain text can outweight all of the drawbacks. You need to ensure that all parties
can communicate using a common standard. Plain text is that standard.” <span class="citation">(Hunt, Thomas, and Cunningham 2000)</span></p>
</blockquote>
<blockquote>
<p>“Data should be formatted in a way that facilitates computer readability. All too often,
we as humans record data in a way that maximizes its readability to us, but takes a
considerable amount of cleaning and tidying before it can be processed by a
computer. The more data (and metadata) that is computer readable, the more we can
leverage our computers to work with this data.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Unix is the foundational computing environment in bioinformatics because its
design is the antithesis of [a] inflexible and fragile approach. The Unix shell
was designed to allow users to easily build complex programs by interfacing
smaller modular programs together. This approach is the Unix philosophy:
‘This is the Unix philosophy: Write programs that do one thing and do it well.
Write programs to work together. Write programs to handle text streams, because
that is a universal interface.’–Doug McIlory”. <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“While checksums are a great method to check if files are different, they don’t tell
us <em>how</em> the files differ. One approach to this is to compute the <em>diff</em> between
two files using the Unix tool <em>diff</em>. Unix’s <em>diff</em> works line by line, and outputs
blocks (called <em>hunks</em>) that differ between files (resembling Git’s <em>git diff</em> command).”
<span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Many formats in bioinformatics are simple tabular plain-text files delimited by a
character. The most common tabular plain-text file format used in bioinformatics is
tab-delimited. This is not an accident: most Unix tools such as <em>cut</em> and <em>awk</em> treat
tabs as delimiters by default. Bioinformatics evolved to favor tab-delimited formats
because of the convenience of woorking with these files using Unix tools. Tab-delimited
file formats are also simple to parse with scripting languages like Python and Perl,
and easy to load into R.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Tabular plain-text data formats are used extensively in computing. The basic format
is incrediably simple: each row (also known as a record) is kept on its own line, and
each column (also known as a field) is separate by some delimiter. There are three
flavors you will encounter: tab-delimited, comma-separated, and variable space-delimited.
Of these three formats, tab-delimited is the most commonly used in bioinformatics. File
formats such as BED, GTF/GFF, SAM, tabular BLAST output, and VCF are all examples of
tab-delimited files. Columns of a tab-delimited file are separated by a single tab
character (which has the escape code . A common convention (but not a standard)
is to include metadata on the first few lines of a tab-delimited file. These metadata
lines begin with # to differentiate them from the tabular dataa records. Because
tab-delimated files use a tab to delimit columns, tabs in data are not allowed.
Comma-separated values (CSV) is another common format. CSV is similar to tab-delimited,
except the delimiter is a comma character. While not a common in bioinformatics, it
is possible that the data stored in CSV format contain commas (which would interfere with
the ability to parse it). Some variants just don’t allow this, while others use quotes
around entries that could contain commas. Unfortunately, there’s no standard CSV format
that defines how to handle this and many other issues with CSV—though some guidelines
are given in RFC 4180. Lastly, there are space-delimited formats. A few stubborn
bioinformatics programs use a variable number of spaces to separate columns. In general,
tab-delimited formats and CSV are better choices than space-delimited formats because
it’s quite common to encounter data containing spaces.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“In bioinformatics, the plain-text data we work with is often encoded in <em>ASCII</em>. ASCII
is a character encoding scheme that uses 7 bits to represent 128 different values,
including letters (upper- and lowercase), numbers, and special nonvisible characters.
While ASCII only uses 7 bits, nowadays computers use an 8-bit <em>byte</em> (a unit representing
8 bits) to store ASCII characters. … Because plain-text data uses characters to
encode information, our encoding scheme matters. When working with a plain-text file,
98% of the time you won’t have to worry about the details of ASCII and how your file is
encoded. However, the 2% of the time when encoding data does matter—usually when an
invisible non-ASCII character has entered the data—it can lead to major headaches.”
<span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“‘One of the core issues of Bioinformatics is dealing with a profusion of (often poorly
defined or ambiguous) file formats. Some <em>ad hoc</em> simple human readable formats have
over time attained the status of de facto standards.’– Peter Cock et al. (2010)”</p>
</blockquote>
<blockquote>
<p>“Nucelotide (and protein) sequences are stored in two plain-text formats widespread
in bioinformatics: FASTA and FASTQ.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Beware of common pitfalls when working with <em>ad hoc</em> bioinformatics formats. Simple
mistakes over minor details like file formats can consume a disproportionate amount of
time and energy to discover and fix, so mind these details early on.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“It would be unwise to bet that these formats [SAM/BAM files] won’t change (or even be replaced
at some point)—the field of bioinformatics is notorious for inventing new data formats (the same goes with
computing in general) … So learning how to work with specific bioinformatics formats may
seem like a lost cause, skills such as following a format specification, manipulating binary
files, extracting information from bitflags, and working with application programming
interfaces (API) are essential skills when working with any format.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“One of the best features of the SAM/BAM format is that is supports including an extensive
amount of metadata about the samples, the alignment reference, processing steps, etc. to be
included with the file. (Note that in contrast, the FASTQ format doesn’t provide a standard
way to include this metadata; in practice, we use filenames to connect metadata kept in
a separate spreadsheet or tab-delimited file.) Many downstream applications make use of the
metadata contained in the SAM header (and many programs require it).” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<div id="when-two-dimensional-structured-data-formats-might-not-work" class="section level3">
<h3><span class="header-section-number">3.0.1</span> When two-dimensional structured data formats might not work</h3>
<blockquote>
<p>“There are several good reasons why researchers need to know about data storage
options. One is that we may not have control over the format in which the
data is given to us. For example, data from NASA’s Live Access Server is in a
format decided by NASA and we are unlikely to be able to convince NASA to provide it
in a different format. This says that we must know about different formats in order
to gain access to data. Another common situation is that we may have to transfer data
between different applications or between different operating systems. This
effectively involves temporary data storage, so it is useful to understand how
to select an appropriate storage format. It is also possible to be involved in
deciding the format for archiving aa data set. There is no overall best storage
format; the correct choice will depend on the size aand complexity of the data
set aand what the data set will be used for. It is necessary to gain an overview of
the relative merits of all of the data storage formats in order to be able to make an
informed decision for any particular situation.” <span class="citation">(Murrell 2009)</span></p>
</blockquote>
<blockquote>
<p>“Samtools now supports (after version 1) a new, highly compressed file format known as <em>CRAM</em>.
Compressing alignments with CRAM can lead to a 10%–30% filesize reduction compared to BAM (and
quite remarkably, with no significant increase in compression or decompression time compared to
BAM). CRAM is a <em>reference-based</em> compression scheme, meaning only the aligned sequence that’s
different from the reference sequence is recorded. This greatly reduces file size, as many
sequence may align with minimal difference from the reference. As a consequence of this
reference-based approach, it is imperative that the reference is available and does not
change, as this would lead to a loss of data kept in the CRAM format. Because the reference
is so important, CRAM files contain an MD5 checksum of the reference file to ensure it has not changed.
CRAM also has support for multiple different <em>lossy compression</em> methods. Lossy compression
entails some information about an alignment and the original read is lost. For example, it’s possible
to bin base quality scores using a lower resolution binning scheme to reduce the filesize.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Very often we need efficient random access to subsequences of a FASTA file (given regions).
At first glance, writing a script to do this doesn’t seem difficult. We could, for example,
write a script that iterates through FASTA entries, extracting sequences that
overlaps the range specified. However, this is not an efficient method when extracting a
few <em>random</em> subsequences. To see why, consider accessing the sequence from position
chromosome 8 (123,407,082 to 123,419,742) from the mouse genome. This approach would
needlessly parse and load chromosomes 1 through 7 into memory, even though we don’t need to
extract subsequences from these chromosomes. Reading entire chromosomes from disk and copying them
into memory can be quite inefficient—we would have to load all 125 megabytes of chromosome 8
to extract 3.6kb! Extracting numerous random subsequences from a FASTA file can be quite
computationaally costly. A common computational strategy that allows for easy and fast random
access is <em>indexing</em> the file. Indexed files are ubiquitous in bioinformatics.”
<span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“We can avoid needlessly reading the entire file off of the disk by using an index that
points to where certian blocks are in the file. In the case of our FASTA file, the index
essentially stores the location of where each sequence begins in the file (as well as
other necessary information). When we look up a range like chromosome 8 (123,407,082–123,410,744),
<em>samtools faidx</em> uses the information in the index to quickly calculate exactly where
in the file those bases are. Then, using an operation called a file <em>seek</em>, the program
jumps to this exact position (called the <em>offset</em>) in the file and starts reading the
sequence. Having precomputed file offsets combined with the ability to jump to those
exact positions is what makes accessing sections of an indexed file fast.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Many standard bioinformatics data formats (GTF/GFF, BED, VCF/BCF, SAM/BAM) … store tabular data in
single <em>flat file</em> formats. Flat file formats don’t have an internal hierarchy or structured
relationship with other tables. While we’re able to join tables using Unix tools like <em>join</em>,
and R’s <em>match</em> and <em>merge</em> functions, the files themselves do not encode any relationships
between tables. Flat file formats are widely used in bioinformatics because they’re simple,
flexible, and portable, but occasionally we do need to store and manipulate data thaat is
best represented in many related tables—this is where <em>relational databases</em> are useful.
Unlike flat files, relational databases can contain multiple tables. Relational databases
also support methods that use relationships between tables to join and extract specific
records using specialized queries.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>SQLite “doesn’t require any setup—you can create a database and start making queries with
minimal time spent on configuring and administrating your database. In contrast, other
database systems like MySQL and PostgreSQL require extensive configuration just to get
them up and running. While SQLite is not as powerful as these larger database systems,
it works surprisingly well for databases in the gigabytes range.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“A lane of sequencing data is too big to fit in the memory of most standard
desktops. If I needed to search for the exact string ‘GTGATTAACTGCGAA’ in this
data, I couldn’t open up a lane of data in Notepad and use the Find feature
to pinpoint where it occurs—there simply isn’t enough memory to hold all
those nucleotides in memory. Instead, most tools rely on streams of data,
being read from a source and actively processed. Both general Unix tools and
many bioinformatics programs are designed to take input through a stream and
pass output through a different stream. It’s these text streams that allow us
to both couple programs together into workflows and process data without
storing huge amounts of data in our computers’ memory.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Passing the output of one program directly into the input of another
program with pipes is a computationally efficient and simple way to interface
Unix programs. This is another reason why bioinformaticians (and software engineers
in general) like Unix. Pipes allow us to build larger, more complex tools from
modular parts. It doesn’t matter what language a program is written in, either; pipes
will work between anything as long as both programs understand the data passed
between them. As the lowest common denominator between most programs, plain-text
streams are often used—a point that McIlroy makes in his quote about the
Unix philosophy.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Data compression, the process of condensing data so that it takes up less space (on
disk drives, in memory, or across network transfers), is an indespensible technology
in modern bioinformatics. For example, sequences from a recent Illumina HiSeq run
when compressed with Gzip take up 21,408,674,240 bytes, which is a bit under 20
gigabytes. Uncompressed, this file is a whopping 63,203,414,514 bytes (around 58
gigabytes). This FASTQ file has 150 million 200bp reads, which is 10x coverage of
the hexaploid wheat genome. The compression ratio (uncompressed size/ compressed size)
of this data is approximately 2.95, which translates to a significant space saving of
about 66%. Your own bioinformatics projects will likely contain much more data, especially
as sequencing costs continue to drop and it’s possible to sequence genomes to higher depth,
include more biological replicates or time points in expression studies, or sequence
more individuals in genotyping studies. For the most part, data can remain compressed on
the disk throughout processing and analysis. Most well-writted bioinformatics tools can
work natively with compressed data as input, without requiring us to decompress it to disk
first. Using pipes and redirection, we can stream compressed data and write compressed files
directly to the disk. Additionally, common Unix tools like <em>cat</em>, <em>grep</em>, and <em>less</em> all
have variants that work with compressed data, and Python’s <em>gzip</em> module allows us to
read and write compressed data from within Python. So while working with large datasets
in bioinformatics can be challenging, using the compression tools in Unix and software
libraries make our lives much easier.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“The <em>pileup format</em> [is] a plain-text format that summarizes reads’ bases at each chromosome
position by stacking or ‘piling up’ aligned reads.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“<em>Out-of-memory approaches</em> [are] computational strategies built arouond storing and working
with data kept out of memory on the disk. Reading data from a disk is much, much slower than working
with data in memory… but in many cases this is the approach we have to take when in-memory
(e.g., loading the entire dataset into R) or streaming approaches (e.g., using Unix pipes …)
aren’t appropriate.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“We often need fast read-only access to data linked to a genomic location or range. For the scale
of data we encounter in genomics, retrieving this type of data is not trivial for a few reasons.
First the data might not fit entirely in memory, requiring an approach where data is kept out of
memory (in other words, on a slow disk). Second, even powerful relational database systems can
be sluggish when querying out millions of entries that overlap a specific region—an incrediably
common operation in genomics. [BGZF and Tabix] are specifically designed to get around these
limitations, allowing fast random-access of tab-delimited genome position data.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“While <em>gzip</em> compresses the <em>entire</em> file, BGZF files are compressed in <em>blocks</em>. These blocks
provide BGZF files with a useful feature that <em>gzip</em>-compressed files don’t have: we can jump to
and decompress a specific block without having to decompress the entire file. Block compression
combined with file indexing is what enables fast random access of alignments from large BAM
files with <em>samtools view</em>.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“The data revolution within the biological and physical science world is generating massive amounts
of data from … a wide range of … projects, such as those undertaken at the Large Hadron Collider
and genomics-proteomics-metabolomics research.” <span class="citation">(Keller et al. 2017)</span></p>
</blockquote>
<blockquote>
<p>“Information in a Unix system is stored in <em>files</em>, which are much like ordinary office files.
Each file has a name, contents, a place to keep it, and some administrative information, such
as who owns it and how bit it is. A file might contain a letter, or a list of names and addresses,
or the source statements of a program, or data to be used by a program, or even programs in their
executable form and other non-textual material.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“The Unix file system is organized so you can maintain your own personal files without interfering
with files belonging to other people, and keep people from interfering with you too.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“Everything in the Unix system is a file. That is less of an oversimplification than you
might think. When the first version of the system was designed, before it even had
a name, the discussions focused on the structure of a file system that would be clean
and easy to use. The file system is central to the success and convenience of the Unix
system. It is one of the best examples of the ‘keep it simple’ philosophy, showing
the power achieved by careful implementation of a few well-chosen ideas.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“A file is a sequence of bytes. (A byte is aa small chunk of information, typically 8 bits
long. For our purposes, a byte is equivalent to a character.) No structure is imposed on
a file by the system, and no meaning is attaached to its contents—the meaning of the bytes
depends solely on the programs that interpret the file. Furthermore, … this is true not
just of disc files but of peripheral devices as well. Magnetic tapes, mail messages, characters
typed on the keyboard, line printer output, data flowing in pipes—each of these is just
a sequence of bytes as far as the systems and the programs in it are concerned.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“Programs [in Unix] retreive the data in a file by a system call (a subroutine in the kernel) called
<code>read</code>. Each time <code>read</code> is called, it returns the next part of a file—the next line of text typed
on the terminal, for example. <code>read</code> also says how many bytes of the file were returned, so end of file
is assumed when a <code>read</code> says ‘zero bytes are being returned’. If there were any bytes left, <code>read</code>
would have returned some of them.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“The format of a file is determined by the programs that use it; there is a wide variety of file
types, perhaps because there is a wide variety of programs. But since file types are not determined
by the file system, the kernel can’t tell you the type of a file: it doesn’t know it. The <code>file</code>
command makes an educated guess … To determine the types, <code>file</code> doesn’t pay attention to the
names (although it could have), because naming conventions are just conventions, and thus not
perfectly reliable. For example, files suffixed ‘.c’ are almost always C source, but there is
nothing to prevent you from creating a ‘.c’ file with arbitrary contents. Instead, <code>file</code> reads the
first hundred bytes of a file and looks for clues to that file type. … In Unix systems there is
just one kind of file, and all that is required to access a file is its name. The lack of file formats
is an advantage overall—programmers don’t need to worry about file types, and all
the standard programs will work on any file.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“Non-text files definitely have their place. For example, very laarge databases usually need extra
address information for rapid access; this has to be binary for efficiency. But every file format
that is not text must have its own family of support programs to do things that the standard tools
could perform if the format were text. Text files may be a little less efficient in maachine cycles,
but this must be balanced against the cost of extra software to maintain more specialized formats.
If you design a file format, you should think carefully before choosing a non-textual representation.”
<span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
</div>
<div id="recording-expermental-data-in-a-structured-format" class="section level3">
<h3><span class="header-section-number">3.0.2</span> Recording expermental data in a structured format</h3>
<blockquote>
<p>“It is important that the goal of standardization is well defined and limited.
Instead of trying to standardize everything, it is better to rely on other
standards and be consistent with them… In fact it is detrimental to the
community not to use relevant standards developed by others.” <span class="citation">(Brazma, Krestyaninova, and Sarkans 2006)</span></p>
</blockquote>
<blockquote>
<p>“Simplicity, but not oversimplification, is the key to success [in developing
standards].” <span class="citation">(Brazma, Krestyaninova, and Sarkans 2006)</span></p>
</blockquote>
<p>First, you can still use spreadsheets, but reduce their use to recording data,
leaving all data cleaning and analysis to be handled with other software. To make
it easier to collaborate with statisticians and to interface with a program like
R for data cleaning and analysis, it will be easiest if you set up your data
recording to include with other statistical programs like R or Python. These
steps are described in a later section, “…”.</p>
<ul>
<li>Each sheet of the spreadsheet should contain data from a single
experiment.</li>
<li>Never use whitespace to represent a meaningful separation in data within
a spreadsheet. Never include multiple tables of data in the same sheet.</li>
<li>The first row of the spreadsheet should include a short column name for
each column with data. All column name information should be within a single row
(i.e., avoid subheadings). Avoid any special characters (e.g., “%”) in column
names. Instead, use only letters, numbers, and underscores ("_"), and start with a letter.
It is especially helpful if you can avoid spaces in column names.</li>
<li>Missing data should be represented consistently in cells. “NA” is one choice. If
you want to clarify why data is missing, it’s much better to add a column (e.g., “why_missing”)
where you can provide those details in text, rather than combining within a single column
numerical observation data with textual reasons for missingness in cells with missing values.</li>
</ul>
<p>Next, you could record data using a statistical language like R. There is an
excellent Integrated Development Environment for R called RStudio, and it creates a
much clearer interface with R compared to running R from a commond line, particularly for new users. RStudio allows you to open delimited plain text files, like csvs, using
a grid-style interface. This grid-style interface looks very similar to a
spreadsheet, but lacks the ability to include formulas or macros. Therefore, this
format enforces a separation of the recording of raw data from the cleaning and
analysis of the data.</p>
<p>[R Project templates]</p>
<p>Data cleaning and analysis can then be shifted away from the files used to
record the data and into reproducible scripts. These scripts can be clearly
documented, either through comments in the code or through open source
documentation tools like RMarkdown than interweave code and text in a way that
allows the creation of documents that are easier to read than commented code.</p>
<p>This documentation should explain why each step is being done. In cases where
it is not immediately evident from the code <em>how</em> the step is being done, this
should be documented as well. Any assumptions being used should be clarified in
the documentation.</p>
</div>
<div id="applied-exercise" class="section level3">
<h3><span class="header-section-number">3.0.3</span> Applied exercise</h3>

</div>
<div id="the-tidy-data-format" class="section level2">
<h2><span class="header-section-number">3.1</span> The ‘tidy’ data format</h2>
<p>The “tidy” data format is an implementation of a structured data format popular
among statisticians and data scientists. By consistently using this data format,
researchers can combine simple, generalizable tools to perform complex tasks in
data processing, analysis, and visualization. We will explain what
characteristics determine if a dataset is “tidy” and how use of the “tidy”
implementation of a structure data format can improve the ease and efficiency of
“Team Science”.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>List characteristics defining the “tidy” structured data format</li>
<li>Explain the difference between the a structured data format (general concept)
and the ‘tidy’ data format (one popular implementation)</li>
</ul>
<div id="the-tidy-data-format-1" class="section level3">
<h3><span class="header-section-number">3.1.1</span> The “tidy” data format</h3>
<blockquote>
<p>“Software systems are transparent when they don’t have murky corners or hidden
depths. Transparency is a passive quality. A program is passive when it is possible
to form a simple mental model of its behavior that is actuaally predictive for all
or most cases, because you can see through the machinery to what is actually going
on.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Software systems are discoverable when they include features that are designed
to help you build in your mind a correct mental model of what they do and how they
work. So, for example, good documentation helps discoverability to a programmer. Discoverability
is an active quality. To achieve it in your software, you cannot merely fail to be obscure,
you have to go out of your way to be helpful.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Elegant code does much with little. Elegant code is not only correct but visibly,
<em>transparently</em> correct. It does not merely communicate an algorithm to a computer,
but also conveys insight and assurance to the mind of a human that reads it. By seeking
elegance in our code, we build better code. Learning to write transparent code is a first,
long step toward learning how to write elegant code—and taking care to make code
discoverable helps us learn how to make it transparent. Elegant code is both transparent and
discoverable.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“To design for transparency and discoverability, you need to apply every tactic for
keeping your code simple, and also concentrate on the ways in which your code is a
communication to other human beings. The first questions to ask, after ‘Will this design
work?’ are ‘Will it be reaadable to other people? Is it elegant?’ We hope it is clear …
that these questions are not fluff and that elegance is not a luxury. These qualities
in the human reaction to software are essential for reducing its bugginess and
increasing its long-term maintainability.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“The Unix style of design applies the do-one-thing-well approach at the level of
cooperating programs as well as cooperating routines within a program,
emphasizing small programs connected by well-defined interprocess communication
or by shared files. Accordingly, the Unix operating system encourages us to break our
programs down into simple subprocesses, and to concentrate on the interfaces between
these subprocesses.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“The ability to combine programs [with piping] can be extremely useful. But the real
win here is not cute combinations; it’s that because both pipes and <em>more(1)</em> exist,
<em>other programs can be simpler</em>. Pipes mean that programs like <em>ls(1)</em> (and other
programs that write to standard out) don’t have to grow their own pagers—and we’re
saved from a word of a thousand built-in pagers (each, naturally, with its own divergent
look and feel). Code bloat is avoided and global complexity reduced. As a bonus, if
anyone needs to customize pager behavior, it can be done in <em>one</em> place, by changing
<em>one</em> program. Indeed, multiple pagers can exist, and will all be useful with every application
that writes to standard output.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Unix was born in 1969 and has been in continuous production use ever since. That’s several
geological eras by computer industry standards. … Unix’s durability and adaptability have
been nothing short of astonishing. Other technologies have come and gone like mayflies.
Machines have increased a thousand-fold in power, languages have mutated, industry practice
has gone through multiple revolutions—and Unix hangs in there, still producing, still paying
the bills, and still commanding loyalty from many of the best and brightest software technologists
on the planet.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“One of the many consequences of the exponential power-versus-time curve in computing, and the
corresponding pace of software development, is that 50% of what one knows becomes obsolete over
every 18 months. Unix does not abolish this phenomenon, but does do a good job of containing it.
There’s a bedrock of unchanging basics—languages, system calls, and tool invocations—that one
can actually keep for entire years, even decades. Elsewhere it is impossible to predict what will
be stable; even entire operating systems cycle out of use. Under Unix, there is a fairly sharp
distinction between transient knowledge and lasting knowledge, and one can know ahead of time
(with about 90% certainty) which category something is likely to fall in when one learns it. Thus
the loyalty Unix commands.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
</div>
<div id="the-tidy-data-format-as-a-structured-data-format" class="section level3">
<h3><span class="header-section-number">3.1.2</span> The “tidy” data format as a structured data format</h3>
</div>
<div id="practice-quiz" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Practice quiz</h3>

</div>
</div>
<div id="designing-templates-for-tidy-data-collection" class="section level2">
<h2><span class="header-section-number">3.2</span> Designing templates for “tidy” data collection</h2>
<p>This module will move from the principles of the “tidy” data format to the
practical details of designing a “tidy” data format to use when collecting
experimental data. We will describe common issues that prevent biomedical
research datasets from being “tidy” and show how these issues can be avoided. We
will also provide rubrics and a checklist to help determine if a data collection
template complies with a “tidy” format.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Identify characteristics that keep a dataset from being ‘tidy’</li>
<li>Convert data from an “untidy” to a “tidy” format</li>
</ul>
<div id="subsection-1" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Subsection 1</h3>
<blockquote>
<p>“Or maybe your goal is that your data is <em>usable</em> in a wide range of
applications? If so, consider adopting standard formats and metadata
standards early on. At the very least, keep track of versions of data
and code, with associated dates.” <span class="citation">(Goodman et al. 2014)</span></p>
</blockquote>
<blockquote>
<p>“Standards for data include, for example, data formats, data exchange
protocols, and meta-data controlled vocabularies.” <span class="citation">(Barga et al. 2011)</span></p>
</blockquote>
<blockquote>
<p>“Software systems are transparent when they don’t have murky corners or hidden
depths. Transparency is a passive quality. A program is passive when it is possible
to form a simple mental model of its behavior that is actuaally predictive for all
or most cases, because you can see through the machinery to what is actually going
on.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Software systems are discoverable when they include features that are designed
to help you build in your mind a correct mental model of what they do and how they
work. So, for example, good documentation helps discoverability to a programmer. Discoverability
is an active quality. To achieve it in your software, you cannot merely fail to be obscure,
you have to go out of your way to be helpful.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Elegant code does much with little. Elegant code is not only correct but visibly,
<em>transparently</em> correct. It does not merely communicate an algorithm to a computer,
but also conveys insight and assurance to the mind of a human that reads it. By seeking
elegance in our code, we build better code. Learning to write transparent code is a first,
long step toward learning how to write elegant code—and taking care to make code
discoverable helps us learn how to make it transparent. Elegant code is both transparent and
discoverable.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“To design for transparency and discoverability, you need to apply every tactic for
keeping your code simple, and also concentrate on the ways in which your code is a
communication to other human beings. The first questions to ask, after ‘Will this design
work?’ are ‘Will it be reaadable to other people? Is it elegant?’ We hope it is clear …
that these questions are not fluff and that elegance is not a luxury. These qualities
in the human reaction to software are essential for reducing its bugginess and
increasing its long-term maintainability.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Software is maintainable to the extent that people who are not its author can
successfully understand and modify it. Maintainability demands more than code that
works; it demands code that follows the Rule of Clarity and communicates successfully
to human beings as well as the computer.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
</div>
<div id="applied-exercise-1" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Applied exercise</h3>

</div>
</div>
<div id="example-creating-a-template-for-tidy-data-collection" class="section level2">
<h2><span class="header-section-number">3.3</span> Example: Creating a template for “tidy” data collection</h2>
<p>We will walk through an example of creating a template to collect data in a
“tidy” format for a laboratory-based research project, based on a research
project on drug efficacy in murine tuberculosis models. We will show the initial
“untidy” format for data recording and show how we converted it to a “tidy”
format. Finally, we will show how the data can then easily be analyzed and
visualized using reproducible tools.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Understand how the principles of “tidy” data can be applied for a real, complex research project;</li>
<li>List advantages of the “tidy” data format for the example project</li>
</ul>
<div id="subsection-1-1" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Subsection 1</h3>
</div>
<div id="subsection-2" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Subsection 2</h3>
</div>
<div id="discussion-questions-1" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Discussion questions</h3>

</div>
</div>
<div id="power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files" class="section level2">
<h2><span class="header-section-number">3.4</span> Power of using a single structured ‘Project’ directory for storing and tracking research project files</h2>
<p>To improve the computational reproducibility of a research project, researchers
can use a single ‘Project’ directory to collectively store all research data,
meta-data, pre-processing code, and research products (e.g., paper drafts,
figures). We will explain how this practice improves the reproducibility and
list some of the common components and subdirectories to include in the
structure of a ‘Project’ directory, including subdirectories for raw and
pre-processed experimental data.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Describe a ‘Project’ directory, including common components and subdirectories</li>
<li>List how a single ‘Project’ directory improves reproducibility</li>
</ul>
<div id="subsection-1-2" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Subsection 1</h3>
<p>One study surveyed over 250 biomedical researchers at the University of Washington.
They noted that, “a common theme surrounding data management and analysis was that
may researchers preferred to utilize their own individual methods to organize data.
The varied ways of managing data were accepted as functional for most present needs.
Some researchers admitted to having no organizational methodology at all, while others
used whatever method best suited their individual needs.” <span class="citation">(Anderson et al. 2007)</span>
One respondent answered, “They’re not organized in any way—they’re just thrown into
files under different projects,” while another said “I grab them when I need them, they’re
not organized in any decent way,” and another, “It’s not even organized—a file on a central
computer of protocols that we use, common lab protocols but those are just individual
Word files within a folder so it’s not searchable per se.” <span class="citation">(Anderson et al. 2007)</span></p>
<blockquote>
<p>“In general, data reuse is most possible when: 1) data; 2) metadata (information
describing the data); and 3) information about the process of generating those data,
such as code, are all provided.” <span class="citation">(Goodman et al. 2014)</span></p>
</blockquote>
<blockquote>
<p>“So far we have used filenames without ever saying what a legal name is, so it’s time for a couple
of rules. First, filenames are limited to 14 characters. Second, although you can use almost any
character in a filename, common sense says you should stick to ones that are visible, and that you
should avoid characters that might be used with other meanings. … To avoid pitfalls, you would
do well to use only letters, numbers, the period and the underscore until you’re familiar with the
situation [i.e., characters with pitfalls]. (The period and the underscore are conventionally used
to divide filenames into chunks…) Finally, don’t forget that case distinctions matter—junk, Junk,
and JUNK are three different names.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“The [Unix] system distinguishes your file called ‘junk’ from anyone else’s of the same name. The
distinction is made by grouping files into <em>directories</em>, rather in the way that books are placed om
shelves in a library, so files in different directories can have the same name without any conflict.
Generally, each user haas a personal or <em>home directory</em>, sometimes called login directory, that
contains only the files that belong to him or her. When you log in, you are ‘in’ your home directory.
You may change the directory you are working in—often called your working or <em>current directory</em>—but
your home directory is always the same. Unless you take special action, when you create a new file it is
made in your current directory. Since this is initially your home directory, the file is unrelated
to a file of the same name that might exist in someone else’s directory. A directory can contain
other directories as well as ordinary files … The natural way to picture this organization is as a
tree of directories and files. It is possible to move around within this tree, and to find any file in the system
by starting at the root of the tree and moving along the proper branches. Conversely, you can start where
you are and move toward the root.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“The name ‘/usr/you/junk’ is called the <em>pathname</em> of the file. ‘Pathname’ has an intuitive meaning:
it represents the full name of the path from the root through the tree of directories to a particular
file. It is a universal rule in the Unix system that wherever you can use an ordinary filename, you can
use a pathname.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“If you work regularly with Mary on information in her directory, you can say ‘I want to work on Mary’s
files instead of my own.’ This is done by changing your current directory with the <code>cd</code> command…
Now when you use a filename (without the /’s) as an argument to <code>cat</code> or <code>pr</code>, it refers to the file
in Mary’s directory. Changing directories doesn’t affect any permissions associated with a file—if you
couldn’t access a file from your own directory, changing to another directory won’t alter that fact.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“It is usually convenient to arrange your own files so that all the files related to one thing are in a
directory separate from other projects. For example, if you want to write a book, you might want to
keep all the text in a directory called ‘book’.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“Suppose you’re typing a large document like a book. Logically this divides into many small pieces,
like chapters and perhaps sections. Physically it should be divided too, because it is cumbersome
to edit large files. Thus you should type the document as a number of files. You might have separate
files for each chapter, called ‘ch1’, ‘ch2’, etc. … With a systematic naming convention, you can tell at
a glance where a particular file fits into the whole. What if you want to print the whole book? You could
say <code>$ pr ch1.1 ch1.2 ch 1.3 ...</code>, but you would soon get bored typing filenames and start to make mistakes.
This is where filename shorthand comes in. If you say <code>$ pr ch*</code> the shell takes the <code>*</code> to mean ‘any
string of characters,’ so ch* is a pattern that matches all filenames in the current directory that
begin with ch. The shell creates the list, in alphabetical order, and passes the list to <code>pr</code>. The
<code>pr</code> command never sees the <code>*</code>; the pattern match that the shell does in the current directory
generates aa list of strings that are passed to <code>pr</code>.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“The current directory is an attribute of a process, not a person or a program. … The notion of a
current directory is certainly a notational convenience, because it can save a lot of typing, but
its real purpose is organizational. Related files belong together in the same directory. ‘/usr’ is
often the top directory of a user file system… ‘/usr/you’ is your login directory, your current
directory when you first log in. … Whenever you embark on a new project, or whenever you have
a set of related files … you could create a new directory with <code>mkdir</code> and put the files there.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“Despite their fundamental properties inside the kernel, directories sit in the file system as
ordinary files. They can be read as ordinary files. But they can’t be created or written as
ordinary files—to preserve its sanity and the users’ files, the kernel reserves to itself all
control over the contents of directories.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“A file has several components: a name, contents, and administrative information such as
permissions and modifications times. The administrative information is stored in the inode
(over the years, the hyphen fell out of ‘i-node’), along with essential system data such as
how long it is, where on the disc the contents of the file are stored, and so on. …
It is important to understand inodes, not only to appreciate the options on <code>ls</code>, but because
in a strong sense the inodes <em>are</em> the files. All the directory hierarchy does is provide
convenient names for files. The system’s name for a file is its <em>i-number</em>: the number of the
inode holding the file’s information. … It is the i-number that is stored in the first two bytes
of a directory, before the name. …
The first two bytes in each directory entry are the only connection between the name of a file and its
contents. A filename in a directory is therefore called a <em>link</em>, because it links a name in the
directory hierarchy to the inode, and hence to the data. The same i-number can appear in more than
one directory. The <code>rm</code> command does not actually remove the inodes; it removes directory entries
or links. Only when the last link to a file disappears does the system remove the inode, and hence
the file itself. If the i-number in a directory entry is zero, it means that the link has been
removed, but not necessarily the contents of the file—there may still be a link somewhere else.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
</div>
<div id="subsection-2-1" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Subsection 2</h3>
</div>
<div id="practice-quiz-1" class="section level3">
<h3><span class="header-section-number">3.4.3</span> Practice quiz</h3>

</div>
</div>
<div id="creating-project-templates" class="section level2">
<h2><span class="header-section-number">3.5</span> Creating ‘Project’ templates</h2>
<p>Researchers can use RStudio’s ‘Projects’ can facilitate collecting research
files in a single, structured directory, with the added benefit of easy use of
version control. Researchers can gain even more benefits by consistently
structuring all their ‘Project’ directories. We will demonstrate how to
implement structured project directories through RStudio, as well as how RStudio
enables the creation of a ‘Project’ for initializing consistently-structured
directories for all of a research group’s projects.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Be able to create a structured <code>Project</code> directory within RStudio</li>
<li>Understand how RStudio can be used to create ‘Project’ templates</li>
</ul>
<div id="subsection-1-3" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Subsection 1</h3>
</div>
<div id="subsection-2-2" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Subsection 2</h3>
</div>
<div id="discussion-questions-2" class="section level3">
<h3><span class="header-section-number">3.5.3</span> Discussion questions</h3>

</div>
</div>
<div id="example-creating-a-project-template" class="section level2">
<h2><span class="header-section-number">3.6</span> Example: Creating a ‘Project’ template</h2>
<p>We will walk through a real example, based on the experiences of one of our
Co-Is, of establishing the format for a research group’s ‘Project’ template,
creating that template using RStudio, and initializing a new research project
directory using the created template. This example will be from a
laboratory-based research group that studies the efficacy of tuberculosis drugs
in a murine model.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Create a ‘Project’ template in RStudio to initialize consistently-formatted
‘Project’ directories</li>
<li>Initialize a new ‘Project’ directory using this template</li>
</ul>
<div id="subsection-1-4" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Subsection 1</h3>
</div>
<div id="subsection-2-3" class="section level3">
<h3><span class="header-section-number">3.6.2</span> Subsection 2</h3>
</div>
<div id="applied-exercise-2" class="section level3">
<h3><span class="header-section-number">3.6.3</span> Applied exercise</h3>

</div>
</div>
<div id="harnessing-version-control-for-transparent-data-recording" class="section level2">
<h2><span class="header-section-number">3.7</span> Harnessing version control for transparent data recording</h2>
<p>As a research project progresses, a typical practice in many experimental
research groups is to save new versions of files (e.g., ‘draft1.doc’,
‘draft2.doc’), so that changes can be reverted. However, this practice leads to
an explosion of files, and it becomes hard to track which files represent the
‘current’ state of a project. Version control allows researchers to edit and
change research project files more cleanly, while maintaining the power to
‘backtrack’ to previous versions, messages included to explain changes. We will
explain what version control is and how it can be used in research projects to
improve the transparency and reproducibility of research, particularly for data
recording.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Describe version control<br />
</li>
<li>Explain how version control can be used to improve reproducibility
for data recording</li>
</ul>
<div id="subsection-1-5" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Subsection 1</h3>
<p>“Or maybe your goal is that your data is <em>usable</em> in a wide range of
applications? If so, consider adopting standard formats and metadata
standards early on. At the very least, keep track of versions of data
and code, with associated dates.” <span class="citation">(Goodman et al. 2014)</span></p>
<p><strong>Email attachments in lieu of common access files.</strong></p>
<p>…</p>
<p>For example, one group of researchers investigated a large collection of emails
from Enron <span class="citation">(Hermans and Murphy-Hill 2015)</span>. They found that passing Excel files through
email attachements was a common practice, and that messages within emails
suggested that spreadsheets were stored locally, rather than in a location that
was accessible to all team members <span class="citation">(Hermans and Murphy-Hill 2015)</span>, which meant that team
members might often be working on different versions of the same spreadsheet
file. They note that “the practice of emailing spreadsheets is known to result in
serious problems in terms of accountability and errors, as people do not have
access to the latest version of a spreadsheet, but need to be updated of changes
via email.” <span class="citation">(Hermans and Murphy-Hill 2015)</span></p>
<p>“Team members regularly pass data files back and forth by hand, by email, and by
using shared lab or project servers, websites, and databases.”
<span class="citation">(Edwards et al. 2011)</span></p>
<p><strong>Version control for spreadsheets</strong></p>
<p>“Recent versions of spreadsheets now incorporate a ‘Traack Changes’ functionality
which enables highlighting of changes made by different users along with a comment
and review system. Such tools are a start toward this but more robust version control
systems are required particularly in the context of increasingly online and
collaborative method of working where large teams interact with a single document
concurrently.” <span class="citation">(Birch, Lyford-Smith, and Guo 2018)</span></p>
</div>
<div id="subsection-2-4" class="section level3">
<h3><span class="header-section-number">3.7.2</span> Subsection 2</h3>
</div>
<div id="discussion-questions-3" class="section level3">
<h3><span class="header-section-number">3.7.3</span> Discussion questions</h3>

</div>
</div>
<div id="enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms" class="section level2">
<h2><span class="header-section-number">3.8</span> Enhance the reproducibility of collaborative research with version control platforms</h2>
<p>Once a researcher has learned to use <em>git</em> on their own computer for
local version control, they can begin using version control platforms (e.g.,
<em>GitLab</em>, <em>GitHub</em>) to collaborate with others under version
control. We will describe how a research team can benefit from using a version
control platform to work collaboratively.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>List benefits of using a version control platform to collaborate
on research projects, particularly for reproducibility</li>
<li>Describe the difference between version control (e.g., <em>git</em>) and
a version control platform (e.g., <em>GitLab</em>)</li>
</ul>
<div id="subsection-1-6" class="section level3">
<h3><span class="header-section-number">3.8.1</span> Subsection 1</h3>
<p><strong>VC platforms as a form of back-up.</strong></p>
<p>One study surveyed neuroscience researchers at a UK institute. “The backup ‘rule
of three’ states that for a file to be sufficiently backed up it should be kept
in three separate locations using two different types of media with one offsite
backup. A lack of an adequate backup solution could mean permanently lost data,
effort and time. In this research, more than 82% of the respondents seemed to be
unaware of suitable backup procedures to protect their data. Some respondents
kept a single backup of work on external hard disks. Others used the
Universities local networked servers as their means of backup.”
<span class="citation">(AlTarawneh and Thorne 2017)</span></p>
<p>“A good approach is to store at least three copies in at least two
geographically distributed locations (e.g., original location such as a desktop
computer, an external hard drive, and one or more remote sites) and to adopt a
regular schedule for duplicating the data (i.e., backup).” <span class="citation">(Michener 2015)</span></p>
</div>
<div id="subsection-2-5" class="section level3">
<h3><span class="header-section-number">3.8.2</span> Subsection 2</h3>
</div>
<div id="discussion-questions-4" class="section level3">
<h3><span class="header-section-number">3.8.3</span> Discussion questions</h3>

</div>
</div>
<div id="using-git-and-gitlab-to-implement-version-control" class="section level2">
<h2><span class="header-section-number">3.9</span> Using git and GitLab to implement version control</h2>
<p>For many years, use of version control required use of the command line,
limiting its accessibility to researchers with limited programming experience.
However, graphical interfaces have removed this barrier, and RStudio has
particularly user-friendly tools for implementing version control. In this
module, we will show how to use <em>git</em> through RStudio’s user-friendly
interface and how to connect from a local computer to <em>GitLab</em> through
RStudio.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Understand how to set up and use <em>git</em> through RStudio’s interface</li>
<li>Understand how to connect with <em>GitLab</em> through RStudio to collaborate on<br />
research projects while maintaining version control</li>
</ul>
<div id="subsection-1-7" class="section level3">
<h3><span class="header-section-number">3.9.1</span> Subsection 1</h3>
<blockquote>
<p>“When the system prints the prompt <code>$</code> and you type commands that get
executed, it’s not the kernel that is talking to you, but a go-between called
the command interpreter or <em>shell</em>. The shell is just an ordinary program like
<code>date</code> or <code>who</code>, although it can do some remarkable things. The fact that the shell
sits between you and the facilities of the kernel has real benefits, some of which
we’ll talk about here. There are three main ones: (1) Filename shorthands: you can
pick up a whole set of filenames as arguments to a program by specifying a
pattern for the names—the shell will find the filenames that fit your pattern;
(2) Input-output redirection: you can arrange for the output of any program to
go into a file instead of onto the terminal, and for the input to come from
a file instead of the terminal. Input and output can even be connected to
other programs. (3) Personalizing the environment: you can define your own
commands and shorthands.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“Suppose you’re typing a large document like a book. Logically this divides into many small pieces,
like chapters and perhaps sections. Physically it should be divided too, because it is cumbersome
to edit large files. Thus you should type the document as a number of files. You might have separate
files for each chapter, called ‘ch1’, ‘ch2’, etc. … With a systematic naming convention, you can tell at
a glance where a particular file fits into the whole. What if you want to print the whole book? You could
say <code>$ pr ch1.1 ch1.2 ch 1.3 ...</code>, but you would soon get bored typing filenames and start to make mistakes.
This is where filename shorthand comes in. If you say <code>$ pr ch*</code> the shell takes the <code>*</code> to mean ‘any
string of characters,’ so ch* is a pattern that matches all filenames in the current directory that
begin with ch. The shell creates the list, in alphabetical order, and passes the list to <code>pr</code>. The
<code>pr</code> command never sees the <code>*</code>; the pattern match that the shell does in the current directory
generates aa list of strings that are passed to <code>pr</code>. The crucial point is that filename shorthand
is not a property of the <code>pr</code> command, but a service of the shell. Thus you can use it to generate
a sequence of filenames for <em>any</em> command.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“One of the virtues of the Unix system is that there are several ways to bring it closer to
your personal taste or the conventions of your local computing environmentl. … If there is a file
named ‘.profile’ in your login directory, the shell will execute the commands in it when you log in,
before printing the first prompt. So you can put commands into ‘.profile’ to set up your environment
as you like it, and they will be executed every time you log in. …
Some of the properties of the shell are actually controlled by so-called <em>shell variables</em>, with
values that you can access and set yourself. For example, the prompt string, which we have been showing
as <code>$</code>, is acually stored in a shell variable called ‘PS1’, and you can set it to anything you like, like
this <code>PS1='Yes dear?'</code>. … Probably the most useful shell variable is the one that controls where the shell
looks for commands. Recall that when you type the name of a command, the shell normally looks for it
first in the current directory, then in ‘/bin’, and then in ‘/usr/bin’. This sequence of directories
is called the <em>search path</em>, and is stored in a shell variable called ‘PATH’. If the default search
path isn’t what you want, you can change it, again usually in your ‘.profile’. … It is also possible
to use variables for abbreviation. If you find yourself frequently referring to some directory with
a long name, it might be worthwhile adding a line like <code>d=/horribly/long/directory/name</code> to your profile,
so that you can say things like <code>$cd $d</code>. Personal variables like <code>d</code> are conventionally spelled
in lower case to distinguish them from those used by the shell itself, like <code>PATH</code>.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“The culmination of your login efforts is a <em>prompt</em>, usually a single character, indicating that the
system is ready to accept commands from you. The prompt is most likely to be a dolloar sign or a percent
sign, but you can change it to anything you like… The prompt is actually printed by a program called
the <em>command interpreter</em> or <em>shell</em>, which is your main interface to the system. … Once you receive
the prompt, you can type <em>commands</em>, which are requests that the system do something. We will use <em>program</em>
as a synonym for command.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
</div>
<div id="subsection-2-6" class="section level3">
<h3><span class="header-section-number">3.9.2</span> Subsection 2</h3>
</div>
<div id="applied-exercise-3" class="section level3">
<h3><span class="header-section-number">3.9.3</span> Applied exercise</h3>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="experimental-data-recording.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="experimental-data-preprocessing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-structured_data.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["improve_repro.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
