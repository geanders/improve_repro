<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="2.6 Power of using a single structured ‘Project’ directory for storing and tracking research project files | Improving the Reproducibility of Experimental Data Recording and Pre-Processing" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing." />
<meta name="github-repo" content="rstudio/bookdown-demo" />

<meta name="author" content="Brooke Anderson, Michael Lyons, Mercedes Gonzalez-Juarrero, Marcela Henao-Tamayo, and Gregory Robertson" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing.">

<title>2.6 Power of using a single structured ‘Project’ directory for storing and tracking research project files | Improving the Reproducibility of Experimental Data Recording and Pre-Processing</title>

<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#overview"><span class="toc-section-number">1</span> Overview</a>
<ul>
<li><a href="1-1-license.html#license"><span class="toc-section-number">1.1</span> License</a></li>
</ul></li>
<li><a href="2-experimental-data-recording.html#experimental-data-recording"><span class="toc-section-number">2</span> Experimental Data Recording</a>
<ul>
<li><a href="2-1-separating-data-recording-and-analysis.html#separating-data-recording-and-analysis"><span class="toc-section-number">2.1</span> Separating data recording and analysis</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#principles-and-power-of-structured-data-formats"><span class="toc-section-number">2.2</span> Principles and power of structured data formats</a></li>
<li><a href="2-3-the-tidy-data-format.html#the-tidy-data-format"><span class="toc-section-number">2.3</span> The ‘tidy’ data format</a></li>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#designing-templates-for-tidy-data-collection"><span class="toc-section-number">2.4</span> Designing templates for “tidy” data collection</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#example-creating-a-template-for-tidy-data-collection"><span class="toc-section-number">2.5</span> Example: Creating a template for “tidy” data collection</a></li>
<li><a href="2-6-power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files.html#power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files"><span class="toc-section-number">2.6</span> Power of using a single structured ‘Project’ directory for storing and tracking research project files</a></li>
<li><a href="2-7-creating-project-templates.html#creating-project-templates"><span class="toc-section-number">2.7</span> Creating ‘Project’ templates</a></li>
<li><a href="2-8-example-creating-a-project-template.html#example-creating-a-project-template"><span class="toc-section-number">2.8</span> Example: Creating a ‘Project’ template</a></li>
<li><a href="2-9-harnessing-version-control-for-transparent-data-recording.html#harnessing-version-control-for-transparent-data-recording"><span class="toc-section-number">2.9</span> Harnessing version control for transparent data recording</a></li>
<li><a href="2-10-enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms.html#enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms"><span class="toc-section-number">2.10</span> Enhance the reproducibility of collaborative research with version control platforms</a></li>
<li><a href="2-11-using-git-and-gitlab-to-implement-version-control.html#using-git-and-gitlab-to-implement-version-control"><span class="toc-section-number">2.11</span> Using git and GitLab to implement version control</a></li>
</ul></li>
<li><a href="3-experimental-data-preprocessing.html#experimental-data-preprocessing"><span class="toc-section-number">3</span> Experimental Data Preprocessing</a>
<ul>
<li><a href="3-1-principles-and-benefits-of-scripted-pre-processing-of-experimental-data.html#principles-and-benefits-of-scripted-pre-processing-of-experimental-data"><span class="toc-section-number">3.1</span> Principles and benefits of scripted pre-processing of experimental data</a></li>
<li><a href="3-2-introduction-to-scripted-data-pre-processing-in-r.html#introduction-to-scripted-data-pre-processing-in-r"><span class="toc-section-number">3.2</span> Introduction to scripted data pre-processing in R</a></li>
<li><a href="3-3-simplify-scripted-pre-processing-through-rs-tidyverse-tools.html#simplify-scripted-pre-processing-through-rs-tidyverse-tools"><span class="toc-section-number">3.3</span> Simplify scripted pre-processing through R’s ‘tidyverse’ tools</a></li>
<li><a href="3-4-complex-data-types-in-experimental-data-pre-processing.html#complex-data-types-in-experimental-data-pre-processing"><span class="toc-section-number">3.4</span> Complex data types in experimental data pre-processing</a></li>
<li><a href="3-5-complex-data-types-in-r-and-bioconductor.html#complex-data-types-in-r-and-bioconductor"><span class="toc-section-number">3.5</span> Complex data types in R and Bioconductor</a></li>
<li><a href="3-6-example-converting-from-complex-to-tidy-data-formats.html#example-converting-from-complex-to-tidy-data-formats"><span class="toc-section-number">3.6</span> Example: Converting from complex to ‘tidy’ data formats</a></li>
<li><a href="3-7-introduction-to-reproducible-data-pre-processing-protocols.html#introduction-to-reproducible-data-pre-processing-protocols"><span class="toc-section-number">3.7</span> Introduction to reproducible data pre-processing protocols</a></li>
<li><a href="3-8-from-pre-processing-scripts-to-pre-processing-protocols.html#from-pre-processing-scripts-to-pre-processing-protocols"><span class="toc-section-number">3.8</span> From pre-processing scripts to pre-processing protocols</a></li>
<li><a href="3-9-rmarkdown-for-creating-reproducible-data-pre-processing-protocols.html#rmarkdown-for-creating-reproducible-data-pre-processing-protocols"><span class="toc-section-number">3.9</span> RMarkdown for creating reproducible data pre-processing protocols</a></li>
<li><a href="3-10-example-creating-a-reproducible-data-pre-processing-protocol.html#example-creating-a-reproducible-data-pre-processing-protocol"><span class="toc-section-number">3.10</span> Example: Creating a reproducible data pre-processing protocol</a></li>
</ul></li>
<li><a href="4-references.html#references"><span class="toc-section-number">4</span> References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> Power of using a single structured ‘Project’ directory for storing and tracking research project files</h2>
<p>To improve the computational reproducibility of a research project, researchers
can use a single ‘Project’ directory to collectively store all research data,
meta-data, pre-processing code, and research products (e.g., paper drafts,
figures). We will explain how this practice improves the reproducibility and
list some of the common components and subdirectories to include in the
structure of a ‘Project’ directory, including subdirectories for raw and
pre-processed experimental data.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Describe a ‘Project’ directory, including common components and subdirectories</li>
<li>List how a single ‘Project’ directory improves reproducibility</li>
</ul>
<div id="organizing-project-files-through-the-file-system" class="section level3" number="2.6.1">
<h3><span class="header-section-number">2.6.1</span> Organizing project files through the file system</h3>
<p>One of the most amazing parts of how modern computers work is their file
directory systems. [More on these.]</p>
<p>It is useful to leverage this system to organize all the files related to a
project. These include data files (both “raw” data—directly output from
measurement equipment or directly recorded from observations, as well as any
“cleaned” version of this data, after steps have been taken to preprocess the
data to prepare it for visualization and analysis in papers and reports). These
files also include the files with writing and presentations (posters and slides)
associated with the project, as well as code scripts for preprocessing data,
for conducting data analysis, and for creating and sharing final figures and
tables.</p>
<p>There are a number of advantages to keeping all files related to a single project
inside a dedicated file directory on your computer. First, this provides a clear
and obvious place to search for all project files throughout your work on the
project, including after lulls in activity (for example, while waiting for
reviews from a paper submission). By keeping all project files within a single
directory, you also make it easier to share the collection of files for the
project. There are several reasons you might want to share these files. An
obvious one is that you likely will want to share the project files across members
in your research team, so they can collaborate together on the project. However,
there are also other reasons you’d need to share files, and one that is growing
in popularity is that you may be asked to share files (data, code scripts, etc.)
when you publish a paper describing your results.</p>
<p>When files are all stored in one directory, the directory can be compressed and
shared as an email attachment or through a file sharing platform like Google Drive.
As you learn more tools for reproducibility, you can also share the directory through
some more dynamic platforms, that let all those sharing access continue to change
and contribute to the files in the directory in a way that is tracked and
reversible. In later modules in this book, we will introduce <code>git</code> version control
software and the GitHub platform for sharing files under this type of version
control—this is one example of this more dynamic way of sharing files within
a directory.</p>
</div>
<div id="organizing-files-within-a-project-directory" class="section level3" number="2.6.2">
<h3><span class="header-section-number">2.6.2</span> Organizing files within a project directory</h3>
<p>To gain the advantages of directory-based project file organization, all the
files need to be within a single directory, but they don’t all have to be within
the same “level” in that directory. Instead, you can use subdirectories to
structure and organize these files, while still retaining all the advantages of
directory-based file organization. This will help limit the number of files in
each “level” of the directory, so none becomes an overwhelming slew of files of
different types. It can help you navigate the files in the directory, and also
help someone you share the directory with figure out what’s in it and where
everything is.</p>
<p>Subdirectory organizations can also, it turns out, be used in clever ways within
code scripts applied to files in the directory. For example, there are functions
in all scripting languages that will list all the files in a specified subdirectory.
If you keep all your raw data files of a certain type (for example, all output from
running flow cytometry for the project) within a single subdirectory, you can
use this type of function with code scripts to list all the files in that directory
and then apply code that you’ve developed to preprocess or visualize the data
across all those files. This code would continue to work as you added files to that
directory, since it starts by looking in that subdirectory each time it runs and
working with all files there as of that moment.</p>
<p>It is worthwhile to take some time to think about the types of files that are
often generated by your research projects, because there are also big advantages
to creating a standard structure of subdirectories that you can use consistently
across the directories for all the projects in your research program. Of course,
some projects may not include certain files, and some might have a new or unusual
type of file, so you can customize the directory structure to some degree for these
types of cases, but it is still a big advantage to include as many common elements
as possible across all your projects.</p>
<p>For example, you may want to always include a subdirectory called “raw_data,” and
consistently call it “raw_data,” to store data directly from observations or
directly output from laboratory equipment. You may want to include subdirectories
in that “raw_data” subdirectory for each type of data—maybe a “cfu” subdirectory,
for example, with results from plating data to count colony forming units, and
another called “flow” for output from a flow cytometer. By using the same structure
and the same subdirectory names, you will find that code scripts are easier to
reuse from one project to another. Again, most scripting languages allow you to
leverage order in how you’ve arranged your files in the file system, and so using
the same order across different projects lets you repeat and reuse code scripts
more easily from one project to another.</p>
<p>Finally, if you create a clear and clean organization structure for your project
directories, you will find it is much easier to navigate your files in all
directories, and also that new lab members and others you share the directories
with will be able to quickly learn to navigate them. In other areas of science
and engineering, this idea of standardized directory structures has allowed the
development of powerful techniques for open-source software developers to work
together. For example, anyone may create their own extensions to the R
programming language and share these with others through GitHub or several large
repositories. This is coordinated by enforcing a common directory structure on
these extension “packages”—to create a new package, you must put certain types
of files in certain subdirectories within a project directory. With these
standardized rules of directory structure and content, each of these packages
can interact with the base version of R, since there are functions that can tap
into any of these new packages by assuming where each type of file will be
within the package’s directory of files. In a similar way, if you impose a
common directory structure across all the project directories in your research
lab, your collaborators will quickly be able to learn where to find each
element, even in projects they are new to, and you will all be able to write
code that can be easily applied across all project directories, allowing you to
improve reproducibility and comparability across all projects by assuring that
you are conducting the same preprocessing and analysis across all projects (or,
if you are conducting things differently for different projects, that you are
deliberate and aware that you are doing so).</p>
<p>Figure [x] gives an example of a project directory organization that might make
sense for a immunology research laboratory.</p>
<p>Once you have decided on a structure for your directory, you can create a
template of it—a file directory with all the subdirectories included, but
without any files (or only template files you’d want to use as a starting
point in each project). When you start a new project, you can then just
copy this template and rename it. If you are using R and begin to use
R Project (described in the next section), you can also create an R Studio
Project template to serve as this kind of starting point each time you
start a new project.</p>
</div>
<div id="using-rstudio-projects-with-project-file-directories" class="section level3" number="2.6.3">
<h3><span class="header-section-number">2.6.3</span> Using RStudio Projects with project file directories</h3>
<p>If you are using the R programming language for data preprocessing, analysis,
and visualization—as well as RMarkdown for writing reports and
presentations—then you can use RStudio’s “Project” functionality to make it
even more convenient to work with files within a research project’s directory.
You can make any file directory a “Project” in RStudio by chosing “File” -&gt;
“New Project” in RStudio’s menu. This gives you the option to create a
project from scratch or to make an existing directory and RStudio Project.</p>
<p>When you make a file directory an RStudio Project, it doesn’t change much in
the directory itself except adding a “.RProj” file. This file keeps track of
some things about the file directory for RStudio, includuing … Also, when you
open one of these Projects in RStudio, it will move your working directory
into that projects top-level directory. This makes it very easy and practical
to write code using relative pathnames that start from this top-level of the
project directory. This is very good practice, because these relative pathnames
will work equally well on someone else’s computer, whereas if you use file
pathnames that are absolute (i.e., giving directions to the file from the root
directory on your computer), then when someone else tries on run the code on their
own computer, it won’t work and they’ll need to change the filepaths in the code,
since everyone’s computer has its files organized differently. For example, if you,
on your personal computer, have the project directory stored in your “Documents”
folder, while a colleague has stored the project directory in his or her “Desktop”
directory, then the absolute filepaths for each file in the directory will be
different for each of you. The relative pathnames, starting from the top level of
the project directory, will be the same for both of you, though, regardless of
where you each stored the project directory on your computer.</p>
<p>There are some other advantages, as well, to turning each of your research
project directories into RStudio Projects. One is that it is very easy to
connect each of these Projects with GitHub, which facilitates collaborative work
on the project across multiple team members while tracking all changes under
version control. This functionality is described in a later module in this book.</p>
<p>As you continue to use R and RStudio’s Project functionality, you may want to
take the template directory for your project and create an RStudio Project
template based on its structure. Once you do, when you start a new research
project, you can create the full directory for your project’s files from within
RStudio by going to “File” -&gt; “New Project” and then choosing to create a new
project based on that template. The new project will already be set up with the
“.RProj” file that allows you to easily navigate into and out of that project,
to connect it to GitHub, and all the other advantages of setting a file
directory as an RStudio Project. The next module gives step-by-step directions
for making a directory an RStudio Project, and also how to create you own
RStudio Project template to quickly create a new directory for project files
each time you start a new research project.</p>
<p>[Visual—project directory as a <em>mise en place</em> for cooking—everything you
need for the analysis, plus the recipe for someone to repeat later.]</p>
<p>[Reference: The Usual Suspects—you’ll typically have the same types of data files,
analysis, types of figures, etc., come up again and again for different research
projects. Leverage tools to improve efficiency when working with these “usual
suspects.” The first time you follow a protocol that is new to you, or the first
time you cook a recipe, it takes much longer and much more thought than it should
as you do it over and over—there are some recipes where I only use the cookbook
now to figure out the oven temperature or the exact measurement of an ingredient.
These tools will help you streamline your project file organization and move towards
reuse of modular tools and ideas (e.g., remembering how to make a vinaigrette and
applying that regardless of the type of salad) across projects.]</p>
<p>[Analogies for moving to do things more programatically—Tom Sawyer outsourcing the
fence painting, sorcerer’s apprentice (all the mops, plus some difficulties when you
first start, before you get the hang of it).]</p>
<p>[File extensions give an idea of the power of consistent file names. While some
operating systems don’t require these, by naming all the files that should be
opened with, for example, Word “.docx,” the operating system can easily do a
targeted search that looks for files with certain key words in the name while
limiting the search only to Word files. You can leverage this same power yourself,
and in a way that’s more customized to your project or typical research approach,
by using consistent conventions to name your files.]</p>
</div>
<div id="subsection-1-1" class="section level3" number="2.6.4">
<h3><span class="header-section-number">2.6.4</span> Subsection 1</h3>
<p>One study surveyed over 250 biomedical researchers at the University of Washington.
They noted that, “a common theme surrounding data management and analysis was that
may researchers preferred to utilize their own individual methods to organize data.
The varied ways of managing data were accepted as functional for most present needs.
Some researchers admitted to having no organizational methodology at all, while others
used whatever method best suited their individual needs.” <span class="citation">(Anderson et al. 2007)</span>
One respondent answered, “They’re not organized in any way—they’re just thrown into
files under different projects,” while another said “I grab them when I need them, they’re
not organized in any decent way,” and another, “It’s not even organized—a file on a central
computer of protocols that we use, common lab protocols but those are just individual
Word files within a folder so it’s not searchable per se.” <span class="citation">(Anderson et al. 2007)</span></p>
<blockquote>
<p>“In general, data reuse is most possible when: 1) data; 2) metadata (information
describing the data); and 3) information about the process of generating those data,
such as code, are all provided.” <span class="citation">(Goodman et al. 2014)</span></p>
</blockquote>
<blockquote>
<p>“So far we have used filenames without ever saying what a legal name is, so it’s time for a couple
of rules. First, filenames are limited to 14 characters. Second, although you can use almost any
character in a filename, common sense says you should stick to ones that are visible, and that you
should avoid characters that might be used with other meanings. … To avoid pitfalls, you would
do well to use only letters, numbers, the period and the underscore until you’re familiar with the
situation [i.e., characters with pitfalls]. (The period and the underscore are conventionally used
to divide filenames into chunks…) Finally, don’t forget that case distinctions matter—junk, Junk,
and JUNK are three different names.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“The [Unix] system distinguishes your file called ‘junk’ from anyone else’s of the same name. The
distinction is made by grouping files into <em>directories</em>, rather in the way that books are placed om
shelves in a library, so files in different directories can have the same name without any conflict.
Generally, each user haas a personal or <em>home directory</em>, sometimes called login directory, that
contains only the files that belong to him or her. When you log in, you are ‘in’ your home directory.
You may change the directory you are working in—often called your working or <em>current directory</em>—but
your home directory is always the same. Unless you take special action, when you create a new file it is
made in your current directory. Since this is initially your home directory, the file is unrelated
to a file of the same name that might exist in someone else’s directory. A directory can contain
other directories as well as ordinary files … The natural way to picture this organization is as a
tree of directories and files. It is possible to move around within this tree, and to find any file in the system
by starting at the root of the tree and moving along the proper branches. Conversely, you can start where
you are and move toward the root.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“The name ‘/usr/you/junk’ is called the <em>pathname</em> of the file. ‘Pathname’ has an intuitive meaning:
it represents the full name of the path from the root through the tree of directories to a particular
file. It is a universal rule in the Unix system that wherever you can use an ordinary filename, you can
use a pathname.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“If you work regularly with Mary on information in her directory, you can say ‘I want to work on Mary’s
files instead of my own.’ This is done by changing your current directory with the <code>cd</code> command…
Now when you use a filename (without the /’s) as an argument to <code>cat</code> or <code>pr</code>, it refers to the file
in Mary’s directory. Changing directories doesn’t affect any permissions associated with a file—if you
couldn’t access a file from your own directory, changing to another directory won’t alter that fact.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“It is usually convenient to arrange your own files so that all the files related to one thing are in a
directory separate from other projects. For example, if you want to write a book, you might want to
keep all the text in a directory called ‘book.’” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“Suppose you’re typing a large document like a book. Logically this divides into many small pieces,
like chapters and perhaps sections. Physically it should be divided too, because it is cumbersome
to edit large files. Thus you should type the document as a number of files. You might have separate
files for each chapter, called ‘ch1,’ ‘ch2,’ etc. … With a systematic naming convention, you can tell at
a glance where a particular file fits into the whole. What if you want to print the whole book? You could
say <code>$ pr ch1.1 ch1.2 ch 1.3 ...</code>, but you would soon get bored typing filenames and start to make mistakes.
This is where filename shorthand comes in. If you say <code>$ pr ch*</code> the shell takes the <code>*</code> to mean ‘any
string of characters,’ so ch* is a pattern that matches all filenames in the current directory that
begin with ch. The shell creates the list, in alphabetical order, and passes the list to <code>pr</code>. The
<code>pr</code> command never sees the <code>*</code>; the pattern match that the shell does in the current directory
generates aa list of strings that are passed to <code>pr</code>.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“The current directory is an attribute of a process, not a person or a program. … The notion of a
current directory is certainly a notational convenience, because it can save a lot of typing, but
its real purpose is organizational. Related files belong together in the same directory. ‘/usr’ is
often the top directory of a user file system… ‘/usr/you’ is your login directory, your current
directory when you first log in. … Whenever you embark on a new project, or whenever you have
a set of related files … you could create a new directory with <code>mkdir</code> and put the files there.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“Despite their fundamental properties inside the kernel, directories sit in the file system as
ordinary files. They can be read as ordinary files. But they can’t be created or written as
ordinary files—to preserve its sanity and the users’ files, the kernel reserves to itself all
control over the contents of directories.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
<blockquote>
<p>“A file has several components: a name, contents, and administrative information such as
permissions and modifications times. The administrative information is stored in the inode
(over the years, the hyphen fell out of ‘i-node’), along with essential system data such as
how long it is, where on the disc the contents of the file are stored, and so on. …
It is important to understand inodes, not only to appreciate the options on <code>ls</code>, but because
in a strong sense the inodes <em>are</em> the files. All the directory hierarchy does is provide
convenient names for files. The system’s name for a file is its <em>i-number</em>: the number of the
inode holding the file’s information. … It is the i-number that is stored in the first two bytes
of a directory, before the name. …
The first two bytes in each directory entry are the only connection between the name of a file and its
contents. A filename in a directory is therefore called a <em>link</em>, because it links a name in the
directory hierarchy to the inode, and hence to the data. The same i-number can appear in more than
one directory. The <code>rm</code> command does not actually remove the inodes; it removes directory entries
or links. Only when the last link to a file disappears does the system remove the inode, and hence
the file itself. If the i-number in a directory entry is zero, it means that the link has been
removed, but not necessarily the contents of the file—there may still be a link somewhere else.” <span class="citation">(Kernighan and Pike 1984)</span></p>
</blockquote>
</div>
<div id="subsection-2" class="section level3" number="2.6.5">
<h3><span class="header-section-number">2.6.5</span> Subsection 2</h3>
<blockquote>
<p>“The file system is the part of the operating system that makes physical storage media
like disks, CDs and DVDs, removable memory devices, and other gadgets look like hierarchies
of files and folders. The file system is a great example of the distinction between
logical organization and physical implementation; file systems organize and store
information on many differet kinds of devices, but the operating system presents the
same interface for all of them.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>" A <em>folder</em> contains the names of other folders and files; examining a folder will
reveal more folders and files. (Unix systems traditionally use the word <em>directory</em>
instead of folder.) The folders provide the organizational structure, while the files
hold the actual contents of documents, pictures, music, spreadsheets, web pages, and
so on. All the information that you computer holds is stored in the file system and
is accessible through it if you poke around. This includes not only your data, but the
executable forms of programs (a browser, for example), libraries, device drivers, and the
files that make up the operating system itself. … The file system manages all this
information, making it accessible for reading and writing by applications and the rest of
the operating system. It coordinates accesses so they are performed efficiently and
don’t interfere with each other, it keeps track of where data is physically located,
and it ensures that the pieces are kept separate so that parts of your email don’t
mysteriously wind up in your spreadsheets or tax returns." <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“File system services are available through system calls at the lowest level,
usually supplemented by libraries to make common operations easy to program.”
<span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“The file system is a wonderful example of how a wide variety of physical
systems can be made to present a uniform logical appearance, a hierarchy of folders
and files.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“A folder is a file that contains information about where folders and files are
located. Because information about file contents and organization must be perfectly
accurate and consistent, the file system reserves to itself the right to manage and
maintain the contents of folders. Users and application programs can only change the
folder contents implicitly, by making requests of the file system.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“In fact, folders <em>are</em> files; there’s no difference in how they are stored except
that the file system is totally responsible for folder contents, and application
programs have no direct way to change them. But otherwise, it’s just blocks on the disk,
all managed by the same mechanisms.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“A folder entry for this [example] file would contain its name, its size of 2,500 bytes,
the date and time it was created or changed, and other miscellaneous facts about it
(permissions, type, etc., depending on the operating system). All of that information
is visible through a program like Explorer or Finder. The folder entry also contains
information about where the file is stored on disk—which of the 100 million blocks
[on the example computer’s hard disk] contain its bytes. There are different ways to
manage that location information. The folder entry could contain a list of block numbers;
it could refer to a block that itself contains a list of block numbers; or it could
contain the number of the first block, which in turn gives the second block, and so
on. … Blocks need not be physically adjacent on disk, and in fact they typically
won’t be, at least for large files. A megabyte file will occupy a thousand blocks, and
those are likely to be scattered to some degree. The folders and the block lists are
themselves stored in blocks…” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“When a program wants to access an existing file, the file system has to search for
the file starting at the root of the file system hierarchy, looking for each component
of the file path name in the corresponding folder. That is, if the file is
<code>/Users/bwk/book/book.txt</code> on a Mac, the file system will search the root of the file
system for <code>Users</code>, then search within that folder for <code>bwk</code>, then within that folder
for <code>book</code>, then within that for <code>book.txt</code>. … This is a divide-and-conquer strategy,
since each component of the path narrows the search to files and folders that lie within
that folder; all others are eliminated. Thus multiple files can have the same name for
some component; the only requirement is that the full path name be unique. In practice,
programs and the operating system keep track of the folder that is currenlty in use
so searches need not start from the root each time, and the system is likely to
cache frequently-used folders to speed up operations.” <span class="citation">(Kernighan 2011)</span></p>
</blockquote>
<blockquote>
<p>“When quitting R, the option is given to save the ‘workspace image.’ The workspace
consists of all values that have been created during a session—all of the data values
that have been stored in RAM. The workspace is saved as a file called <code>.Rdata</code> and then
R starts up, it checks for such a file in the current working directory and loads it
automatically. This provides a simple way of retaining the results of calculations from
one R session to the next. However, saving the entire R workspace is not the recommended
approach. It is better to save the original data set and R code and re-create results by
running the code again.” <span class="citation">(Murrell 2009)</span></p>
</blockquote>
<blockquote>
<p>“Just as a well-organized laboratory makes a scientist’s life easier, a well-organized
and well-documented project makes a bioinformatician’s life easier. Regardless of the
particular project you’re working on, your project directory should be laid out in a
consistent and understandable fashion. Clear project organization makes it easier
for both you and collaborators to figure out exactly where and what everything is.
Additionally, it’s much easier to automate tasks when files are organized and
clearly named. For example, processing 300 gene sequences stored in separate FASTA
files with a script is trivial if these files are organized in a single directory and
are consistently named.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Project directory organization isn’t just about being tidy, but is essential to the
way by which tasks are automated across large numbers of files” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“All files and directories used in your project should live in a single project directory
with a clear name. During the course of a project, you’ll have amassed data files, notes,
scripts, and so on—if these were scattered all over your hard drive (or worse, across
many computers’ hard drives), it would be a nightmare to keep track of everything. Even
worse, such a disordered project would later make your research nearly impossible to
reproduce.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Naming files and directories on a computer matters more than you may think. In
transitioning from a graphical user interface (GUI) based operating system to
the Unix command line, many folks bring the bad habit of using spaces in
file and directory names. This isn’t appropriate in a Unix-based environment, because
spaces are used to separate arguments in commands. … Although Unix doesn’t require
file extensions, including extensions in file names helps indicate the type of each
file. For example, a file named <em>osativa-genes.fasta</em> makes it clear that this is
a file of sequences in FASTA format. In contrast, a file named <em>osativa-genes</em> could
be a file of gene models, notes on where these <em>Oryza sativa</em> genes came from, or
sequence data. When in doubt, explicit is always better than implicit when it comes to
filenames, documentation, and writing code.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Scripts and analyses often need to refer to other files (such as data) in your
project hierarchy. This may require referring to parent directories in you directory’s
hierarcy … In these cases, it’s important to always use <em>relative paths</em> … rather
than <em>absolute paths</em> … As long as your internal project directory structure remains the
same, these relative paths will always work. In contrast, absolute paths rely on you particular
user account and directory structures details <em>above</em> the project directory level
(not good). Using absolute paths leaves your work less portable between collaborators and
decreases reproducibility.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“<em>Document the origin of all data in your project directory.</em> You need to keep track of
where data was downloaded from, who gave it to you, and any other relevant information.
‘Data’ doesn’t just refer to your project’s experimental data—it’s any data that
programs use to create output. This includes files your collaborators send you from their
separate analyses, gene annotation tracks, reference genomes, and so on. It’s critical
to record this important data about you’re data, or <em>metadata</em>. For example, if you downloaded
a set of genic regions, record the website’s URL. This seems like an obvious recommendation,
but ocuntless times I’ve encountered an analysis step that couldn’t be easily reproduced
because someone forgot to record the data’s source.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“<em>Record data version information.</em> Many databases have explicit release numbers,
version numbers, or names (e.g., TAIR10 version of genome annotation for <em>Arabidopsis
thaliana</em>, or Wormbase release WS231 for <em>Caenorhabditis elegans</em>). It’s important to
record all version information in your documentation, including minor version numbers.”
<span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“<em>Describe how you downloaded the data.</em> For example, did you use MySQL to download a
set of genes? Or the USCS Genome Browser? THese details can be useful in tracking down
issues like when data is different between collaborators.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Bioinformatics projects involve many subprojects and subanalyses. For example, the
quality of raw experimental data should be assessed and poor quality regions removed
before running it through bioinformatics tools like aligners or assemblers. … Even
before you get to actually analyzing the sequences, your project directory can get
cluttered with intermediate files. Creating directories to logically separate subprojects
(e.g., sequencing data quality improvement, aligning, analyzing alignment results, etc.)
can simplify complex projects and help keep files organized. It also helps reduce the
risk of accidentally clobbering a file with a buggy script, as subdirectories help
isolate mishaps. Breaking a project down into subprojects and keeping these in separate
subdirectories also makes documenting your work easier; each README pertains to the
directory it resides in. Ultimately, you’ll arrive at your own project organization
system that works for you; the take-home point is: leverage directories to help stay
organized.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Because automating file processing tasks is an integral part of bioinformatics,
organizing our projects to facilitate this is essential. Organizing data into subdirectories
and using clear and consistent file naming schemes is imperative—both of these practices
allow us to <em>programmatically</em> refer to files, the first step to automating a task.
Doing something programatically means doing it through code rather than manually, using
a method that can effortlessly scale to multiple objects (e.g., files). Programatically
referring to multiple files is easier and safer than typing them all out (because it’s
less error prone.)” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Organizing data files into a single directory with consistent filenames prepares us to
iterate over <em>all</em> of our data, whether it’s the four example files used in this example,
or 40,000 files in a real project. Think of it this way: remember when you discovered you
could select many files with your mouse cursor? With this trick, you could move 60 files
as easily as six files. You could also select certain file types (e.g., photos) and attach
them all to an email with one movement. By using consistent file naming and directory
organization, you can do the same programatically using the Unix shell and other
programming languages.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Because lots of daily bioinformatics work involves file processing, programmatically
accessing files makes our job easier and eliminates mistakes from mistyping a filename
or forgetting a sample. However, our ability to programmatically access files with
wildcards (or other methods in R or Python) is only possible when our filenames are
consistent. While wildcards are powerful, they’re useless if files are inconsistently
named. … Unfortunately, inconsistent naming is widespread across biology, and is
the source of bioinformaticians everywhere. Collectively, bioinformaticians have
probably wasted thousands of hours fighting others’ poor naming schemes of files,
genes, and in code.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Another useful trick is to use leading zeros … when naming files. This is useful
because lexicographically sorting files (as <code>ls</code> does) leads to correct ordering. …
Using leading zeros isn’t just useful when naming filenames; this is also the best
way to name genes, transcripts, and so on. Projects like Ensembl use this naming
scheme in naming their genes (e.g., ENSG00000164256).” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“In addition to simplifying working with files, consistent naming is an often overlooked
component of robust bioinformatics. Bad naming schemes can easily lead to switched samples.
Poorly chosen filenames can also cause serious errors when you or collaborators think you’re
working with the correct data, but it’s actually outdate or the wrong file. I guarantee
that out of all the papers published in the past decade, at least a few and likely many
more contain erroneous results because of a file naming issue.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“In order to read or write a file, the first thing we need to be able to do is specify
<em>which</em> file we want to work with. Any function that works with a file requires a
precise description of the name of the file and the location of the file. A filename
is just a character value…, but identifying the location of a file can involve a
<strong>path</strong>, which describes a location on a persistent storage medium, such as a hard drive.”
<span class="citation">(Murrell 2009)</span></p>
</blockquote>
<blockquote>
<p>“A regular expression consists of a mixture of <strong>literal</strong> characters, which have their
normal meaning, and <strong>metacharacters</strong>, which have a special meaning. The combination
describes a <strong>pattern</strong> that can be used to find matches amongst text values.” <span class="citation">(Murrell 2009)</span></p>
</blockquote>
<blockquote>
<p>“A regular expression may be as simple as a literal word, such as <code>cat</code>, but regular
expressions can also be quite complex and express sophisticated ideas, such as
<code>[a-z]{3,4}[0-9]{3}</code>, which describes a pattern consisting of either three or four
lowercase letters followed by any three digits.” <span class="citation">(Murrell 2009)</span></p>
</blockquote>
<blockquote>
<p>“… it’s important to mind R’s working directory. Scripts should <em>not</em> use
<code>setwd()</code> to set their working directory, as this is not portable to other
systems (which won’t have the same directory structure). For the same reason,
use <em>relative</em> paths … when loading in data, and <em>not</em> absolute pathers…
Also, it’s a good idea to indicate (either in comments or a README file)
which directory the user should set as their working directory.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“<strong>Centralize the location of the raw data files and automate the derivation of
intermediate data.</strong> Store the input data on a centralized file server that is
profesionally backed up. Mark the files as read-only. Have a clear and linear
workflow for computing the derived data (e.g., normalized, summarized, transformed,
etc.) from the raw files, and store these in a separate directory. Anticipate that
this workflow will need to be run several times, and version it. Use the
<code>BiocFileCache</code> package to mirror these files on your personal computer.
[footnote: A more basic alternative is the rsync utility. A popular solution offered
by some organizations is based on ownCloud. Commercial options are Dropbox,
Google Drive and the like].” <span class="citation">(Holmes and Huber 2018)</span></p>
</blockquote>
</div>
<div id="practice-quiz-1" class="section level3" number="2.6.6">
<h3><span class="header-section-number">2.6.6</span> Practice quiz</h3>

</div>
</div>
<p style="text-align: center;">
<a href="2-5-example-creating-a-template-for-tidy-data-collection.html"><button class="btn btn-default">Previous</button></a>
<a href="2-7-creating-project-templates.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
