<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 2 Experimental Data Recording | Improving the Reproducibility of Experimental Data Recording and Pre-Processing</title>
  <meta name="description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 2 Experimental Data Recording | Improving the Reproducibility of Experimental Data Recording and Pre-Processing" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Experimental Data Recording | Improving the Reproducibility of Experimental Data Recording and Pre-Processing" />
  
  <meta name="twitter:description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing." />
  

<meta name="author" content="Brooke Anderson, Michael Lyons, Mercedes Gonzalez-Juarrero, Marcela Henao-Tamayo, and Gregory Robertson">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="experimental-data-preprocessing.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Visualization in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Overview</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>1.1</b> License</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html"><i class="fa fa-check"></i><b>2</b> Experimental Data Recording</a><ul>
<li class="chapter" data-level="2.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#separating-data-recording-and-analysis"><i class="fa fa-check"></i><b>2.1</b> Separating data recording and analysis</a><ul>
<li class="chapter" data-level="2.1.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#data-recording-versus-data-analysis"><i class="fa fa-check"></i><b>2.1.1</b> Data recording versus data analysis</a></li>
<li class="chapter" data-level="2.1.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#hazards-of-combining-recording-and-analysis"><i class="fa fa-check"></i><b>2.1.2</b> Hazards of combining recording and analysis</a></li>
<li class="chapter" data-level="2.1.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#approaches-to-separate-recording-and-analysis"><i class="fa fa-check"></i><b>2.1.3</b> Approaches to separate recording and analysis</a></li>
<li class="chapter" data-level="2.1.4" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#discussion-questions"><i class="fa fa-check"></i><b>2.1.4</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#principles-and-power-of-structured-data-formats"><i class="fa fa-check"></i><b>2.2</b> Principles and power of structured data formats</a><ul>
<li class="chapter" data-level="2.2.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#characteristics-of-a-structured-data-format"><i class="fa fa-check"></i><b>2.2.1</b> Characteristics of a structured data format</a></li>
<li class="chapter" data-level="2.2.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#benefits-of-a-structured-data-format"><i class="fa fa-check"></i><b>2.2.2</b> Benefits of a structured data format</a></li>
<li class="chapter" data-level="2.2.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#applied-exercise"><i class="fa fa-check"></i><b>2.2.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#the-tidy-data-format"><i class="fa fa-check"></i><b>2.3</b> The ‘tidy’ data format</a><ul>
<li class="chapter" data-level="2.3.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#the-tidy-data-format-1"><i class="fa fa-check"></i><b>2.3.1</b> The “tidy” data format</a></li>
<li class="chapter" data-level="2.3.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#the-tidy-data-format-as-a-structured-data-format"><i class="fa fa-check"></i><b>2.3.2</b> The “tidy” data format as a structured data format</a></li>
<li class="chapter" data-level="2.3.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#practice-quiz"><i class="fa fa-check"></i><b>2.3.3</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#designing-templates-for-tidy-data-collection"><i class="fa fa-check"></i><b>2.4</b> Designing templates for “tidy” data collection</a><ul>
<li class="chapter" data-level="2.4.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1"><i class="fa fa-check"></i><b>2.4.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.4.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#applied-exercise-1"><i class="fa fa-check"></i><b>2.4.2</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#example-creating-a-template-for-tidy-data-collection"><i class="fa fa-check"></i><b>2.5</b> Example: Creating a template for “tidy” data collection</a><ul>
<li class="chapter" data-level="2.5.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-1"><i class="fa fa-check"></i><b>2.5.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.5.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2"><i class="fa fa-check"></i><b>2.5.2</b> Subsection 2</a></li>
<li class="chapter" data-level="2.5.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#discussion-questions-1"><i class="fa fa-check"></i><b>2.5.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files"><i class="fa fa-check"></i><b>2.6</b> Power of using a single structured ‘Project’ directory for storing and tracking research project files</a><ul>
<li class="chapter" data-level="2.6.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-2"><i class="fa fa-check"></i><b>2.6.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.6.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2-1"><i class="fa fa-check"></i><b>2.6.2</b> Subsection 2</a></li>
<li class="chapter" data-level="2.6.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#practice-quiz-1"><i class="fa fa-check"></i><b>2.6.3</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#creating-project-templates"><i class="fa fa-check"></i><b>2.7</b> Creating ‘Project’ templates</a><ul>
<li class="chapter" data-level="2.7.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-3"><i class="fa fa-check"></i><b>2.7.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.7.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2-2"><i class="fa fa-check"></i><b>2.7.2</b> Subsection 2</a></li>
<li class="chapter" data-level="2.7.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#discussion-questions-2"><i class="fa fa-check"></i><b>2.7.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#example-creating-a-project-template"><i class="fa fa-check"></i><b>2.8</b> Example: Creating a ‘Project’ template</a><ul>
<li class="chapter" data-level="2.8.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-4"><i class="fa fa-check"></i><b>2.8.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.8.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2-3"><i class="fa fa-check"></i><b>2.8.2</b> Subsection 2</a></li>
<li class="chapter" data-level="2.8.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#applied-exercise-2"><i class="fa fa-check"></i><b>2.8.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#harnessing-version-control-for-transparent-data-recording"><i class="fa fa-check"></i><b>2.9</b> Harnessing version control for transparent data recording</a><ul>
<li class="chapter" data-level="2.9.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-5"><i class="fa fa-check"></i><b>2.9.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.9.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2-4"><i class="fa fa-check"></i><b>2.9.2</b> Subsection 2</a></li>
<li class="chapter" data-level="2.9.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#discussion-questions-3"><i class="fa fa-check"></i><b>2.9.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms"><i class="fa fa-check"></i><b>2.10</b> Enhance the reproducibility of collaborative research with version control platforms</a><ul>
<li class="chapter" data-level="2.10.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-6"><i class="fa fa-check"></i><b>2.10.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.10.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2-5"><i class="fa fa-check"></i><b>2.10.2</b> Subsection 2</a></li>
<li class="chapter" data-level="2.10.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#discussion-questions-4"><i class="fa fa-check"></i><b>2.10.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#using-git-and-gitlab-to-implement-version-control"><i class="fa fa-check"></i><b>2.11</b> Using git and GitLab to implement version control</a><ul>
<li class="chapter" data-level="2.11.1" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-1-7"><i class="fa fa-check"></i><b>2.11.1</b> Subsection 1</a></li>
<li class="chapter" data-level="2.11.2" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#subsection-2-6"><i class="fa fa-check"></i><b>2.11.2</b> Subsection 2</a></li>
<li class="chapter" data-level="2.11.3" data-path="experimental-data-recording.html"><a href="experimental-data-recording.html#applied-exercise-3"><i class="fa fa-check"></i><b>2.11.3</b> Applied exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html"><i class="fa fa-check"></i><b>3</b> Experimental Data Preprocessing</a><ul>
<li class="chapter" data-level="3.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#principles-and-benefits-of-scripted-pre-processing-of-experimental-data"><i class="fa fa-check"></i><b>3.1</b> Principles and benefits of scripted pre-processing of experimental data</a><ul>
<li class="chapter" data-level="3.1.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-8"><i class="fa fa-check"></i><b>3.1.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.1.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-7"><i class="fa fa-check"></i><b>3.1.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.1.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#discussion-questions-5"><i class="fa fa-check"></i><b>3.1.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#introduction-to-scripted-data-pre-processing-in-r"><i class="fa fa-check"></i><b>3.2</b> Introduction to scripted data pre-processing in R</a><ul>
<li class="chapter" data-level="3.2.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-9"><i class="fa fa-check"></i><b>3.2.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.2.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-8"><i class="fa fa-check"></i><b>3.2.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.2.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-4"><i class="fa fa-check"></i><b>3.2.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#simplify-scripted-pre-processing-through-rs-tidyverse-tools"><i class="fa fa-check"></i><b>3.3</b> Simplify scripted pre-processing through R’s ‘tidyverse’ tools</a><ul>
<li class="chapter" data-level="3.3.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-10"><i class="fa fa-check"></i><b>3.3.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.3.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-9"><i class="fa fa-check"></i><b>3.3.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.3.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#practice-quiz-2"><i class="fa fa-check"></i><b>3.3.3</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#complex-data-types-in-experimental-data-pre-processing"><i class="fa fa-check"></i><b>3.4</b> Complex data types in experimental data pre-processing</a><ul>
<li class="chapter" data-level="3.4.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-11"><i class="fa fa-check"></i><b>3.4.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.4.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-10"><i class="fa fa-check"></i><b>3.4.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.4.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#practice-quiz-3"><i class="fa fa-check"></i><b>3.4.3</b> Practice quiz</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#complex-data-types-in-r-and-bioconductor"><i class="fa fa-check"></i><b>3.5</b> Complex data types in R and Bioconductor</a><ul>
<li class="chapter" data-level="3.5.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-12"><i class="fa fa-check"></i><b>3.5.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.5.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-11"><i class="fa fa-check"></i><b>3.5.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.5.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-5"><i class="fa fa-check"></i><b>3.5.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#example-converting-from-complex-to-tidy-data-formats"><i class="fa fa-check"></i><b>3.6</b> Example: Converting from complex to ‘tidy’ data formats</a><ul>
<li class="chapter" data-level="3.6.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-13"><i class="fa fa-check"></i><b>3.6.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.6.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-12"><i class="fa fa-check"></i><b>3.6.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.6.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-6"><i class="fa fa-check"></i><b>3.6.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#introduction-to-reproducible-data-pre-processing-protocols"><i class="fa fa-check"></i><b>3.7</b> Introduction to reproducible data pre-processing protocols</a><ul>
<li class="chapter" data-level="3.7.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-14"><i class="fa fa-check"></i><b>3.7.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.7.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-13"><i class="fa fa-check"></i><b>3.7.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.7.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#discussion-questions-6"><i class="fa fa-check"></i><b>3.7.3</b> Discussion questions</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#rmarkdown-for-creating-reproducible-data-pre-processing-protocols"><i class="fa fa-check"></i><b>3.8</b> RMarkdown for creating reproducible data pre-processing protocols</a><ul>
<li class="chapter" data-level="3.8.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-15"><i class="fa fa-check"></i><b>3.8.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.8.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-14"><i class="fa fa-check"></i><b>3.8.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.8.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#applied-exercise-7"><i class="fa fa-check"></i><b>3.8.3</b> Applied exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#example-creating-a-reproducible-data-pre-processing-protocol"><i class="fa fa-check"></i><b>3.9</b> Example: Creating a reproducible data pre-processing protocol</a><ul>
<li class="chapter" data-level="3.9.1" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-1-16"><i class="fa fa-check"></i><b>3.9.1</b> Subsection 1</a></li>
<li class="chapter" data-level="3.9.2" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#subsection-2-15"><i class="fa fa-check"></i><b>3.9.2</b> Subsection 2</a></li>
<li class="chapter" data-level="3.9.3" data-path="experimental-data-preprocessing.html"><a href="experimental-data-preprocessing.html#practice-quiz-4"><i class="fa fa-check"></i><b>3.9.3</b> Practice quiz</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>4</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Improving the Reproducibility of Experimental Data Recording and Pre-Processing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="experimental-data-recording" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Experimental Data Recording</h1>
<div id="separating-data-recording-and-analysis" class="section level2">
<h2><span class="header-section-number">2.1</span> Separating data recording and analysis</h2>
<p>Many biomedical laboratories currently use spreadsheets—with formulas creating
underlying connections between spreadsheet cells—to jointly record, visualize,
and analyze experimental data <span class="citation">(Broman and Woo 2018)</span>. This practice impedes the
transparency and reproducibility of both data recording and data analysis. When
a research group develops and uses an evolving spreadsheet template with
embedded formulas, it leads to a data recording / analysis process that can
become extraordinarily opaque and complex. To improve the computational
reproducibility of a research project, it is critical for biomedical researchers
to learn the importance of maintaining recorded experimental data as “read-only”
files, separating data recording from any data pre-processing or data analysis
steps <span class="citation">(Broman and Woo 2018; Marwick, Boettiger, and Mullen 2018)</span>. Statisticians have outlined
specific methods that a laboratory-based scientist can take to ensure that data
shared in an Excel spreadsheet are shared in a reliable and reproducible way,
including avoiding macros or embedded formulas, using a separate Excel file for
each dataset, recording descriptions of variables in a separate code book rather
than in the Excel file, avoiding the use of color of the cells to encode
information, using “NA” to code missing values, avoiding spaces in column
headers, and avoiding splitting or merging cells <span class="citation">(Ellis and Leek 2018; Broman and Woo 2018)</span>. In this module, we will describe this common practice and will
outline alternative approaches that separate the steps of data recording and
data analysis.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Explain the difference between data recording and data analysis</li>
<li>Understand why collecting data on spreadsheets with embedded formulas impedes
reproducibility</li>
<li>List alternative approaches to improve reproducibility</li>
</ul>
<div id="data-recording-versus-data-analysis" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Data recording versus data analysis</h3>
<p>Many scientific laboratories use spreadsheets within their data collection
process, both to record data and to clean and analyze the data. One survey of
over 250 biomedical researchers at the University of Washington found that most
respondants used general-purpose applications like spreadsheets
<span class="citation">(Anderson et al. 2007)</span>, while a survey of neuroscience researchers at the
University of Newcastle similarly found that most respondents used spreadsheets
and other general-purpose software in their research <span class="citation">(AlTarawneh and Thorne 2017)</span>. A
working group on bioinformatics and data-intensive science similarly found
spreadsheets were the most common tool used across attendees
<span class="citation">(Barga et al. 2011)</span>.</p>
<p>Spreadsheets have long been an extremely popular tool, in part because they
allow people without programming experience to conduct a range of standard
computations and statistical analyses through a visual interface that is more
immediately user-friendly to non-programmers than programs with command line
interfaces. An early target for spreadsheet programs in terms of early users was
business executives, and so the programs were designed to be very simple and
easy to use—just one step up in complexity from crunching numbers on the back
of an envelope <span class="citation">(Campbell-Kelly 2007)</span>. Spreadsheet programs in fact became so
popular within businesses that many attribute these programs with driving the
uptake of personal computers <span class="citation">(Campbell-Kelly 2007)</span>.</p>
<p>Spreadsheets were innovative and rapidly adapted in part because they allowed
users to combine data recording and analysis—while previously, in business
settings, any complicated data analysis tasked needed to be outsourced to
mainframe computers and data processing teams, the initial spreadsheet program
(VisiCalc) allowed one person to quickly apply and test different models or
calculations to recorded data <span class="citation">(Levy 1984)</span>. These spreadsheet programs
allowed non-programmers to engage with data, including data processing and
analysis tasks, that previously required programming expertise
<span class="citation">(Levy 1984)</span>.</p>
<p>In some cases, a spreadsheet is used solely to record data, as a simple type of
database <span class="citation">(Birch, Lyford-Smith, and Guo 2018)</span>. However, biomedical researchers often use
spreadsheets to both record and analyze experimental data <span class="citation">(Anderson et al. 2007)</span>.
In this case, data processing and analysis is implemented through the use of
formulas and macros embedded within the spreadsheet. When a spreadsheet has
formulas or macros within it, the spreadsheet program creates an internal record
of how cells are connected through these formulas. For example, if the value in
a specific cell is converted from Fahrenheit to Celsius to fill a second cell,
and then that value is combined with other values in a column to calculate the
mean temperature across several observations, then the spreadsheet program has
internally saved how the later cells depend on the earlier ones. When you change
the value recorded in a cell of a spreadsheet, the spreadsheet program queries
this record and only recalculates the cells that depend on that cell. This
process allows the program to quickly “react” to any change in cell inputs,
immediately providing an update to all downstream calculations and analyses
<span class="citation">(Levy 1984)</span>. Starting from the spreadsheet program Lotus 1-2-3,
spreadsheet programs also included <em>macros</em>, “a single computer instruction that
stands for a sequence of operations” <span class="citation">(Creeth 1985)</span>.</p>
<p>Spreadsheets have become so popular in part because so many people know how to
use them, at least in basic ways, and so many people have the software on their
computers that files can be shared with the virtual guarantee that everyone will
be able to open the file on their own computer <span class="citation">(Hermans et al. 2016)</span>.
Spreadsheets uses the visual metaphore of a traditional gridded ledger sheet
<span class="citation">(Levy 1984)</span>, providing an interface that is easy for users to
immediately understand and create a mental map of <span class="citation">(Birch, Lyford-Smith, and Guo 2018; Barga et al. 2011)</span>. This visually clear interface also means that
spreadsheets can be printed or incorporated into other documents (Word files,
PowerPoint presentations) “as-is”, as a workable and understandable table of
data values. In fact, some of the most popular plug-in software packages for the
early spreadsheet program Lotus 1-2-3 were programs for printing and publishing
spreadsheets <span class="citation">(Campbell-Kelly 2007)</span>. This “What You See Is What You Get”
interface was a huge advance from previous methods of data analysis for the
first spreadsheet program, VisiCalc, providing a “window to the data” that was
accessible to business executives and others without programming expertise
<span class="citation">(Creeth 1985)</span>. Several surveys of researchers have found that
spreadsheets were popular because of their simplicity and ease-of-use
<span class="citation">(Anderson et al. 2007; AlTarawneh and Thorne 2017; Barga et al. 2011)</span>. By
contrast, databases and scritped programming lanugages can be perceived as
requiring a cognitive load and lengthly training that is not worth the
investment when an easier tool is available <span class="citation">(Hermans et al. 2016; Anderson et al. 2007; Myneni and Patel 2010; Barga et al. 2011; Topaloglou et al. 2004)</span>.</p>
</div>
<div id="hazards-of-combining-recording-and-analysis" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Hazards of combining recording and analysis</h3>
<p><strong>Raw data often lost.</strong></p>
<p>One of the key tenets of ensuring that research is computationally reproducible
is to always keep a copy of all raw data, as well as the steps taken to get from
the raw data to a cleaned version of the data through to the results of data
analysis. However, maintaining a easily accessible copy of all original raw data
for a project is a common problem among biomedical researchers
<span class="citation">(Goodman et al. 2014)</span>, especially as team members move on from a laboratory group
<span class="citation">(Myneni and Patel 2010)</span>.</p>
<p>The use of spreadsheets to jointly record and analyze data can contribute to
this problem. Spreadsheets allow for the immediate and embedded processing of
data. As a result, it may become very difficult to pull out the raw data
originally recorded in a spreadsheet. At the least, the combination of raw and
processed data in a spreadsheet makes it hard to identify which data points
within a spreadsheet make up the raw data and which are the result of processing
that raw data. One study of operational spreadsheets noted that:</p>
<blockquote>
<p>“The data used in most spreadsheets is undocumented and there is no practical
way to check it. Even the original developer would have difficulty checking the
data.” <span class="citation">(Powell, Baker, and Lawson 2009)</span></p>
</blockquote>
<p>Further, data in a spreadsheet is typically not saved as “read-only”, so it is
possible for it to be accidentally overwritten. In situations where spreadsheets
are shared among multiple users, without “read-only” protection, original cell
values can easily be accidentally written over, and it may not be clear who last
changed a value, when it was changed, or why <span class="citation">(AlTarawneh and Thorne 2017)</span>.</p>
<p>Finally, many spreadsheets use a proprietary format. In the development of
spreadsheet programs, this use of proprietary, binary file formats helped a
software program keep users, increasing barriers for a user to switch to a new
program (since it wouldn’t be able to read their old files)
<span class="citation">(Campbell-Kelly 2007)</span>. However, this file format may be hard to open in the
future, as software changes and evolves <span class="citation">(Michener 2015)</span>; by comparison, plain
text files should be widely accessible through general purpose tools regardless
of changes to proprietary software like Microsoft Excel.</p>
<p><strong>Opacity of analysis steps and potential for errors.</strong></p>
<p>Previous studies have found that errors are very common within spreadsheets
<span class="citation">(Hermans et al. 2016)</span>. For example, one study of 50 operational
spreadsheets found that about 90% contained at least one error
<span class="citation">(Powell, Baker, and Lawson 2009)</span>. In part, it is easier to make errors in spreadsheets and
harder to catch errors in later work with a spreadsheet because the formulas and
connections between cells aren’t visible when you look at the
spreadsheet—they’re behind the scenes <span class="citation">(Birch, Lyford-Smith, and Guo 2018)</span>. This makes it very
hard to get a clear and complete view of the pipeline of analytic steps in data
processing and analysis within a spreadsheet, as well as to discern how cells
are connected within and across sheets of the spreadsheet. As one early article on
the history of spreadsheet programs notes:</p>
<blockquote>
<p>“People tend to forget that even the most elegantly crafted spreadsheet is a
house of cards, ready to collapse at the first erroneous assumption. The
spreadsheet that looks good but turns out to be tragically wrong is becoming
a familiar phenomenon.” <span class="citation">(Levy 1984)</span></p>
</blockquote>
<p>Some characteristics of spreadsheets may heighten chances for errors. These
include high conditional complexity (i.e., lots of branching of data flow
through if / else structures), formulas that depend on a large number of cells
or that incorporate many functions <span class="citation">(Hermans et al. 2016)</span>. Following the
logical chain of spreadsheet formulas can be particularly difficult when several
calculations are chained in a row <span class="citation">(Hermans and Murphy-Hill 2015)</span>. Very long chains of
dependent formulas across spreadsheet cells may in some case requiring sketching
out by hand the flow of information through the spreadsheet to understand what’s
going on <span class="citation">(Nardi and Miller 1990)</span>. The use of macros can also make it
particularly hard to figure out the steps of an analysis and to diagnose and fix
any bugs in those steps <span class="citation">(Nash 2006; Creeth 1985)</span>. One
study of spreadsheets in use in real life applications noted that, “Many
spreadsheets are so chaotically designed that auditing (especially of a few
formulas) is extremely difficult or impossible.” <span class="citation">(Powell, Baker, and Lawson 2009)</span></p>
<p>In some cases, formula dependences might span across different sheets of a
spreadsheet file. For the example given above of a spreadsheet that converts
temperature from one unit to another and then averages across observations, for
example, the original temperature might be recorded in one sheet while the
converted temperature value is calculated and shown in a second sheet. These
cross-sheet dependencies can make the analysis steps even more opaque
<span class="citation">(Hermans et al. 2016)</span>, as a change in the cell value of one sheet might not
be immediately visible as a change in another cell on that sheet (the same is
true for spreadsheets so large that upstream and downstream cells are not
concurrently visible on screen). Other common sources of errors included
incorrect references to cells inside formulas and incorrect use of formulas
<span class="citation">(Powell, Baker, and Lawson 2009)</span> or errors introduced through the common practice of copying
and pasting when developing spreadsheets <span class="citation">(Hermans et al. 2016)</span>.</p>
<p>To keep analysis steps clear, whether in scripted code or in spreadsheets or
pen-and-paper calculations, it is important to document what is being done at
each step and why <span class="citation">(Goodman et al. 2014)</span>. Scripted languages allow for code comments,
which are written directly into the script but not evaluated by the computer,
and so can be used to document steps within the code without changing the
operation of the code. Further, the program file itself often presents a linear,
step-by-step view of the pipeline, stored separated from the data itself
<span class="citation">(Creeth 1985)</span>. Calculations done with pen-and-paper (e.g., in a
laboratory notebook) can be annotated with text to document the steps. However,
there is evidence that spreadsheets are often poorly documented, or documented
in ways that are hard to keep track of. Before spreadsheets,</p>
<blockquote>
<p>“The formulas appeared in one place and the results in another. You could see
what you were getting. That cannot be said of electronic spreadsheets, which
don’t display the formulas that govern their calculations. As Mitch Kapor
explained, with electronic spreadsheets, ‘You can just randomly make formulas,
all of which depend on each other. And when you look at the final results, you
have no way of knowing what the rules are, unless someone tells you.’”
<span class="citation">(Levy 1984)</span></p>
</blockquote>
<p>Within spreadsheets, the logic and methods behind the pipeline of data
processing and analysis is often not documented, or only documented with cell
comments (hard to see as a whole) or in emails, not the spreadsheet file.
One study that investigated a large collection of spreadsheets found that most
do not include documentation explaining the logic or implementation of data
processing and analysis implemented within the spreadsheet
<span class="citation">(Hermans et al. 2016)</span>. A survey of neuroscience researchers at a UK
institute found that about a third of respondents included no documentation
for spreadsheets used in their research laboratories <span class="citation">(AlTarawneh and Thorne 2017)</span>.</p>
<p>When spreadsheet pipelines are documented, it is often through methods that are
hard to find and interpret later. One study of scientific researchers found
that, when research spreadsheets were documented, it was often through “cell
comments” added to specific cells in the spreadsheet, which can be hard to
interpret inclusively to understand the flow and logic of a spreadsheet as a
whole <span class="citation">(AlTarawneh and Thorne 2017)</span>. In some cases, teams discuss and document
functionality and changes in spreadsheets through email chains, passing
different versions of the spreadsheet file as attachments of emails with
discussion of the spreadsheet in the email body. One research team investigated
over 700,000 emails from employees of Enron that were released during legal
proceedings and investigated the spreadsheets attached to these emails (over
15,000 spreadsheets) as well as discussion of the spreadsheets within the emails
themselves <span class="citation">(Hermans and Murphy-Hill 2015)</span>. They found that the logic and methods of
calculations within the spreadsheets were often documented within the bodies of
emails that team members used to share and discuss spreadsheets. This means
that, if someone needs to figure out why a step was taken or identify when an
error was introduced into a spreadsheet, they may need to dig through the chain
of old emails documenting that spreadsheet, rather than being able to find the
relevant documentation within the spreadsheet’s own file.</p>
<p>Often spreadsheets are designed, and their structure determined, by one person,
and this is often done in an <em>ad hoc</em> fashion, rather than designing the
spreadsheet to follow a common structure for the research field or for the
laboratory group <span class="citation">(Anderson et al. 2007)</span>. Often, data processing and analysis
pipelines for spreadsheets are not carefully designed; instead, it’s more
typically for spreadsheet user to start by directly entering data and formulas
without a clear overall plan <span class="citation">(AlTarawneh and Thorne 2017)</span>. Often, the person who
created the spreadsheet is the only person who fully knows how it works
<span class="citation">(Myneni and Patel 2010)</span>, particularly if the spreadsheet includes complex
macros or a complicated structure in the analysis pipeline
<span class="citation">(Creeth 1985)</span>.</p>
<p>This practice creates a heavy dependence on the person who created that
spreadsheet anytime the data or results in that spreadsheet need to be
interpreted. This is particularly problematic in projects where the spreadsheet
will be shared for collaboration or adapted to be used in a future project, as
is often done in scientific research groups. One survey of neuroscience
researchers at a UK institute, for example, found that “on average, 2–5
researchers share the same spreadsheet”. <span class="citation">(AlTarawneh and Thorne 2017)</span> In this case, it
can be hard to “onboard” new people to use the file, and much of the work and
knowledge about the spreadsheet can be lost when that person moves on from the
business or laboratory group <span class="citation">(Creeth 1985; Myneni and Patel 2010)</span>. If you share a spreadsheet with numerous and complex
macros and formulas included to clean and analyze the data, it can take an
extensive amount of time, and in some cases may be impossible, for the
researcher you share it with to decipher what is being done to get from the
original data input in some cells to the final results shown in others and in
graphs. Further, if others can’t figure out the steps being done through macros
and formulas in a spreadsheet, they will not be able to check it for problems in
the logic of the overall analysis pipeline or for errors in the specific
formulas used within that pipeline. They also will struggle to extend and adapt
the spreadsheet to be used for other projects. These problems come up not only
when sharing with a collaborator, but also when reviewing spreadsheets that you
have previously created and used (as many have noted, your most frequent
collaborator will likely be “future you”). In fact, one survey of biomedical
researchers at the University of Washington noted that,</p>
<blockquote>
<p>“The profusion of individually created spreadsheets containing overlapping and
inconsistently updated data created a great deal of confusion within some labs.
There was little consideration to future data exchange of submission
requirements at the time of publication.” <span class="citation">(Anderson et al. 2007)</span></p>
</blockquote>
<p>There are methods that have been brought from more traditional programming work
into spreadsheet programming to try to help limit errors, including spreadsheet
assertions to enable testing of spreadsheets <span class="citation">(Hermans et al. 2016)</span>.
However, these are often not implemented, in part perhaps because many
spreadsheet users see themselves as “end-users”, creating spreadsheets for their
own personal use rather than as something robust to future use by others, and so
don’t seek out strategies adopted by “programmers” when creating stable tools
for others to use <span class="citation">(Hermans et al. 2016)</span>. In practice, though, often a
spreadsheet is used much longer, and by more people, than originally intended.
Often, the spreadsheet in this case was not designed for robust, long-term use.
From early in the history of spreadsheet programs, users have shared spreadsheet
files with interesting functionality with other users <span class="citation">(Levy 1984)</span>,
and the lifespan of a spreadsheet can be much longer than originally
intended—a spreadsheet created by one user for their own personal use can end
up being used and modified by that person or others for years
<span class="citation">(Hermans et al. 2016)</span>.</p>
<p><strong>Subpar software for analysis.</strong></p>
<p>While spreadsheets serve as a widely-used tool for data recording and analysis,
in many cases spreadsheets programs are poorly suited to clean and analyze
scientific data compared to other programs. As tools and interfaces continue to
develop that make other software more user-friendly to those new to programming,
scientists may want to reevaluate the costs and benefits, in terms of both time
required for training and aptness of tools, for spreadsheet programs compared to
using scripted programming languages like R and Python.</p>
<p>Several problems have been identified with spreadsheet programs in the context of
recording and, especially, analyzing scientific data. First, some statistical
methods may be inferior to those available in other statistical programming language.
Since the most popular spreadsheet program (Excel) is closed source, it is hard to
identify and diagnose such problems, and there is likely less of an incentive for
problems in statistical methodology to be fixed (rather than using development time
and funds to increase easier-to-see functionality in the program). Many statistical
operations require computations that cannot be perfectly achieved with a
computer, since the computer must ultimately solve many mathematical problems using
numerical approximations rather than continuous methods (e.g., calculus). The choice of
the algorithms used for these approximations heavily influence how closely a result
approximates the true answer.</p>
<p>A series of papers examined the quality of statistical methods in several
statistical software programs, including Excel, starting in the 1990s
<span class="citation">(Bruce D McCullough and Wilson 1999; Bruce D McCullough 1999; McCullough and Wilson 2002, 2005; McCullough and Heiser 2008; Mélard 2014)</span>. In the
earliest studies, they found some concerns across all programs considered
<span class="citation">(Bruce D McCullough and Wilson 1999; Bruce D McCullough 1999)</span>. One of the biggest
concerns, however, was that there was little evidence over the years that the
identified problems in Excel were resolved, or at least improved, over time
<span class="citation">(McCullough 2001; McCullough and Heiser 2008)</span>. The authors note that there may
be little incentive for checking and fixing problems with algorithms for
statistical approximation in closed source software like Excel, where sales
might depend more on the more immediately evident functionality in the software,
while problems with statistical algorithms might be less evident to potential
users <span class="citation">(McCullough 2001)</span>.</p>
<p>Open source software, on the other hand, offers pathways for identifying and fixing
any problems in the software, including for statistical algorithms and methods
implemented in the software’s code. Since the full source code is available, researchers
can closely inspect the algorithms being used and compare them to the latest
knowledge in statistical computing methodology. Further, if an inferior algorithm is in
use, most open source software licenses allow a user to adapt and extend the software,
for example to implement better statistical algorithms.</p>
<p>Second, spreadsheet programs can include automated functionality that’s meant to
make something easier for most users, but that might invisibly create problems
in some cases. A critical problem, for example, has been identified when using
Excel for genomics data. When Excel encounters a cell value in a format that
seems like it could be a date (e.g., “Mar-3-06”), it will try to convert that
cell to a “date” class. Many software programs save date as this special “date”
format, where it is printed and visually appears in a format like “3-Mar-06” but
is saved internally by the program as a number (for Microsoft Excel, the number
of days since January 1, 1900 <span class="citation">(Willekens 2013)</span>). By doing this, the
software can more easily undertake calculations with dates, like calculating the
number of days between two dates or which of two dates is earlier.
Bioinformatics researchers at the National Institutes of Health found that Excel
was doing this type of automatic and irreversible date conversion for 30 gene
names, including “MAR3” and “APR-4”, resulting in these gene names being lost
for further analysis <span class="citation">(Zeeberg et al. 2004)</span>. Other automatic conversion problems
caused the lost of clone identifiers with composed of digits and the letter “E”
<span class="citation">(Zeeberg et al. 2004; Welsh et al. 2017)</span>, which were assumed to be expressing a
number using scientific notation and so automatically and irreversibly converted
to a numeric class. Further automatic conversion problems can be caused by cells
that start with an operator (e.g., “+ control”) or with leading zeros in a
numeric identifier (e.g., “007”) <span class="citation">(Welsh et al. 2017)</span>.</p>
<p>Avoiding this automatic date conversion required specifying that columns with
columns susceptible to these problems, including columns of gene names, should
be retained in a “text” class in Excel’s file import process. While this
problem was originally identified and published in 2004 <span class="citation">(Zeeberg et al. 2004)</span>,
along with tips to identify and avoid the problem, a study in 2016 found that
approximately a fifth of genomics papers investigated in a large-scale review
had gene name errors resulting from Excel automatic conversion, with the rate of
errors actually increasing over time <span class="citation">(Ziemann, Eren, and El-Osta 2016)</span>.</p>
<p>Finally, spreadsheet programs can be limited as analysis needs become more
complex or large <span class="citation">(Topaloglou et al. 2004)</span>. For example, spreadsheets can be
problematic when integrating or merging large, separate datasets
<span class="citation">(Birch, Lyford-Smith, and Guo 2018)</span>. This can create barriers, for example, in biological studies
seeking to integrate measurements from different instruments (e.g., flow
cytometry data with RNA-sequencing data). Further, while datasets continue to
expand in their capacity for data, for very large datasets they continue to face
limits that may be reached in practical applications <span class="citation">(Birch, Lyford-Smith, and Guo 2018)</span>, and
their efficiency of running data processing and analysis pipelines across large
datasets can be slow compared to code implemented with other programming
languages.</p>
<p><strong>Difficulty collaborating with statisticians.</strong></p>
<p>Modern biomedical researchers requires large teams, with statisticians and
bioinformaticians often forming a critical part of the team to enable
sophisticated processing and analysis of experimental data. However, the process
of combining data recording and analysis of experimental data, especially
through the use of spreadsheet programs, can create barriers in working across
disciplines. One group defined these issues as “data friction” and “science
friction”—the extra steps and work required at each interface where data
passes, for example, from a machine to analysis or from a collaborator in one
discipline to one in a separate discipline <span class="citation">(Edwards et al. 2011)</span>.
From a survey of scientific labs, for example, one respondent said:</p>
<blockquote>
<p>“I can give data that I think are appropriate to answer a question to a
biostatistician, but when they look at it, they see it from a different point of
view. And that spreadsheet does not really encapsulate where it came from very
well, how was it generated, was it random, how was this data collected. You
would run a series of queries that you think are pertinent to what this
biostatistician would want to know. They become a part of the exploration and
not just a receiver of whatever I decided to put in my spreadsheet on that day.
What I get back is almost never fully documented in any way that I can really
understand and add more to the process.” <span class="citation">(Myneni and Patel 2010)</span></p>
</blockquote>
<p>When collaborating with statisticians or bioinformaticians, one of the key
sources of this “data friction” can result from the use of spreadsheets to
jointly record and analyze experiemental data. First, spreadsheets are easy to
print or copy into another format (e.g., PowerPoint presentation, Word
document), and so researchers often design spreadsheets to be immediately
visually appealing to viewers. For example, a spreadsheet might be designed to
include hierarchically organized headers (e.g., heading and subheading, some
within a cell merged across several columns), or to show the result of a
calculation at the bottom of a column of observations (e.g., “Total” in the last
cell of the column) <span class="citation">(Teixeira and Amaral 2016)</span>. Multiple separate small tables
might be included in the same sheet, with empty cells used for visual
separation, or use a “horizontal single entry” design , where the headers are in
the leftmost column rather than the top row <span class="citation">(Teixeira and Amaral 2016)</span>.</p>
<p>These spreadsheet design choices make it much more difficult for the contents of
the spreadsheet to be read into other statistical programs. These types of data
require several extra steps in coding, in some cases fairly complex coding, with
regular expressions or logical rules needed to parse out the data and convert it
to the needed shape, before the statistical work can be done for the dataset.
This is a poor use of time for a collaborating statistician, especially if it
can be avoided through the design of the data recording template. Further, it
introduces many more chances for errors in cleaning the data.</p>
<p>Further, information embedded in formulas, macros, and extra formatting like
color or text boxes is lost when the spreadsheet file is input into other
programs. Spreadsheets allow users to use highlighting to represent information
(e.g., measurements for control animals shown in red, those for experiment
animals in blue) and to include information or documentation in text boxes. For
example, one survey study of biomedical researchers at the University of
Washington included this quote from a respondent: “I have one spreadsheet that
has all of my chromosomes … and then I’ve gone through and color coded it for
homozygosity and linkage.” <span class="citation">(Anderson et al. 2007)</span> All the information encoded in
this sheet through color will be lost when the data from the spreadsheet is read
into another statistical program.</p>
</div>
<div id="approaches-to-separate-recording-and-analysis" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Approaches to separate recording and analysis</h3>
<p>In the remaining modules in this section, we will present and describe techniques
that can be used to limit or remove these problems. First, in the module on
“Structure data”, we will walk through techniques to design data recording
formats so that data is saved in a consistent format across experiments within
a laboratory group, and in a way that removes “data friction” for collaboration
with statisticians or later use in scripted code. These techniques can be immediately
used to design a better spreadsheet to be used solely for data collection.</p>
<p>In later modules, we will discuss the use of R projects to coordinate data
recording and analysis steps within a directory, while using separate files for
data recording versus data processing and analysis. These more advanced formats
will enable the use of quality assurance / control measures like testing of data
entry and analysis functionality, better documentation of data analysis pipelines,
and easy use of version control to track projects and collaborate transparently and
with a recorded history.</p>
<p>[We will probably want to flesh this section out as we write later modules.]</p>
</div>
<div id="discussion-questions" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Discussion questions</h3>

</div>
</div>
<div id="principles-and-power-of-structured-data-formats" class="section level2">
<h2><span class="header-section-number">2.2</span> Principles and power of structured data formats</h2>
<p>The format in which experimental data is recorded can have a large influence on
how easy and likely it is to implement reproducibility tools in later stages of
the research workflow. Recording data in a “structured” format brings many
benefits. In this module, we will explain what makes a dataset “structured” and
why this format is a powerful tool for reproducible research.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>List the characteristics of a structured data format</li>
<li>Describe benefits for research transparency and reproducibility</li>
<li>Outline other benefits of using a structured format when recording data</li>
</ul>
<div id="characteristics-of-a-structured-data-format" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Characteristics of a structured data format</h3>
</div>
<div id="benefits-of-a-structured-data-format" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Benefits of a structured data format</h3>
<p>From a working group on bioinformatics and data-intensive science: “Many simple
analyses are not automated because data formats are a moving target. … The
community has been slow to share tools, partially because tools are not robust
against different input formats.” <span class="citation">(Barga et al. 2011)</span></p>
<p>“Determine whether there is a community-based metadata schema or standard (i.e.,
preferred sets of metadata elements) that can be adopted.” <span class="citation">(Michener 2015)</span></p>
<p>First, you can still use spreadsheets, but reduce their use to recording data,
leaving all data cleaning and analysis to be handled with other software. To make
it easier to collaborate with statisticians and to interface with a program like
R for data cleaning and analysis, it will be easiest if you set up your data
recording to include with other statistical programs like R or Python. These
steps are described in a later section, “…”.</p>
<ul>
<li>Each sheet of the spreadsheet should contain data from a single
experiment.</li>
<li>Never use whitespace to represent a meaningful separation in data within
a spreadsheet. Never include multiple tables of data in the same sheet.</li>
<li>The first row of the spreadsheet should include a short column name for
each column with data. All column name information should be within a single row
(i.e., avoid subheadings). Avoid any special characters (e.g., “%”) in column
names. Instead, use only letters, numbers, and underscores ("_"), and start with a letter.
It is especially helpful if you can avoid spaces in column names.</li>
<li>Missing data should be represented consistently in cells. “NA” is one choice. If
you want to clarify why data is missing, it’s much better to add a column (e.g., “why_missing”)
where you can provide those details in text, rather than combining within a single column
numerical observation data with textual reasons for missingness in cells with missing values.</li>
</ul>
<p>Next, you could record data using a statistical language like R. There is an
excellent Integrated Development Environment for R called RStudio, and it creates a
much clearer interface with R compared to running R from a commond line, particularly for new users. RStudio allows you to open delimited plain text files, like csvs, using
a grid-style interface. This grid-style interface looks very similar to a
spreadsheet, but lacks the ability to include formulas or macros. Therefore, this
format enforces a separation of the recording of raw data from the cleaning and
analysis of the data.</p>
<p>[R Project templates]</p>
<p>Data cleaning and analysis can then be shifted away from the files used to
record the data and into reproducible scripts. These scripts can be clearly
documented, either through comments in the code or through open source
documentation tools like RMarkdown than interweave code and text in a way that
allows the creation of documents that are easier to read than commented code.</p>
<p>This documentation should explain why each step is being done. In cases where
it is not immediately evident from the code <em>how</em> the step is being done, this
should be documented as well. Any assumptions being used should be clarified in
the documentation.</p>
</div>
<div id="applied-exercise" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Applied exercise</h3>

</div>
</div>
<div id="the-tidy-data-format" class="section level2">
<h2><span class="header-section-number">2.3</span> The ‘tidy’ data format</h2>
<p>The “tidy” data format is an implementation of a structured data format popular
among statisticians and data scientists. By consistently using this data format,
researchers can combine simple, generalizable tools to perform complex tasks in
data processing, analysis, and visualization. We will explain what
characteristics determine if a dataset is “tidy” and how use of the “tidy”
implementation of a structure data format can improve the ease and efficiency of
“Team Science”.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>List characteristics defining the “tidy” structured data format</li>
<li>Explain the difference between the a structured data format (general concept)
and the ‘tidy’ data format (one popular implementation)</li>
</ul>
<div id="the-tidy-data-format-1" class="section level3">
<h3><span class="header-section-number">2.3.1</span> The “tidy” data format</h3>
</div>
<div id="the-tidy-data-format-as-a-structured-data-format" class="section level3">
<h3><span class="header-section-number">2.3.2</span> The “tidy” data format as a structured data format</h3>
</div>
<div id="practice-quiz" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Practice quiz</h3>

</div>
</div>
<div id="designing-templates-for-tidy-data-collection" class="section level2">
<h2><span class="header-section-number">2.4</span> Designing templates for “tidy” data collection</h2>
<p>This module will move from the principles of the “tidy” data format to the
practical details of designing a “tidy” data format to use when collecting
experimental data. We will describe common issues that prevent biomedical
research datasets from being “tidy” and show how these issues can be avoided. We
will also provide rubrics and a checklist to help determine if a data collection
template complies with a “tidy” format.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Identify characteristics that keep a dataset from being ‘tidy’</li>
<li>Convert data from an “untidy” to a “tidy” format</li>
</ul>
<div id="subsection-1" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Subsection 1</h3>
<p>“Or maybe your goal is that your data is <em>usable</em> in a wide range of
applications? If so, consider adopting standard formats and metadata
standards early on. At the very least, keep track of versions of data
and code, with associated dates.” <span class="citation">(Goodman et al. 2014)</span></p>
<p>“Standards for data include, for example, data formats, data exchange
protocols, and meta-data controlled vocabularies.” <span class="citation">(Barga et al. 2011)</span></p>
</div>
<div id="applied-exercise-1" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Applied exercise</h3>

</div>
</div>
<div id="example-creating-a-template-for-tidy-data-collection" class="section level2">
<h2><span class="header-section-number">2.5</span> Example: Creating a template for “tidy” data collection</h2>
<p>We will walk through an example of creating a template to collect data in a
“tidy” format for a laboratory-based research project, based on a research
project on drug efficacy in murine tuberculosis models. We will show the initial
“untidy” format for data recording and show how we converted it to a “tidy”
format. Finally, we will show how the data can then easily be analyzed and
visualized using reproducible tools.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Understand how the principles of “tidy” data can be applied for a real, complex research project;</li>
<li>List advantages of the “tidy” data format for the example project</li>
</ul>
<div id="subsection-1-1" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Subsection 1</h3>
</div>
<div id="subsection-2" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Subsection 2</h3>
</div>
<div id="discussion-questions-1" class="section level3">
<h3><span class="header-section-number">2.5.3</span> Discussion questions</h3>

</div>
</div>
<div id="power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files" class="section level2">
<h2><span class="header-section-number">2.6</span> Power of using a single structured ‘Project’ directory for storing and tracking research project files</h2>
<p>To improve the computational reproducibility of a research project, researchers
can use a single ‘Project’ directory to collectively store all research data,
meta-data, pre-processing code, and research products (e.g., paper drafts,
figures). We will explain how this practice improves the reproducibility and
list some of the common components and subdirectories to include in the
structure of a ‘Project’ directory, including subdirectories for raw and
pre-processed experimental data.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Describe a ‘Project’ directory, including common components and subdirectories</li>
<li>List how a single ‘Project’ directory improves reproducibility</li>
</ul>
<div id="subsection-1-2" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Subsection 1</h3>
<p>One study surveyed over 250 biomedical researchers at the University of Washington.
They noted that, “a common theme surrounding data management and analysis was that
may researchers preferred to utilize their own individual methods to organize data.
The varied ways of managing data were accepted as functional for most present needs.
Some researchers admitted to having no organizational methodology at all, while others
used whatever method best suited their individual needs.” <span class="citation">(Anderson et al. 2007)</span>
One respondent answered, “They’re not organized in any way—they’re just thrown into
files under different projects,” while another said “I grab them when I need them, they’re
not organized in any decent way,” and another, “It’s not even organized—a file on a central
computer of protocols that we use, common lab protocols but those are just individual
Word files within a folder so it’s not searchable per se.” <span class="citation">(Anderson et al. 2007)</span></p>
<p>“In general, data reuse is most possible when: 1) data; 2) metadata (information
describing the data); and 3) information about the process of generating those data,
such as code, are all provided.” <span class="citation">(Goodman et al. 2014)</span></p>
</div>
<div id="subsection-2-1" class="section level3">
<h3><span class="header-section-number">2.6.2</span> Subsection 2</h3>
</div>
<div id="practice-quiz-1" class="section level3">
<h3><span class="header-section-number">2.6.3</span> Practice quiz</h3>

</div>
</div>
<div id="creating-project-templates" class="section level2">
<h2><span class="header-section-number">2.7</span> Creating ‘Project’ templates</h2>
<p>Researchers can use RStudio’s ‘Projects’ can facilitate collecting research
files in a single, structured directory, with the added benefit of easy use of
version control. Researchers can gain even more benefits by consistently
structuring all their ‘Project’ directories. We will demonstrate how to
implement structured project directories through RStudio, as well as how RStudio
enables the creation of a ‘Project’ for initializing consistently-structured
directories for all of a research group’s projects.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Be able to create a structured <code>Project</code> directory within RStudio</li>
<li>Understand how RStudio can be used to create ‘Project’ templates</li>
</ul>
<div id="subsection-1-3" class="section level3">
<h3><span class="header-section-number">2.7.1</span> Subsection 1</h3>
</div>
<div id="subsection-2-2" class="section level3">
<h3><span class="header-section-number">2.7.2</span> Subsection 2</h3>
</div>
<div id="discussion-questions-2" class="section level3">
<h3><span class="header-section-number">2.7.3</span> Discussion questions</h3>

</div>
</div>
<div id="example-creating-a-project-template" class="section level2">
<h2><span class="header-section-number">2.8</span> Example: Creating a ‘Project’ template</h2>
<p>We will walk through a real example, based on the experiences of one of our
Co-Is, of establishing the format for a research group’s ‘Project’ template,
creating that template using RStudio, and initializing a new research project
directory using the created template. This example will be from a
laboratory-based research group that studies the efficacy of tuberculosis drugs
in a murine model.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Create a ‘Project’ template in RStudio to initialize consistently-formatted
‘Project’ directories</li>
<li>Initialize a new ‘Project’ directory using this template</li>
</ul>
<div id="subsection-1-4" class="section level3">
<h3><span class="header-section-number">2.8.1</span> Subsection 1</h3>
</div>
<div id="subsection-2-3" class="section level3">
<h3><span class="header-section-number">2.8.2</span> Subsection 2</h3>
</div>
<div id="applied-exercise-2" class="section level3">
<h3><span class="header-section-number">2.8.3</span> Applied exercise</h3>

</div>
</div>
<div id="harnessing-version-control-for-transparent-data-recording" class="section level2">
<h2><span class="header-section-number">2.9</span> Harnessing version control for transparent data recording</h2>
<p>As a research project progresses, a typical practice in many experimental
research groups is to save new versions of files (e.g., ‘draft1.doc’,
‘draft2.doc’), so that changes can be reverted. However, this practice leads to
an explosion of files, and it becomes hard to track which files represent the
‘current’ state of a project. Version control allows researchers to edit and
change research project files more cleanly, while maintaining the power to
‘backtrack’ to previous versions, messages included to explain changes. We will
explain what version control is and how it can be used in research projects to
improve the transparency and reproducibility of research, particularly for data
recording.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Describe version control<br />
</li>
<li>Explain how version control can be used to improve reproducibility
for data recording</li>
</ul>
<div id="subsection-1-5" class="section level3">
<h3><span class="header-section-number">2.9.1</span> Subsection 1</h3>
<p>“Or maybe your goal is that your data is <em>usable</em> in a wide range of
applications? If so, consider adopting standard formats and metadata
standards early on. At the very least, keep track of versions of data
and code, with associated dates.” <span class="citation">(Goodman et al. 2014)</span></p>
<p><strong>Email attachments in lieu of common access files.</strong></p>
<p>…</p>
<p>For example, one group of researchers investigated a large collection of emails
from Enron <span class="citation">(Hermans and Murphy-Hill 2015)</span>. They found that passing Excel files through
email attachements was a common practice, and that messages within emails
suggested that spreadsheets were stored locally, rather than in a location that
was accessible to all team members <span class="citation">(Hermans and Murphy-Hill 2015)</span>, which meant that team
members might often be working on different versions of the same spreadsheet
file. They note that “the practice of emailing spreadsheets is known to result in
serious problems in terms of accountability and errors, as people do not have
access to the latest version of a spreadsheet, but need to be updated of changes
via email.” <span class="citation">(Hermans and Murphy-Hill 2015)</span></p>
<p>“Team members regularly pass data files back and forth by hand, by email, and by
using shared lab or project servers, websites, and databases.”
<span class="citation">(Edwards et al. 2011)</span></p>
<p><strong>Version control for spreadsheets</strong></p>
<p>“Recent versions of spreadsheets now incorporate a ‘Traack Changes’ functionality
which enables highlighting of changes made by different users along with a comment
and review system. Such tools are a start toward this but more robust version control
systems are required particularly in the context of increasingly online and
collaborative method of working where large teams interact with a single document
concurrently.” <span class="citation">(Birch, Lyford-Smith, and Guo 2018)</span></p>
</div>
<div id="subsection-2-4" class="section level3">
<h3><span class="header-section-number">2.9.2</span> Subsection 2</h3>
</div>
<div id="discussion-questions-3" class="section level3">
<h3><span class="header-section-number">2.9.3</span> Discussion questions</h3>

</div>
</div>
<div id="enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms" class="section level2">
<h2><span class="header-section-number">2.10</span> Enhance the reproducibility of collaborative research with version control platforms</h2>
<p>Once a researcher has learned to use <em>git</em> on their own computer for
local version control, they can begin using version control platforms (e.g.,
<em>GitLab</em>, <em>GitHub</em>) to collaborate with others under version
control. We will describe how a research team can benefit from using a version
control platform to work collaboratively.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>List benefits of using a version control platform to collaborate
on research projects, particularly for reproducibility</li>
<li>Describe the difference between version control (e.g., <em>git</em>) and
a version control platform (e.g., <em>GitLab</em>)</li>
</ul>
<div id="subsection-1-6" class="section level3">
<h3><span class="header-section-number">2.10.1</span> Subsection 1</h3>
<p><strong>VC platforms as a form of back-up.</strong></p>
<p>One study surveyed neuroscience researchers at a UK institute. “The backup ‘rule
of three’ states that for a file to be sufficiently backed up it should be kept
in three separate locations using two different types of media with one offsite
backup. A lack of an adequate backup solution could mean permanently lost data,
effort and time. In this research, more than 82% of the respondents seemed to be
unaware of suitable backup procedures to protect their data. Some respondents
kept a single backup of work on external hard disks. Others used the
Universities local networked servers as their means of backup.”
<span class="citation">(AlTarawneh and Thorne 2017)</span></p>
<p>“A good approach is to store at least three copies in at least two
geographically distributed locations (e.g., original location such as a desktop
computer, an external hard drive, and one or more remote sites) and to adopt a
regular schedule for duplicating the data (i.e., backup).” <span class="citation">(Michener 2015)</span></p>
</div>
<div id="subsection-2-5" class="section level3">
<h3><span class="header-section-number">2.10.2</span> Subsection 2</h3>
</div>
<div id="discussion-questions-4" class="section level3">
<h3><span class="header-section-number">2.10.3</span> Discussion questions</h3>

</div>
</div>
<div id="using-git-and-gitlab-to-implement-version-control" class="section level2">
<h2><span class="header-section-number">2.11</span> Using git and GitLab to implement version control</h2>
<p>For many years, use of version control required use of the command line,
limiting its accessibility to researchers with limited programming experience.
However, graphical interfaces have removed this barrier, and RStudio has
particularly user-friendly tools for implementing version control. In this
module, we will show how to use <em>git</em> through RStudio’s user-friendly
interface and how to connect from a local computer to <em>GitLab</em> through
RStudio.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>Understand how to set up and use <em>git</em> through RStudio’s interface</li>
<li>Understand how to connect with <em>GitLab</em> through RStudio to collaborate on<br />
research projects while maintaining version control</li>
</ul>
<div id="subsection-1-7" class="section level3">
<h3><span class="header-section-number">2.11.1</span> Subsection 1</h3>
</div>
<div id="subsection-2-6" class="section level3">
<h3><span class="header-section-number">2.11.2</span> Subsection 2</h3>
</div>
<div id="applied-exercise-3" class="section level3">
<h3><span class="header-section-number">2.11.3</span> Applied exercise</h3>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="experimental-data-preprocessing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01-separating.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["improve_repro.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
