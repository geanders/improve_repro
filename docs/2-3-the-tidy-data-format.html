<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="2.3 The ‘tidy’ data format | Improving the Reproducibility of Experimental Data Recording and Pre-Processing" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing." />
<meta name="github-repo" content="rstudio/bookdown-demo" />

<meta name="author" content="Brooke Anderson, Michael Lyons, Mercedes Gonzalez-Juarrero, Marcela Henao-Tamayo, and Gregory Robertson" />



<meta name="description" content="Online book with modules for improving the reproducibility of experimental data recording and preprocessing.">

<title>2.3 The ‘tidy’ data format | Improving the Reproducibility of Experimental Data Recording and Pre-Processing</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />




<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#overview"><span class="toc-section-number">1</span> Overview</a><ul>
<li><a href="1-1-license.html#license"><span class="toc-section-number">1.1</span> License</a></li>
</ul></li>
<li class="has-sub"><a href="2-experimental-data-recording.html#experimental-data-recording"><span class="toc-section-number">2</span> Experimental Data Recording</a><ul>
<li class="has-sub"><a href="2-1-separating-data-recording-and-analysis.html#separating-data-recording-and-analysis"><span class="toc-section-number">2.1</span> Separating data recording and analysis</a><ul>
<li><a href="2-1-separating-data-recording-and-analysis.html#data-recording-versus-data-analysis"><span class="toc-section-number">2.1.1</span> Data recording versus data analysis</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#hazards-of-combining-recording-and-analysis"><span class="toc-section-number">2.1.2</span> Hazards of combining recording and analysis</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#approaches-to-separate-recording-and-analysis"><span class="toc-section-number">2.1.3</span> Approaches to separate recording and analysis</a></li>
<li><a href="2-1-separating-data-recording-and-analysis.html#discussion-questions"><span class="toc-section-number">2.1.4</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="2-2-principles-and-power-of-structured-data-formats.html#principles-and-power-of-structured-data-formats"><span class="toc-section-number">2.2</span> Principles and power of structured data formats</a><ul>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#data-recording-standards"><span class="toc-section-number">2.2.1</span> Data recording standards</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#defining-data-standards-for-a-research-group"><span class="toc-section-number">2.2.2</span> Defining data standards for a research group</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#two-dimensional-structured-data-format"><span class="toc-section-number">2.2.3</span> Two-dimensional structured data format</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#saving-two-dimensional-structured-data-in-plain-text-file-formats"><span class="toc-section-number">2.2.4</span> Saving two-dimensional structured data in plain text file formats</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#occassions-for-more-complex-data-structures-and-file-formats"><span class="toc-section-number">2.2.5</span> Occassions for more complex data structures and file formats</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#levels-of-standardizationresearch-group-to-research-community"><span class="toc-section-number">2.2.6</span> Levels of standardization—research group to research community</a></li>
<li><a href="2-2-principles-and-power-of-structured-data-formats.html#applied-exercise"><span class="toc-section-number">2.2.7</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="2-3-the-tidy-data-format.html#the-tidy-data-format"><span class="toc-section-number">2.3</span> The ‘tidy’ data format</a><ul>
<li><a href="2-3-the-tidy-data-format.html#the-tidy-data-format-1"><span class="toc-section-number">2.3.1</span> The “tidy” data format</a></li>
<li><a href="2-3-the-tidy-data-format.html#what-makes-data-tidy"><span class="toc-section-number">2.3.2</span> What makes data “tidy”?</a></li>
<li><a href="2-3-the-tidy-data-format.html#why-make-your-data-tidy"><span class="toc-section-number">2.3.3</span> Why make your data “tidy”?</a></li>
<li><a href="2-3-the-tidy-data-format.html#using-tidyverse-tools-with-data-in-the-tidy-data-format"><span class="toc-section-number">2.3.4</span> Using tidyverse tools with data in the “tidy data” format</a></li>
<li><a href="2-3-the-tidy-data-format.html#practice-quiz"><span class="toc-section-number">2.3.5</span> Practice quiz</a></li>
</ul></li>
<li class="has-sub"><a href="2-4-designing-templates-for-tidy-data-collection.html#designing-templates-for-tidy-data-collection"><span class="toc-section-number">2.4</span> Designing templates for “tidy” data collection</a><ul>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#subsection-1"><span class="toc-section-number">2.4.1</span> Subsection 1</a></li>
<li><a href="2-4-designing-templates-for-tidy-data-collection.html#applied-exercise-1"><span class="toc-section-number">2.4.2</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#example-creating-a-template-for-tidy-data-collection"><span class="toc-section-number">2.5</span> Example: Creating a template for “tidy” data collection</a><ul>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-1-1"><span class="toc-section-number">2.5.1</span> Subsection 1</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#subsection-2"><span class="toc-section-number">2.5.2</span> Subsection 2</a></li>
<li><a href="2-5-example-creating-a-template-for-tidy-data-collection.html#discussion-questions-1"><span class="toc-section-number">2.5.3</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="2-6-power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files.html#power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files"><span class="toc-section-number">2.6</span> Power of using a single structured ‘Project’ directory for storing and tracking research project files</a><ul>
<li><a href="2-6-power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files.html#subsection-1-2"><span class="toc-section-number">2.6.1</span> Subsection 1</a></li>
<li><a href="2-6-power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files.html#subsection-2-1"><span class="toc-section-number">2.6.2</span> Subsection 2</a></li>
<li><a href="2-6-power-of-using-a-single-structured-project-directory-for-storing-and-tracking-research-project-files.html#practice-quiz-1"><span class="toc-section-number">2.6.3</span> Practice quiz</a></li>
</ul></li>
<li class="has-sub"><a href="2-7-creating-project-templates.html#creating-project-templates"><span class="toc-section-number">2.7</span> Creating ‘Project’ templates</a><ul>
<li><a href="2-7-creating-project-templates.html#subsection-1-3"><span class="toc-section-number">2.7.1</span> Subsection 1</a></li>
<li><a href="2-7-creating-project-templates.html#subsection-2-2"><span class="toc-section-number">2.7.2</span> Subsection 2</a></li>
<li><a href="2-7-creating-project-templates.html#discussion-questions-2"><span class="toc-section-number">2.7.3</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="2-8-example-creating-a-project-template.html#example-creating-a-project-template"><span class="toc-section-number">2.8</span> Example: Creating a ‘Project’ template</a><ul>
<li><a href="2-8-example-creating-a-project-template.html#subsection-1-4"><span class="toc-section-number">2.8.1</span> Subsection 1</a></li>
<li><a href="2-8-example-creating-a-project-template.html#subsection-2-3"><span class="toc-section-number">2.8.2</span> Subsection 2</a></li>
<li><a href="2-8-example-creating-a-project-template.html#applied-exercise-2"><span class="toc-section-number">2.8.3</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="2-9-harnessing-version-control-for-transparent-data-recording.html#harnessing-version-control-for-transparent-data-recording"><span class="toc-section-number">2.9</span> Harnessing version control for transparent data recording</a><ul>
<li><a href="2-9-harnessing-version-control-for-transparent-data-recording.html#subsection-1-5"><span class="toc-section-number">2.9.1</span> Subsection 1</a></li>
<li><a href="2-9-harnessing-version-control-for-transparent-data-recording.html#subsection-2-4"><span class="toc-section-number">2.9.2</span> Subsection 2</a></li>
<li><a href="2-9-harnessing-version-control-for-transparent-data-recording.html#discussion-questions-3"><span class="toc-section-number">2.9.3</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="2-10-enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms.html#enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms"><span class="toc-section-number">2.10</span> Enhance the reproducibility of collaborative research with version control platforms</a><ul>
<li><a href="2-10-enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms.html#subsection-1-6"><span class="toc-section-number">2.10.1</span> Subsection 1</a></li>
<li><a href="2-10-enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms.html#subsection-2-5"><span class="toc-section-number">2.10.2</span> Subsection 2</a></li>
<li><a href="2-10-enhance-the-reproducibility-of-collaborative-research-with-version-control-platforms.html#discussion-questions-4"><span class="toc-section-number">2.10.3</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="2-11-using-git-and-gitlab-to-implement-version-control.html#using-git-and-gitlab-to-implement-version-control"><span class="toc-section-number">2.11</span> Using git and GitLab to implement version control</a><ul>
<li><a href="2-11-using-git-and-gitlab-to-implement-version-control.html#subsection-1-7"><span class="toc-section-number">2.11.1</span> Subsection 1</a></li>
<li><a href="2-11-using-git-and-gitlab-to-implement-version-control.html#subsection-2-6"><span class="toc-section-number">2.11.2</span> Subsection 2</a></li>
<li><a href="2-11-using-git-and-gitlab-to-implement-version-control.html#applied-exercise-3"><span class="toc-section-number">2.11.3</span> Applied exercise</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="3-experimental-data-preprocessing.html#experimental-data-preprocessing"><span class="toc-section-number">3</span> Experimental Data Preprocessing</a><ul>
<li class="has-sub"><a href="3-1-principles-and-benefits-of-scripted-pre-processing-of-experimental-data.html#principles-and-benefits-of-scripted-pre-processing-of-experimental-data"><span class="toc-section-number">3.1</span> Principles and benefits of scripted pre-processing of experimental data</a><ul>
<li><a href="3-1-principles-and-benefits-of-scripted-pre-processing-of-experimental-data.html#subsection-1-8"><span class="toc-section-number">3.1.1</span> Subsection 1</a></li>
<li><a href="3-1-principles-and-benefits-of-scripted-pre-processing-of-experimental-data.html#subsection-2-7"><span class="toc-section-number">3.1.2</span> Subsection 2</a></li>
<li><a href="3-1-principles-and-benefits-of-scripted-pre-processing-of-experimental-data.html#discussion-questions-5"><span class="toc-section-number">3.1.3</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="3-2-introduction-to-scripted-data-pre-processing-in-r.html#introduction-to-scripted-data-pre-processing-in-r"><span class="toc-section-number">3.2</span> Introduction to scripted data pre-processing in R</a><ul>
<li><a href="3-2-introduction-to-scripted-data-pre-processing-in-r.html#subsection-1-9"><span class="toc-section-number">3.2.1</span> Subsection 1</a></li>
<li><a href="3-2-introduction-to-scripted-data-pre-processing-in-r.html#subsection-2-8"><span class="toc-section-number">3.2.2</span> Subsection 2</a></li>
<li><a href="3-2-introduction-to-scripted-data-pre-processing-in-r.html#applied-exercise-4"><span class="toc-section-number">3.2.3</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="3-3-simplify-scripted-pre-processing-through-rs-tidyverse-tools.html#simplify-scripted-pre-processing-through-rs-tidyverse-tools"><span class="toc-section-number">3.3</span> Simplify scripted pre-processing through R’s ‘tidyverse’ tools</a><ul>
<li><a href="3-3-simplify-scripted-pre-processing-through-rs-tidyverse-tools.html#subsection-1-10"><span class="toc-section-number">3.3.1</span> Subsection 1</a></li>
<li><a href="3-3-simplify-scripted-pre-processing-through-rs-tidyverse-tools.html#subsection-2-9"><span class="toc-section-number">3.3.2</span> Subsection 2</a></li>
<li><a href="3-3-simplify-scripted-pre-processing-through-rs-tidyverse-tools.html#practice-quiz-2"><span class="toc-section-number">3.3.3</span> Practice quiz</a></li>
</ul></li>
<li class="has-sub"><a href="3-4-complex-data-types-in-experimental-data-pre-processing.html#complex-data-types-in-experimental-data-pre-processing"><span class="toc-section-number">3.4</span> Complex data types in experimental data pre-processing</a><ul>
<li><a href="3-4-complex-data-types-in-experimental-data-pre-processing.html#subsection-1-11"><span class="toc-section-number">3.4.1</span> Subsection 1</a></li>
<li><a href="3-4-complex-data-types-in-experimental-data-pre-processing.html#subsection-2-10"><span class="toc-section-number">3.4.2</span> Subsection 2</a></li>
<li><a href="3-4-complex-data-types-in-experimental-data-pre-processing.html#practice-quiz-3"><span class="toc-section-number">3.4.3</span> Practice quiz</a></li>
</ul></li>
<li class="has-sub"><a href="3-5-complex-data-types-in-r-and-bioconductor.html#complex-data-types-in-r-and-bioconductor"><span class="toc-section-number">3.5</span> Complex data types in R and Bioconductor</a><ul>
<li><a href="3-5-complex-data-types-in-r-and-bioconductor.html#subsection-1-12"><span class="toc-section-number">3.5.1</span> Subsection 1</a></li>
<li><a href="3-5-complex-data-types-in-r-and-bioconductor.html#subsection-2-11"><span class="toc-section-number">3.5.2</span> Subsection 2</a></li>
<li><a href="3-5-complex-data-types-in-r-and-bioconductor.html#applied-exercise-5"><span class="toc-section-number">3.5.3</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="3-6-example-converting-from-complex-to-tidy-data-formats.html#example-converting-from-complex-to-tidy-data-formats"><span class="toc-section-number">3.6</span> Example: Converting from complex to ‘tidy’ data formats</a><ul>
<li><a href="3-6-example-converting-from-complex-to-tidy-data-formats.html#subsection-1-13"><span class="toc-section-number">3.6.1</span> Subsection 1</a></li>
<li><a href="3-6-example-converting-from-complex-to-tidy-data-formats.html#subsection-2-12"><span class="toc-section-number">3.6.2</span> Subsection 2</a></li>
<li><a href="3-6-example-converting-from-complex-to-tidy-data-formats.html#applied-exercise-6"><span class="toc-section-number">3.6.3</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="3-7-introduction-to-reproducible-data-pre-processing-protocols.html#introduction-to-reproducible-data-pre-processing-protocols"><span class="toc-section-number">3.7</span> Introduction to reproducible data pre-processing protocols</a><ul>
<li><a href="3-7-introduction-to-reproducible-data-pre-processing-protocols.html#subsection-1-14"><span class="toc-section-number">3.7.1</span> Subsection 1</a></li>
<li><a href="3-7-introduction-to-reproducible-data-pre-processing-protocols.html#subsection-2-13"><span class="toc-section-number">3.7.2</span> Subsection 2</a></li>
<li><a href="3-7-introduction-to-reproducible-data-pre-processing-protocols.html#discussion-questions-6"><span class="toc-section-number">3.7.3</span> Discussion questions</a></li>
</ul></li>
<li class="has-sub"><a href="3-8-rmarkdown-for-creating-reproducible-data-pre-processing-protocols.html#rmarkdown-for-creating-reproducible-data-pre-processing-protocols"><span class="toc-section-number">3.8</span> RMarkdown for creating reproducible data pre-processing protocols</a><ul>
<li><a href="3-8-rmarkdown-for-creating-reproducible-data-pre-processing-protocols.html#subsection-1-15"><span class="toc-section-number">3.8.1</span> Subsection 1</a></li>
<li><a href="3-8-rmarkdown-for-creating-reproducible-data-pre-processing-protocols.html#subsection-2-14"><span class="toc-section-number">3.8.2</span> Subsection 2</a></li>
<li><a href="3-8-rmarkdown-for-creating-reproducible-data-pre-processing-protocols.html#applied-exercise-7"><span class="toc-section-number">3.8.3</span> Applied exercise</a></li>
</ul></li>
<li class="has-sub"><a href="3-9-example-creating-a-reproducible-data-pre-processing-protocol.html#example-creating-a-reproducible-data-pre-processing-protocol"><span class="toc-section-number">3.9</span> Example: Creating a reproducible data pre-processing protocol</a><ul>
<li><a href="3-9-example-creating-a-reproducible-data-pre-processing-protocol.html#subsection-1-16"><span class="toc-section-number">3.9.1</span> Subsection 1</a></li>
<li><a href="3-9-example-creating-a-reproducible-data-pre-processing-protocol.html#subsection-2-15"><span class="toc-section-number">3.9.2</span> Subsection 2</a></li>
<li><a href="3-9-example-creating-a-reproducible-data-pre-processing-protocol.html#practice-quiz-4"><span class="toc-section-number">3.9.3</span> Practice quiz</a></li>
</ul></li>
</ul></li>
<li><a href="4-references.html#references"><span class="toc-section-number">4</span> References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="the-tidy-data-format" class="section level2">
<h2><span class="header-section-number">2.3</span> The ‘tidy’ data format</h2>
<p>The “tidy” data format is an implementation of a structured data format popular
among statisticians and data scientists. By consistently using this data format,
researchers can combine simple, generalizable tools to perform complex tasks in
data processing, analysis, and visualization. We will explain what
characteristics determine if a dataset is “tidy” and how use of the “tidy”
implementation of a structure data format can improve the ease and efficiency of
“Team Science”.</p>
<p><strong>Objectives.</strong> After this module, the trainee will be able to:</p>
<ul>
<li>List characteristics defining the “tidy” structured data format</li>
<li>Explain the difference between the a structured data format (general concept)
and the ‘tidy’ data format (one popular implementation)</li>
</ul>
<p>In the previous module, we explained the benefits of saving data in a structured
format, and in particular using a two-dimensional format saved to a plain text
file when possible. In this section, we’ll talk about the “tidy text” format—a
set of principles to use when structuring two-dimensional tabular data. These
principles cover some basic rules for ordering the data, and the resulting datasets
can be very easily worked with, including to clean, model, and visualize the
data, using a series of open-source tools on the R platform called the “tidyverse”.
These characteristics mean that, if you are planning to use a standardized data
format for recording experimental data in your research group, you may want to
consider creating on that adheres to the “tidy data” rules.</p>
<p>To explain more simply, it is usually very little work to record data in a structure
that follows the “tidy data” principles, especially if you are planning to record
the data in a two-dimensional, tabular format already, and following these
principles can bring some big advantages. We explain these rules and provide
examples of biomedical datasets that both comply and don’t comply with these
principles, to help make it clearer how you could structure a “tidy-compliant”
structure for recording experimental data for your own research.</p>
<p>Since a key advantage of the “tidy data” format is that it works so well with
R’s “tidyverse” tools, we’ll also talk a bit in this section about the use of
scripting languages like R, and how using them to analyze and visualize the
data you collect can improve the overall reproducibility of your research.</p>
<p>The principles of “tidy data” were explained in a paper in [x] by [x]. The word
“tidy” was used because … . It is not meant to apply that other formats are
“dirty”, or that they include data that is incorrect or subpar. In fact, the
same set of datapoints could be saved in a file in a way that is either “tidy”
(in the sense of [paper] or untidy, depending only on how the data are organized
across columns and rows.</p>
<p>If the data is the same regardless of whether it’s “tidy” or not, then why all
the fuss about following the “tidy” principles when you’re designing the format
you’ll use to record your data? The magic here in this—if you follow these
principles, then your data can be immediately input into a collection of powerful
tools for visualizing and analyzing the data, without further cleaning steps.
What’s more, all those tools (the set of tools is calld the “tidyverse”) will
typically <em>output</em> your data in a “tidy” format, as well.</p>
<p>Once you have tools that input and output data in the same way, it becomes very
easy to model each of the tools as “small, sharp tools”—each one does one
thing, and does it really well. That’s because, if each tool needs the same
type of input and creates that same type of output, those tools can be chained
together to solve complex problems. The alternative is to create large software
tools, ones that do a lot to the input data before giving you some output.
“Big” tools are harder to understand, and more importantly, they make it hard
to adapt your own solutions, and to go beyond the analysis or visualization that
the original tool creators were thinking of when they created it. Think of it this
way—if you were writing an essay, how much more can you say when you can mix and
match words to create your own sentences versus if you were made to combine
pre-set sentences?</p>
<p>These small tools can be combined together because they take the same input
(data in a “tidy” format) and they output in the same format (also data in a
“tidy” format). This is such a powerful idea that many of the best loved toys
work on the same principle. Think of interlocking plastic block sets, like Lego.
You can create almost anything with a large enough set of Legos, because they
can be combined in almost any kind of way. Why? Because they all follow a
standard size for the … on top of each block, and they all “input” … of that
same size on the bottom of the block. That means they can be joined together in
any order and combination, and as a result very complex structures can be
created. It also means that each piece can be small and easy to understand—if
you’re building a Lego structure, even something very fancy, you’ll probably use
lots of rectangular brinks that are two … across and four … long, and that’s
easy enough to describe that you could probably get a young child to help you
find those pieces when you need them.</p>
<p>We’ll next describe what rules a dataset’s format must follow for it to be
“tidy”, and try to clarify how you can set up your data recording to follow
these rules. In a later part of this module, we’ll talk more about the tidyverse
tools that you can use with this data, as well as give some resources for
finding out more about the tidyverse and how to use its tools.</p>
<p>First, to be “tidy”, a dataset must be tabular and two-dimensional, a structured
data format described in the previous module. It should not be saved in a
hierarchical structure, like XML (although there are now tools for converting
data from XML to a “tidy” format, so you may still be able to take advantage of
the tidyverse even if you must use XML for your data recording).</p>
<div id="the-tidy-data-format-1" class="section level3">
<h3><span class="header-section-number">2.3.1</span> The “tidy” data format</h3>
<blockquote>
<p>“Software systems are transparent when they don’t have murky corners or hidden
depths. Transparency is a passive quality. A program is passive when it is possible
to form a simple mental model of its behavior that is actuaally predictive for all
or most cases, because you can see through the machinery to what is actually going
on.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Software systems are discoverable when they include features that are designed
to help you build in your mind a correct mental model of what they do and how they
work. So, for example, good documentation helps discoverability to a programmer. Discoverability
is an active quality. To achieve it in your software, you cannot merely fail to be obscure,
you have to go out of your way to be helpful.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Elegant code does much with little. Elegant code is not only correct but visibly,
<em>transparently</em> correct. It does not merely communicate an algorithm to a computer,
but also conveys insight and assurance to the mind of a human that reads it. By seeking
elegance in our code, we build better code. Learning to write transparent code is a first,
long step toward learning how to write elegant code—and taking care to make code
discoverable helps us learn how to make it transparent. Elegant code is both transparent and
discoverable.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“To design for transparency and discoverability, you need to apply every tactic for
keeping your code simple, and also concentrate on the ways in which your code is a
communication to other human beings. The first questions to ask, after ‘Will this design
work?’ are ‘Will it be reaadable to other people? Is it elegant?’ We hope it is clear …
that these questions are not fluff and that elegance is not a luxury. These qualities
in the human reaction to software are essential for reducing its bugginess and
increasing its long-term maintainability.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“The Unix style of design applies the do-one-thing-well approach at the level of
cooperating programs as well as cooperating routines within a program,
emphasizing small programs connected by well-defined interprocess communication
or by shared files. Accordingly, the Unix operating system encourages us to break our
programs down into simple subprocesses, and to concentrate on the interfaces between
these subprocesses.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“The ability to combine programs [with piping] can be extremely useful. But the real
win here is not cute combinations; it’s that because both pipes and <em>more(1)</em> exist,
<em>other programs can be simpler</em>. Pipes mean that programs like <em>ls(1)</em> (and other
programs that write to standard out) don’t have to grow their own pagers—and we’re
saved from a word of a thousand built-in pagers (each, naturally, with its own divergent
look and feel). Code bloat is avoided and global complexity reduced. As a bonus, if
anyone needs to customize pager behavior, it can be done in <em>one</em> place, by changing
<em>one</em> program. Indeed, multiple pagers can exist, and will all be useful with every application
that writes to standard output.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Unix was born in 1969 and has been in continuous production use ever since. That’s several
geological eras by computer industry standards. … Unix’s durability and adaptability have
been nothing short of astonishing. Other technologies have come and gone like mayflies.
Machines have increased a thousand-fold in power, languages have mutated, industry practice
has gone through multiple revolutions—and Unix hangs in there, still producing, still paying
the bills, and still commanding loyalty from many of the best and brightest software technologists
on the planet.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“One of the many consequences of the exponential power-versus-time curve in computing, and the
corresponding pace of software development, is that 50% of what one knows becomes obsolete over
every 18 months. Unix does not abolish this phenomenon, but does do a good job of containing it.
There’s a bedrock of unchanging basics—languages, system calls, and tool invocations—that one
can actually keep for entire years, even decades. Elsewhere it is impossible to predict what will
be stable; even entire operating systems cycle out of use. Under Unix, there is a fairly sharp
distinction between transient knowledge and lasting knowledge, and one can know ahead of time
(with about 90% certainty) which category something is likely to fall in when one learns it. Thus
the loyalty Unix commands.” <span class="citation">(Raymond 2003)</span></p>
</blockquote>
<blockquote>
<p>“Unix is famous for being designed around the philosophy of small, sharp tools, each
intended to do one thing well. This philosophy is enabled by using a common underlying
format—the line-oriented, plain text file. Databases used for system administration
(users and passwords, network configuration, and so on) are all kept as plain
text files. … When a system crashes, you may be faced with only a minimal
environment to restore it (you may not be able to access graphics drivers,
for instance). Situations such as this can really make you appreciate the simplicity of
plain text.” <span class="citation">(Hunt, Thomas, and Cunningham 2000)</span></p>
</blockquote>
<blockquote>
<p>“Unix is the foundational computing environment in bioinformatics because its
design is the antithesis of [a] inflexible and fragile approach. The Unix shell
was designed to allow users to easily build complex programs by interfacing
smaller modular programs together. This approach is the Unix philosophy:
‘This is the Unix philosophy: Write programs that do one thing and do it well.
Write programs to work together. Write programs to handle text streams, because
that is a universal interface.’–Doug McIlory”. <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
<blockquote>
<p>“Passing the output of one program directly into the input of another
program with pipes is a computationally efficient and simple way to interface
Unix programs. This is another reason why bioinformaticians (and software engineers
in general) like Unix. Pipes allow us to build larger, more complex tools from
modular parts. It doesn’t matter what language a program is written in, either; pipes
will work between anything as long as both programs understand the data passed
between them. As the lowest common denominator between most programs, plain-text
streams are often used—a point that McIlroy makes in his quote about the
Unix philosophy.” <span class="citation">(Buffalo 2015)</span></p>
</blockquote>
</div>
<div id="what-makes-data-tidy" class="section level3">
<h3><span class="header-section-number">2.3.2</span> What makes data “tidy”?</h3>
<p>The “tidy” data format describes one way to structure tabular data. If you have
data in a structured, tabular format that doesn’t follow these rules, you don’t
need to consider it “dirty”, though—just think of “tidy” as the tagname for
this particular structure of data (the name, in this case, connects the data
format with a set of tools in R called the “tidyverse”). The name follows from
the focus of this data format and its associated set of tools—the
“tidyverse”—on preparing and cleaning (“tidying”) data, in contrast to sets of
tools more focused on other steps, like data analysis [Tidy data].</p>
<blockquote>
<p>“The development of tidy data has been driven by my experience from working
with real-world datasets. With few, if any, constraints on their organization,
such datasets are often constructed in bizarre ways. I have spent countless
hours struggling to get such datasets organized in a way that makes data
analysis possible, let alone easy.” [Tidy data]</p>
</blockquote>
<p>The rules for making data “tidy” are pretty simple, and they are defined in
detail, and with extended examples, in the journal article that originally
defined the data format [Tidy data]. Here, we’ll go through those rules, with
the hope that you’ll be able to understand what makes a dataset follow the
“tidy” data format. If so, you’ll be able to set up your data recording
template to follow this template, and you’ll be able to tell if other data you
get is in this format and, if it’s not, restructure it so that it does. In
the next part of this module, we’ll explain why it’s so useful to have your
data in this format.</p>
<p>Tidy data, first, must be in a tabular (i.e., two-dimensional, with columns and
rows, and with all rows and columns of the same length—nothing “ragged”). If
you recorded data in a spreadsheet using a very basic strategy of saving a
single table per spreadsheet, with the first row giving the column names (as
described in the previous module), then your data will be in a tabular format.
In general, if your recorded data looks “boxy”, it’s probably in a
two-dimensional tabular format.</p>
<p>There are some additional criteria for the “tidy” data format, though, and so
not every structured, tabular dataset is in a “tidy” format. The first of these
rules are that each row of a “tidy” dataset records the values for a single
observation, and that each column provides characteristics or measurements of a
certain type, in the order of the observations given by the rows [Tidy data].</p>
<blockquote>
<p>“Most statistical datasets are rectangular tables made up of rows and columns
… [but] there are many ways to structure the same underlying data. …
Real datasets can, and often do, violate the three precepts of tidy data in
almost every way imaginable.” [Tidy data]</p>
</blockquote>
<p>To be able to decide if your data is tidy, then, you need to know what forms a
single observation in data you’re collecting. The <em>unit of observation</em> of a
dataset is the unit at which you take measurements [Sedgewick 2014 Unit]. This
idea is different than the <em>unit of analysis</em>, which is the unit that you’re
focusing on in your study hypotheses and conclusions (this is sometimes also
called the “sampling unit” or “unit of investigation”) [Altman and Bland]. In
some cases, these two might be equivalent (the same unit is both the unit of
observation and the unit of measurement), but often they are not [Sedgewick 2014
Unit].</p>
<blockquote>
<p>“The unit of observation and unit of analysis are often confused.
The unit of observation, sometimes referred to as the unit of
measurement, is defined statistically as the ‘who’ or ‘what’
for which data are measured or collected. The unit of analysis
is defined statistically as the ‘who’ or ‘what’ for which
information is analysed and conclusions are made.” [Sedgewick 2014 Unit]</p>
</blockquote>
<p>For example, say you are testing how the immune system of mice responds to a
certain drug over time. You may have several replicates of mice measured at
several time points, and those mice might be in separate groups (for example,
infected with a disease versus uninfected). In this case, if a separate mouse
(replicate) is used to collect each observation, and a mouse is never measured
twice (i.e., at different time points, or for a different infection status),
then the unit of measurement is the mouse. There should be one and only one row
in your dataset for each mouse, and that row should include two types of
information: first, information about the unit being measured (e.g., the time
point, whether the mouse was infected, and a unique mouse identifier) and,
second, the results of that measurement (e.g., the weight of the mouse when it
was sacrificed, the levels of different immune cell populations in the mouse, a
measure of the extent of infection in the mouse if it was infected, and perhaps
some notes about anything of note for the mouse, like if it appeared noticably
sick). In this case, the <em>unit of analysis</em> might be the drug, or a combination
of drug and dose—ultimately, you may want to test something like if one
drug is more effective than another. However, the <em>unit of observation</em>, the
level at which each data point is collected, is the mouse, with each mouse
providing a single observation to help answer the larger research question.</p>
<p>As another example, say you conducted a trial on human subjects, to see how the
use of a certain treatment affects the speed of recovery, where each study
subject was measured at different time points. In this case, the unit of
observation is the combination of study subject and time point (while the unit
of analysis is the study subject, if the treatments are randomized to the study
subjects). That means that Subject 1’s measurement at Time 1 would be one
observation, and the same person’s measurement at Time 2 would be a separate
observation. For a dataset to comply with the “tidy” data format, these two
observations would need to be recorded on separate lines in the data. If the
data instead had different columns to record each study subject’s measurements
at different time points, then the data would still be tabular, but it would not
be “tidy”.</p>
<p>In this second example, you may initially find the “tidy” format unappealing,
because it seems like it would lead to a lot of repeated data. For example, if
you wanted to record each study subject’s sex, it seems like the “tidy” format
would require you to repeat that information in each separate line of data
that’s used to record the measurements for that subject for different time
points. This isn’t the case—instead, with a “tidy” data format, different
“levels” of data observations should be recorded in separate tables [Tidy data].
So, if you have some data on each study subject that does not change across the
time points of the study—like the subject’s ID, sex, and age at
enrollment—those form a separate dataset, one where the unit of observation is
the study subject, so there should be just one row of data per study subject in
that data table, while the measurements for each time point should be recorded
in a separate data table. A unique identifier, like a subject ID, should be
recorded in each data table so it can be used to link the data in the two
tables. If you are using a spreadsheet to record data, this would mean that the
data for these separate levels of observation should be recorded in separate
sheets, and not on the same sheet of a spreadsheet file. Once you read the data
into a scripting language like R or Python, it will be easy to link the larger
and smaller “tidy” datasets as needed for analysis, visualizations, and reports.</p>
<p>Once you have divided your data into separate datasets based on the level of
observation, and structured each row to record data for a single observation
based on the unit of observation within that dataset, each column should be used
to measure a separate characteristic or measurement (a <em>variable</em>) for each
measurment [Tidy data]. A column could either give characteristics of the data
that were pre-defined by the study design—for example, the treatment assigned
to a mouse, or the time point at which a measurement was taken if the study
design defined the time points when measurements would be taken. These types of
column values are also sometimes called <em>fixed variables</em> [Tidy data]. Other
columns will record observed measurements—values that were not set prior to
the experiment. These might include values like the level of infection measured
in an animal and are sometimes called <em>measured variables</em> [Tidy data].</p>
<blockquote>
<p>“While the order of variables and observations does not affect analysis, a
good ordering makes it easier to scan the raw values. One way of organizing
variables is by their role in the analysis: are values fixed by the design of
the data collection, or are they measured during the course of the experiment?
Fixed variables describe the experimental design and are known in advance.
… Measured variables are what we actually measure in the study. Fixed
variables should come first, followed by measured variables, each ordered so
that related variables are contiguous. Rows can then be ordered by the first
variable, breaking ties with the second and subsequent (fixed) variables.” [Tidy
data]</p>
</blockquote>
</div>
<div id="why-make-your-data-tidy" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Why make your data “tidy”?</h3>
<p>This may all seem like a lot of extra work, to make a dataset “tidy”, and why
bother if you already have it in a structured, tabular format? It turns out
that, once you get the hang of what gives data a “tidy” format, it’s pretty
simple to design recording formats that comply with these rules. What’s more,
when data is in a “tidy” format, it can be directly input into a collection
of tools in R that belong to something called the “tidyverse”. This collection
of tools is very straightforward to use and so powerful that it’s well worth
making an effort to record data in a format that works directly with the
tools, if possible. Outside of cases of very complex or very large data, it
should be possible.</p>
<blockquote>
<p>“A standard makes initial data cleaning easier because you do not need to
start from scratch and reinvent the wheel every time. The tidy data standard has
been designed to facilitate initial exploration and analysis of the data, and to
simplify the development of data analysis tools that work well together.” [Tidy
data]</p>
</blockquote>
<blockquote>
<p>“Tidy data is great for a huge fraction of data analyses you might
be interested in. It makes organizing, developing, and sharing data a lot
easier. It’s how I recommend most people share data.” [Toward tidy analysis]</p>
</blockquote>
<p>The “tidyverse” is a collection of tools united by a common philosophy: <strong>very
complex things can be done simply and efficiently with small, sharp tools
that share a common interface</strong>.</p>
<blockquote>
<p>“The philosophy of the tidyverse is similar to
and inspired by the “unix philosophy”, a set of loose principles that ensure
most command line tools play well together. … Each function should solve one
small and well-defined class of problems. To solve more complex problems, you
combine simple pieces in a standard way." [Declutter]</p>
</blockquote>
<p>The tidyverse isn’t the only popular system that follows this philosophy—one
other favorite is Legos. Legos are small, plastic bricks, with small studs on
top and tubes for the studs to fit into on the bottom. The studs all have the
same, standardized size and are all spaced the same distance apart. Therefore,
the bricks can be joined together in any combination, since each brick uses the
same <em>input format</em> (studs of the standard size and spaced at the standard
distance fit into the tubes on the bottom of the brick) and the same <em>output
format</em> (again, studs of the standard size and spaced at the standard distance
at the top of the brick).</p>
<p>This is true if you want to build with bricks of different colors or different
heights or different widths or depths. It even allows you to include bricks at
certain spots that either don’t require input (for example, a solid sheet that
serves as the base) or that don’t give output (for example, the round smooth
bricks with painted “eyes” that are used to create different creatures). With
Legos, even though each “tool” (brick) is very simple, the tools can be combined
in infinite variations to create very complex structures.</p>
<div class="figure"><span id="fig:legoshark"></span>
<p class="caption marginnote shownote">
Figure 1.2: When simple tools have a common interface that allows them to be combined in different ways, like Legos, they can be combined to create complex structures, like this Lego shark.
</p>
<img src="figures/legoshark.jpg" alt="When simple tools have a common interface that allows them to be combined in different ways, like Legos, they can be combined to create complex structures, like this Lego shark." width="\textwidth"  />
</div>
<p>The tools in the “tidyverse” operate on a similar principle. They all input one
of a few very straightforward data types, and they (almost) all output data in
the same format they input it. For most of the tools, their required format for
input and output is the “tidy data” format [Tidy data], called a tidy
<em>dataframe</em> in R—this is a dataframe that follows the rules detailed earlier
in this section.</p>
<p>Some of the tools require input and output of <em>vectors</em> instead of tidy
dataframes [Tidy data]; a <em>vector</em> in R is a one-dimensional string of values,
all of which are of the same data type (e.g., all numbers, or all character
strings, like names). In a tidy dataframe, each column is a vector, and the
dataframe is essentially several vectors of the same length stuck together to
make a table. Having functions that input and output vectors, then, means that
you can use those functions to make changes to the columns in a tidy dataframe.</p>
<p>A few functions in the “tidyverse” input a tidy dataframe but output data in a
different format. For example, visualizations are created using a function
called <code>ggplot</code>, as well as its helper functions and extensions. This function
inputs data in a tidy dataframe but outputs it in a type of R object called a
“ggplot object”. This object encodes the plot the code created, so in this case
the fact that the output is in a different format from the endpoint is similar
to with the “eye” blocks in Legos, where it’s meant as a final output step, and
you don’t intend to do anything further in the code once you move into that
step.</p>
<p>This common input / output interface, and the use of small tools that follow
this interface and can be combined in various ways, is what makes the tidyverse
tools so powerful. However, there are other good things about the tidyverse that
make it so popular. One is that it’s fairly easy to learn to use the tools, in
comparison to learning how to write code for other R tools [Teach the tidyverse;
Teaching R to new users]. The developers who have created the tidyverse tools
have taken a lot of effort to try to make sure that they have a clear and
consistent <em>user interface</em> across tools [Tidy tools manifesto; Three ring
circus]. So far, we’ve talked about the interface between functions, and how a
common <em>input / output interface</em> means the functions can be chained together
more easily. But there’s another interface that’s important for software tools:
the rules for how a computer users employ that tool, or the <em>user interface</em>.</p>
<p>To help understand a user interface, and how having a consistent user interface
across tools is useful, let’s think about a different example—cars. When you
drive a car, you get the car to do what you want through the steering wheel, the
gas pedal, the break pedal, and different knobs and buttons on the dashboard.
When the car needs to give you feedback, it uses different gauges on the
dashboard, like the speedometer, as well as warning lights and sounds.
Collectively, these ways of interacting with your car make up the car’s <em>user
interface</em>. In the same way, each function in a programming language has a
collection of parameters you can set, which let you customize the way the
function runs, as well as a way of providing you output once the function has
finished running and the way to provide any messages or warnings about the
function’s run. For functions, the software developer can usually choose design
elements for the function’s user interface, including which parameters to
include for the function, what to name those parameters, and how to provide
feedback to the user through messages, warnings, and the final output.</p>
<p>If a collection of tools is similar in its user interfaces, it will make it
easier for users to learn and use any of the tools in that collection once
they’ve learned how to use one. For cars, this explains how the rental car
business is able to succeed. Even though different car models are very different
in many characteristics—their engines, their colors, their software—they are
very consistent in their user interfaces. Once you’ve learned how to drive one
car, when you get in a new car, the gas pedal, brake, and steering wheel are
almost guaranteed to be in about the same place and to operate about the same
way as in the car you learned to drive in. The exceptions are rare enough to be
memorable—think how manyu movies have a laughline from a character trying to
drive a car with the driver side on the right if they’re used to the left or
vice versa.</p>
<p>The tidyverse tools are similarly designed so that they all have a very similar
user interface. For example …<br />
What’s more, the functions are typically given
names that very clearly describe the action that the function does, like
<code>filter</code>, <code>summarize</code>, <code>mutate</code>, and <code>group</code>. As a result, the final code is
very clear and can almost be “read” as a natural language, rather than code.</p>
<blockquote>
<p>“Another part of what makes the Tidyverse effective is harder to see and,
indeed, the goal is for it to become invisible: conventions. The Tidyverse
philosophy is to rigorously (and ruthlessly) identify and obey common
conventions. This applies to the objects passed from one function to another
and to the user interface each function presents. Taken in isolation, each
instance of this seems small and unimportant. But collectively, it creates
a cohesive system: having learned one component you are more likely to be
able to guess how another different component works.” [Three ring circus]</p>
</blockquote>
<blockquote>
<p>“The goal of [the tidy tools] principles is to provide a uniform interface so
that tidyverse packages work together naturally, and once you’ve mastered one,
you have a head start on mastering the others.” [Tidy tools manifesto]</p>
</blockquote>
<p>As a result, the tidyverse collection of tools is pretty easy to learn, compared
to other sets of functions in scripting languages, and pretty easy to expand
your knowledge of once you know some of its functions. Several people who teach
R programming now focus on first teaching the tidyverse, given these
characteristics [Teach the tidyverse; Teaching R to New Users], and it’s often a
first focus for online courses and workshops on R programming. Since it’s main
data structure is the “tidy data” structure, it’s often well worth recording
data in this format so that all these tools can easily be used to explore and
model the data.</p>
<blockquote>
<p>“All our code is underpinned by the principles of tidy data, the
grammar of data manipulation, and the tidyverse R packages developed
by Wickham. This deliberate philosophy for thinking
about data helped bridge our scientific questions with the data processing
required to get there, and the readability and conciseness of
tidyverse operations makes our data analysis read more as a story
arc. Operations require less syntax—which can mean fewer potential
errors that are easier to identify—and they can be chained together,
minimizing intermediate steps and data objects that can cause clutter and
confusion. The tidyverse tools for wrangling data have
expedited our transformation as coders and made R less intimidating to
learn.” [Our path to better science]</p>
</blockquote>
</div>
<div id="using-tidyverse-tools-with-data-in-the-tidy-data-format" class="section level3">
<h3><span class="header-section-number">2.3.4</span> Using tidyverse tools with data in the “tidy data” format</h3>
<p>The tidyverse includes tools for many of the tasks you might need to
do while managing and working with experimental data. When you download
R, you get what’s called <em>base R</em>. This includes the main code that drives
anything you do in R, as well as functions for doing many core tasks.
However, the power of R is that, in addition to base R, you can also add
onto R through what are called <em>packages</em> (sometimes also referred to
as <em>extensions</em> or <em>libraries</em>). These are kind of like “booster packs”
that add on new functions for R. They can be created and contributed
by anyone, and many are collected through a few key repositories like
CRAN and Bioconductor.</p>
<p>All the tidyverse tools are included in R extension packages, rather than base
R, so once you download R, you’ll need to download these packages as well to use
the tidyverse tools. The core tidyverse functions include functions to read in
data (the <code>readr</code> package for reading in plain text, delimited files, <code>readxl</code>
[?] to read in data from Excel spreadsheets), clean or summarize the data (the
<code>dplyr</code> package, which includes functions to merge different datasets [?], make
new columns as functions of old ones, and summarize columns in the data, either
as a whole or by group), and reformat the data if needed to get it in a tidy
format (the <code>tidyr</code> package). The tidyverse also includes more precise tools,
including tools to parse dates and times (<code>lubridate</code>) and tools to work with
character strings, including using regular expressions as a powerful way to find
and use certain patterns in strings (<code>stringr</code>). Finally, the tidyverse
includes powerful functions for visualizing data, based around the <code>ggplot2</code>
package, which implements a “grammar of graphics” within R. You can install and
load any of these tidyverse packages one-by-one using the <code>install.packages</code> and
<code>library</code> functions with the package name from within R. If you are planning on
using many of the tidyverse packages, you can also install and load many of the
tidyverse functions by installing a package called “tidyverse”, which serves as
an umbrella for many of the tidyverse packages.</p>
<p>In addition to the original tools in the tidyverse, many people have developed
<em>tidyverse</em> extensions—R packages that build off the tools and principles in
the tidyverse. These often bring the tidyverse conventions into tools for
specific areas of science. For example, the <code>tidytext</code> package provides tools to
analyze large datasets of text, including books or collections of tweets, using
the tidy data format and tidyverse-style tools. Similar tidyverse extensions
exist for working with network data ([package?]) or geospatial data (<code>sf</code>).
Extensions also exist for the visualization branch of the tidyverse
specifically. These include <em>ggplot extensions</em> that allow users to create
things like calendar plots and … [mouse plots?] These extensions all allow
users to work with data that’s in a “tidy data” format, and they all provide
similar user interfaces, making it easier to learn a large set of tools to do a
range of data analysis and visualization, compared to if the set of tools lacked
this coherence.</p>
</div>
<div id="practice-quiz" class="section level3">
<h3><span class="header-section-number">2.3.5</span> Practice quiz</h3>

</div>
</div>
<p style="text-align: center;">
<a href="2-2-principles-and-power-of-structured-data-formats.html"><button class="btn btn-default">Previous</button></a>
<a href="2-4-designing-templates-for-tidy-data-collection.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
