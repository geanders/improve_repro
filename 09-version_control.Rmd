## Harnessing version control for transparent data recording

As a research project progresses, a typical practice in many experimental
research groups is to save new versions of files (e.g., 'draft1.doc',
'draft2.doc'), so that changes can be reverted. However, this practice leads to
an explosion of files, and it becomes hard to track which files represent the
'current' state of a project. Version control allows researchers to edit and
change research project files more cleanly, while maintaining the power to
'backtrack' to previous versions, messages included to explain changes. We will
explain what version control is and how it can be used in research projects to
improve the transparency and reproducibility of research, particularly for data
recording.

**Objectives.** After this module, the trainee will be able to:

- Describe version control  
- Explain how version control can be used to improve reproducibility 
for data recording

### What is version control?

Version control developed as a way to coordinate collaborative work on 
software programming projects. The term "version" here refers to the current
state of a document or set of documents, for example the source code for a
computer program. The idea of "control" is to allow for safe changes and updates
to this version while more than one person is working on it. 
The general term "version control" can refer to any method of
syncing contributions from several people to a file or set of files, and
very early on it was done by people rather than through a computer program. 
Some software developers have shared their memories of taking their
code to the "Source Control" team, who then integrated it into the main
source code file by hand [@irving2011astonishments]. 

As the proverb about too many cooks in the kitchen captures, any time you have
multiple people working on a project, it introduces the chance for conflicts. 
While higher-level conflicts, like about what you want the final product to 
look like or who should do which jobs, can't be easily managed by a computer
program, now the complications of integrating everyone's contributions---and letting
people work in their own space and then bring together their individual work
into one final joint project---can be. While these programs for version control
were originally created to help with programmers developing code, they can 
be used now to coordinate group work on numerous types of file-based projects, 
including scientific manuscripts, books, and websites. And although they can 
work with projects that include binary code, they thrive in projects with a 
heavier concentration of text-based files, and so they fit in nicely in a 
scientific research / data analysis workflow that is based on data stored
in plain text formats and data analysis scripts written in plain text files, 
tools we discuss in other parts of this book. 

In early types of version control programs, there was one central "main" 
version of the file or set of files the team was working on. Very early on, 
this was kept on one computer. A team member who wanted to make a change
would "check out" the file he or she wanted to work on, make changes, and 
then check it back in as the newest main version. While one team member had
this file checkout out, other members would often be "locked" out of making
any changes to that file---they could look at it, but couldn't make any edits. 
This meant that there was no chance of two people trying to change the same
part of a file at the same time. In spirit, this early system is pretty similar 
to the idea of sending a file around the team by email, with the understanding
that only one person works on it at a time. While the "main" version is in
different people's hands at different times, to do work, you all agree that only
one person will work on it at a time. A slightly more modern analogy is 
the idea of having a single version of a file in Dropbox or Google Docs, and
avoiding working on the file when you see that another team member is working
on it. (However, both of these examples other key features of version control, 
which we'll discuss a bit later.)

This system is pretty clunky, though. In particular, it probably usually increases
the amount of time that it takes the team to finish the project, because only one
person can work on a file at a time. Later types of version control programs moved
toward a different style, allowing for *distributed* rather than *centralized* 
collaborative work on a file or a set of files. Under the distributed model, all 
team members can have their own version of all the files, work on them and make
records of changes they make to the files, and then occassionally sync with everyone
else to share your changes with them and bring their changes into your copy of the 
files. This idea allowed for the development of other useful features and styles of
working, including *branching* to try out new ideas that you're not sure you'll 
ultimately want to go with and *forking*, a key tool used in open-source software
development, which among other things facilitates someone who isn't part of the 
original team getting a copy of the files they can work with and suggesting some 
changes that might be helpful.

So, this is the basic idea of modern version control---for a project that involves a set
of computer files, everyone on has their own copy of a directory with those files
on their own computer, makes changes at the time and in the spots in the files that
they want, and then regularly re-syncs their local directory with everyone else's
to share changes and updates. 

There is one key feature of modern version control that's
critical to making this work---merging files that started the same but were edited in
different ways and now need to be put back together, bringing any changes made from the
original version. This step is called *merging* the files. While this is typically 
described using the plural, "files", at a higher-level, you can thing of this as 
just merging the *changes* that two people have made as they edited a single file, a
file where they both started out with identical copies. 

Think of the file broken up into each of its separate lines. There will be some lines
that neither person changed. Those are easy to handle in the "merge"---they stay the
same as in the original copy of the file. Next, there will be some lines that one
person changed, but that the other person didn't. It turns out that these are pretty
easy to handle, too. If only one person changed the line, then you use their version---it's
the most up-to-date, since if both people started out with the same version, it means
that the other person didn't make any changes to that part of the file. 
Finally, there may be a few lines that both people changed. These are called *merge conflicts*. 
They're places in the file where there's not a clear, easy-to-automate way that
the computer can know which version to put into the integrated, latest version of the
file. Different version control programs handle these merge conflicts in different ways. 
For the most common version control program used today, *git*, these spots in the 
file are flagged with a special set of symbols when you try to integrate the two updated
versions of the file. Along with the special symbols to denote a conflict, there will 
also be *both* versions of the conflicting lines of the file. Whoever is integrating the 
files must go in and pick the version of those lines to use in the integrated version
of the file, or write in some compromise version of those lines that brings in elements
from both people's changes, and then delete all the symbols denoting that was a conflict
and save this latest version of the file. 

There are a number of other features of version control that make it useful for 
collaborating on file-based projects with teams. First, these systems allow you to 
explain your changes as you make them---in other words, it allows for *annotation*
of the developing and editing process. This provides the team with a full history of
why the files evolved in the way they did across the team. It also provides a way to 
communicate across the team members. For example, if one person is the key person 
working on a certain file, but has run into a problem with one spot and asks another
team member to take a go, then the second team member isn't limited to just looking at
the file and then emailing some suggestions. Instead, the second person can make 
sure he or she has the latest version of that file, make the changes they think will
help, *commit* those changes with a message (a *commit message*) about why they think
this change will fix the problem, and then push that latest version of the file back 
to the first person. If there are several places where it would help to change the file, 
then these can be fixed through several separate commits, each with their own message. 
The first person, who originally asked for help, can read through the updates in the file
(most platforms for using version control will now highlight where all these changes
are in the file) and read the second person's message or messages about why each change
might help. Even better, days or months later, when team members are trying to figure out
why a certain change was made in that part of the file, can go back and read these messages
to get an explanation. 

There's another feature of version control that can be demonstrated through this example. 
Because the changes made to the files in the project are regularly *committed*, with a 
message for each commit and a record of what was changed in that commit, the team members can,
at any point, go back to the *exact* version of the project at any earlier point in time. 
Each of the commits is given its own ID tag ([name for this? hash?]), and *git* has a number
of commands that let you "roll back" to earlier versions, by going back to the version as it
was when a certain commit was made. 

It turns out that this functionality---of being able to "roll back" to earlier versions---has
a wonderful side benefit when it comes to working on a large project. It means that you 
**don't** need to save earlier versions of each file. You can maintain one and only one
version of each project file in the project's directory, with the confidence that you never
"lose" old versions of the file. If you're working on a manuscript, for example, when it's 
time to edit, you can cut whole paragraphs, and if you ever need to get them back, they'll 
be right there in the commit history for your project, with their own commit message about
why they were cut (hopefully a nice clear one that will make it easy to find that commit
if you ever need those paragraphs again).

### Improving scientific research with version control



### How to use version control

While this method of merging two sets of changes to a file generally works very well in 
integrating what members of the team have typed into the file in their edits (i.e., the
actual text), it doesn't do *anything* to check the logic. If that text is computer
code, then the latest version, with code integrated from two people, could be "broken", 
even if each person confirmed that the code worked on their own computers before merging, 
because a change in one spot in code could break something somewhere else in the code. 
One way to try to quickly identify this kind of a problem is to create small pieces of 
code that can be run whenever you'd like to check that your code is still behaving like you
want it to. These pieces of code are called "unit tests". They allow you to define how
you *expect* your code to behave---for example, if you have created a function in your code that
counts the number of letters in a word, you expect it to always give back "5" for "fever"
and "0" for "". You can write a bit of code that runs the function, using inputs of 
"fever" and "", and then tests to see if what it gets in return is "5" and "0". If it does, 
great! You won't hear anything else. If it doesn't though, it will print out a message 
to warn you that one of the functions in your code didn't return what you were expecting
it to. You can collect all of these unit tests in one part of the project directory, and you 
can even set up a "hook" with your version control program to run all of those tests
every time you merge in new changes from team members. If everything still works fine after
merging in new changes, it will be a silent success, but if a merge breaks something, 
you'll get a noisy failure which, while certainly worse that a silent success, is much, 
much better than a silent failure. As Mark Twain (supposedly) said, "What gets us into 
trouble is not what we don't know. It's what we know for sure that just ain't so."

[Odds and ends---.DS_Store, $Word_doc]


### Subsection 1


"Or maybe your goal is that your data is *usable* in a wide range of
applications? If so, consider adopting standard formats and metadata 
standards early on. At the very least, keep track of versions of data
and code, with associated dates." [@goodman2014ten]


**Email attachments in lieu of common access files.**

...

For example, one group of researchers investigated a large collection of emails
from Enron [@hermans2015enron]. They found that passing Excel files through
email attachements was a common practice, and that messages within emails
suggested that spreadsheets were stored locally, rather than in a location that
was accessible to all team members [@hermans2015enron], which meant that team
members might often be working on different versions of the same spreadsheet
file. They note that "the practice of emailing spreadsheets is known to result in 
serious problems in terms of accountability and errors, as people do not have
access to the latest version of a spreadsheet, but need to be updated of changes 
via email." [@hermans2015enron]

"Team members regularly pass data files back and forth by hand, by email, and by
using shared lab or project servers, websites, and databases."
[@edwards2011science]

**Version control for spreadsheets**

"Recent versions of spreadsheets now incorporate a 'Traack Changes' functionality
which enables highlighting of changes made by different users along with a comment
and review system. Such tools are a start toward this but more robust version control
systems are required particularly in the context of increasingly online and 
collaborative method of working where large teams interact with a single document
concurrently." [@birch2018future]

### Subsection 2

### Discussion questions

