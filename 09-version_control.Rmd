## Harnessing version control for transparent data recording

As a research project progresses, a typical practice in many experimental
research groups is to save new versions of files (e.g., 'draft1.doc',
'draft2.doc'), so that changes can be reverted. However, this practice leads to
an explosion of files, and it becomes hard to track which files represent the
'current' state of a project. Version control allows researchers to edit and
change research project files more cleanly, while maintaining the power to
'backtrack' to previous versions, messages included to explain changes. We will
explain what version control is and how it can be used in research projects to
improve the transparency and reproducibility of research, particularly for data
recording.

**Objectives.** After this module, the trainee will be able to:

- Describe version control  
- Explain how version control can be used to improve reproducibility 
for data recording

### What is version control?

Version control developed as a way to coordinate collaborative work on 
software programming projects. The term "version" here refers to the current
state of a document or set of documents, for example the source code for a
computer program. The idea of "control" is to allow for safe changes and updates
to this version while more than one person is working on it. 
The general term "version control" can refer to any method of
syncing contributions from several people to a file or set of files, and
very early on it was done by people rather than through a computer program. 
Some software developers have shared their memories of taking their
code to the "Source Control" team, who then integrated it into the main
source code file by hand [@irving2011astonishments]. 

> "Tracking all that detail is just the sort of thing computers
are good at and humans are not." [@raymond2003art]

As the proverb about too many cooks in the kitchen captures, any time you have
multiple people working on a project, it introduces the chance for conflicts.
While higher-level conflicts, like about what you want the final product to look
like or who should do which jobs, can't be easily managed by a computer program,
now the complications of integrating everyone's contributions---and letting
people work in their own space and then bring together their individual work
into one final joint project---can be. While these programs for version control
were originally created to help with programmers developing code, they can be
used now to coordinate group work on numerous types of file-based projects,
including scientific manuscripts, books, and websites [@raymondunderstanding].
And although they can work with projects that include binary code, they thrive
in projects with a heavier concentration of text-based files, and so they fit in
nicely in a scientific research / data analysis workflow that is based on data
stored in plain text formats and data analysis scripts written in plain text
files, tools we discuss in other parts of this book.

In earlier types of version control programs, there was one central "main"
repository the file or set of files the team was working on
[@raymondunderstanding; @target2018version]. Very early on, this was kept on one
computer [@irving2011astonishments]. A team member who wanted to make a change
would "check out" the file he or she wanted to work on, make changes, and then
check it back in as the newest main version [@raymond2003art. While one team
member had this file checkout out, other members would often be "locked" out of
making any changes to that file---they could look at it, but couldn't make any
edits [@raymondunderstanding; @target2018version]. This meant that there was no
chance of two people trying to change the same part of a file at the same time.
In spirit, this early system is pretty similar to the idea of sending a file
around the team by email, with the understanding that only one person works on
it at a time. While the "main" version is in different people's hands at
different times, to do work, you all agree that only one person will work on it
at a time. A slightly more modern analogy is the idea of having a single version
of a file in Dropbox or Google Docs, and avoiding working on the file when you
see that another team member is working on it. (However, both of these examples
other key features of version control, which we'll discuss a bit later.)

> "The most primitive (but still very common) method [of version control] is all 
hand-hacking. You snapshot the project periodically by manually copying everything
in it to a backup. You include history comments in source files. You make verbal
or email arrangements with other developers to keep their hands off certain files
while you hack them." [@raymond2003art]

> "The hidden costs of this hand-hacking method are high, especially when (as 
frequently happens) it breaks down. The procedures take time and concentration; 
they're prone to error, and tend to get slipped under pressure or when the project
is in trouble---that is exactly when they are needed. ... To avoid these problems, 
you can use a *version-control system* (VCS), a suite of programs that 
automates away most of the drudgery involved in keeping an annotated history of
your project and avoiding modification conflicts." [@raymond2003art]

> "In a medium-sized project, it often happens that a (relatively small) number
of people work simultaneously on a single set of files, the 'program' or the
'project'. Often these people have additional tasks, causing their working
speeds to differ greatly. One person may be working a steady ten hours a day on
the project, a second may have barely time to dabble in the project enough to
keep current, while a third participant may be sent off on an urgent temporary
assignment just before finishing a modification. It would be nice if each
participant could be abstracted from the vicissitudes of the lives of the
others." [@grune1986concurrent]

This system is pretty clunky, though. In particular, it probably usually
increases the amount of time that it takes the team to finish the project,
because only one person can work on a file at a time. Later types of version
control programs moved toward a different style, allowing for *distributed*
rather than *centralized* collaborative work on a file or a set of files
[@raymondunderstanding; @irving2011astonishments]. Under the distributed model,
all team members can have their own version of all the files, work on them and
make records of changes they make to the files, and then occassionally sync with
everyone else to share your changes with them and bring their changes into your
copy of the files. 

This functionality is called *concurrency*, since it allows team members to
concurrently work on the same set of files [@raymondunderstanding]. This idea
allowed for the development of other useful features and styles of working,
including *branching* to try out new ideas that you're not sure you'll
ultimately want to go with and *forking*, a key tool used in open-source
software development, which among other things facilitates someone who isn't
part of the original team getting a copy of the files they can work with and
suggesting some changes that might be helpful.

So, this is the basic idea of modern version control---for a project that involves a set
of computer files, everyone on has their own copy of a directory with those files
on their own computer, makes changes at the time and in the spots in the files that
they want, and then regularly re-syncs their local directory with everyone else's
to share changes and updates. 

> "VCSs are a huge boon to productivity and code quality in many ways, even for small 
single-developer projects. They automate away many procedures that are just tedious
work. They help a lot in recovering from mistakes. Perhaps most importantly, they 
free programmers to experiment by guarnateeing that reversion to a known-good
state will always be easy." [@raymond2003art]

There is one key feature of modern version control that's
critical to making this work---merging files that started the same but were edited in
different ways and now need to be put back together, bringing any changes made from the
original version. This step is called *merging* the files. While this is typically 
described using the plural, "files", at a higher-level, you can thing of this as 
just merging the *changes* that two people have made as they edited a single file, a
file where they both started out with identical copies. 

Think of the file broken up into each of its separate lines. There will be some lines
that neither person changed. Those are easy to handle in the "merge"---they stay the
same as in the original copy of the file. Next, there will be some lines that one
person changed, but that the other person didn't. It turns out that these are pretty
easy to handle, too. If only one person changed the line, then you use their version---it's
the most up-to-date, since if both people started out with the same version, it means
that the other person didn't make any changes to that part of the file. 
Finally, there may be a few lines that both people changed. These are called *merge conflicts*. 
They're places in the file where there's not a clear, easy-to-automate way that
the computer can know which version to put into the integrated, latest version of the
file. Different version control programs handle these merge conflicts in different ways. 
For the most common version control program used today, *git*, these spots in the 
file are flagged with a special set of symbols when you try to integrate the two updated
versions of the file. Along with the special symbols to denote a conflict, there will 
also be *both* versions of the conflicting lines of the file. Whoever is integrating the 
files must go in and pick the version of those lines to use in the integrated version
of the file, or write in some compromise version of those lines that brings in elements
from both people's changes, and then delete all the symbols denoting that was a conflict
and save this latest version of the file. 

There are a number of other features of version control that make it useful for
collaborating on file-based projects with teams. First, these systems allow you
to explain your changes as you make them---in other words, it allows for
*annotation* of the developing and editing process [@raymondunderstanding]. This
provides the team with a full history of why the files evolved in the way they
did across the team. It also provides a way to communicate across the team
members. 

> "You will likely share your code with multiple lab mates or collaborators, 
and they may have suggestions on how to improve it. If you email the code
to multiple people, you will have to manually incorporate all the changes 
each of them sends." [@blischak2016quick]

[*change tracking*]
For example, if one person is the key person working on a certain file,
but has run into a problem with one spot and asks another team member to take a
go, then the second team member isn't limited to just looking at the file and
then emailing some suggestions. Instead, the second person can make sure he or
she has the latest version of that file, make the changes they think will help,
*commit* those changes with a message (a *commit message*) about why they think
this change will fix the problem, and then push that latest version of the file
back to the first person. If there are several places where it would help to
change the file, then these can be fixed through several separate commits, each
with their own message. The first person, who originally asked for help, can
read through the updates in the file (most platforms for using version control
will now highlight where all these changes are in the file) and read the second
person's message or messages about why each change might help. Even better, days
or months later, when team members are trying to figure out why a certain change
was made in that part of the file, can go back and read these messages to get an
explanation. 

> "You know your code has changed; do you know why? It's easy to forget the 
reasons for changes, and step on them later. If you have collaborators on a 
project, how do you know what they have changed while you weren't looking, and
who was responsible for each change?" [@raymond2003art]

There's another feature of version control that can be demonstrated through this
example. Because the changes made to the files in the project are regularly
*committed*, with a message for each commit and a record of what was changed in
that commit, the team members can, at any point, go back to the *exact* version
of the project at any earlier point in time. Each of the commits is given its
own ID tag ([name for this? hash?]), and *git* has a number of commands that let
you "roll back" to earlier versions, by going back to the version as it was when
a certain commit was made, provided *reversability* within the project files
[@raymondunderstanding].

> "If you make a change, and discover it's not viable, how can you revert
to a code version that is known good? If reversion is difficult or unreliable, 
it's hard to risk making changes at all (you could trash the whole project, or
make many hours of painful work for yourself)." [@raymond2003art]

It turns out that this functionality---of being able to "roll back" to earlier
versions---has a wonderful side benefit when it comes to working on a large
project. It means that you **don't** need to save earlier versions of each file.
You can maintain one and only one version of each project file in the project's
directory, with the confidence that you never "lose" old versions of the file
[@perkel2018git; @blischak2016quick]. If you're working on a manuscript, for
example, when it's time to edit, you can cut whole paragraphs, and if you ever
need to get them back, they'll be right there in the commit history for your
project, with their own commit message about why they were cut (hopefully a nice
clear one that will make it easy to find that commit if you ever need those
paragraphs again).

[xkcd / cartoon of this?]

> "Early in his graduate career, John Blischak found himself creating figures
for his advisor's grant application. Blischak was using the programming language
R to generate the figures, and as he iterated and optimized his code, he ran
into a familiar problem: Determined not to lose his work, he gave each new
version a different filename---analysis_1, analysis_2, and so on, for
instance---but failed to document how they had evolved. 'I had no idea what had
changed between them,' says Blischak... Using Git, Blischak says, he no longer
needed to maintain multiple copies of his files. 'I just keep overwriting it and
changing it and saving the snapshots. And if the professor comes back and says,
'oh, you sent me an email back in March with this figure', I can say, 'okay,
well, I'll just bo back to the March version of my code and I can recreate
it'.'" [@perkel2018git]

> "Have a quick look back up at those decades of progress. Yes, some of the
advances were also enabled by increasing computer power. But, mainly, they were
simply made by people thinking of cleverer ways of collaborating."
[@irving2011astonishments]

> "Using GitHub or any similar versioning / tracking system is not a replacement
for good project management; it is an extension, an improvement for good
project and file management." [@perez2016ten]

The most common version control program currently used for scienctific projects is
*git*. This program was created by Linus Torvalds, who also created the Linux 
operating system, in 2005 as a way to facilitate the team working on Linux 
development. This program for version control thrives in large collaborative
projects, for example open-source software development projects that include
numerous contributors, both regular and occasional [@brown2018git].

> "If your software engineering career, like mine, is no older than GitHub, then 
git may be the only version control software you have ever used. While people 
sometimes grouse about its steep learning curve or unintuitive interface, git has
become everyone's go-to for version control." [@target2018version]

In recent years, some complementary tools have been developed that make the process of 
collaborating together using version control software easier. 
Other tools can helps in collaborating on file-based projects, including *bug trackers*
or *issue trackers*, which allow the team to keep a running "to-do" list of what needs
to be done to complete the project. Other helpful tools, particularly for compiled
software projects, include *build systems*. Some of these features come within 
Software Configuration Management (SCM) programs [@raymondunderstanding]

> "GitHub issues are a great way to keep track of bugs, tasks, feature requests,
and enhancements. While classical issue trackers are primarily intended to be 
used as bug trackers, in contrast, GitHub issue trackers follow a different 
philosophy: each tracker has its own section in every repository and can be used
to trace bugs, new ideas, and enhancements by using a powerful tagging system.
The main objective of issues in GitHub is promoting collaboration and providing 
context using cross-references. Raising an issue does not require lengthy forms
to be completed. It only requires a title and, preferably, at least a short description.
Issues have very clear formatting and provide space for anyone with a GitHub account
to provide feedback. ... Additional elements of issues are (i) color-coded labels
that help to categorize and filter issues, (ii) milestones, and (iii) one assignee 
responsible for working on the issue." [@perez2016ten]

> "As another illustration of issues and their generic and wide application, we
and others used GitHub issues to discuss and comment on changes in manuscripts
and address reviewers' comments." [@perez2016ten]

GitHub was created in 2008 as a web-based platform to facilitate collaborating
on projects running under git version control. It can provide an easier entry
to using git for version control than trying to learn to use git from the
command line [@perez2016ten]. It also plays well with RStudio, making it easy
to integrate a collaborative workflow through GitHub from the same RStudio
window on your computer where you are otherwise doing your analysis [@perez2016ten].

> "The astonishment was that you might want to make even your tiny hacks to 
other people's code public. Before GitHub, we tended to keep those on our own
computer. Nowadays, it is so each to make a fork, or even edit the code directly 
in your browser, that potentially anyone can find even your least polished
bug fixes immediately." [@irving2011astonishments]

> Resources like GitHub are "essential for collaborative software projects
because they enable the organization and sharing of programming tasks between
different remote contributors." [@perez2016ten]

On GitHub, you can set the access to a project to be either public or private,
and can be converted easily from one form to the other over the course of the
project [@metz2015github]. A private project can be viewed only by fellow team
members, while a public project can be viewed by anyone. What's more, while only
collaborators on a public project can directly change the code, anyone else can
*suggest* changes through a process of copying a version of the project
(*forking* it), making the changes they would like to suggest, and the asking
the project's owners to consider integrating the changes back into the main
version of the project through a *pull request*. GitHub therefore creates a
platform where people can explore, adapt, and add to other people's coding
projects, enabling a community of coders [@perez2016ten].

> "Much more than a code warehouse, GitHub is effectively a social network for
software development." [@perkel2018git]

> GitHub has been described as "a kind of bazaar that offers just about any 
piece of code you might want---and so much of it free." [@metz2015github]

GitHub can also be used to collaborate on, host, and publish websites and other
online content [@perez2016ten]. It's GitHub Pages functionality, for example, is
now being used to host a number of books created in R using the `bookdown`
package, including the online version of this book.

> "The traditional way to promote scientific software is by publishing an associated
paper in the peer-reviewed scientific literature, though, as pointed out by Buckheir and
Donoho, this is just advertising. Additional steps can boost the visibility of 
an organization. For example, GitHub Pages are simple websites freely hosted by 
GitHub. Users can create and host blog websites, help pages, manuals, tutorials, 
and websites related to specific projects." [@perez2016ten]

> "VCSs, by the way, are not merely good for program code; the manuscript of this 
book was maintained as a collection of files under RCS while it was being written."
[@raymond2003art]

### Recording data in the laboratory---from paper to computers

Traditionally, experimental data collected in a laboratory was recorded in a
paper laboratory notebook. These laboratory notebooks played a role not only as
the initial recording of data, but also can serve as, for example, a legal
record of the data recorded in the lab [@mascarelli2014research]. They were also
a resource for collaborating across a team and for passing on a research project
from one lab member to another [@butler2005electronic]. 

However, paper laboratory notebooks have a number of limitations. First, they
can be very inefficient. In a time when almost all data analyses---even simple
calculations---are done on a computer, recording research data on paper rather
than directly entering it into a computer is inefficient. Also, any stage of
copying data from one format to another, especially when done by a human rather
than a machine, introduces the chance to copying errors. Handwritten laboratory
notebooks can be hard to read [@butler2005electronic; @perkel2011coding], and
may lack adequate flexibility and expandability to handle the complex
experiments often conducted. Further, electronic alternatives can also be easier
to search, allowing for deeper and more comprehensive investigations of the data
collected across multiple experiments [@giles2012digital; @butler2005electronic;
@perkel2011coding].

> "Lab notebooks are stuck in a time warp, still handwritten, on paper. Many
scientists can barely understand their own scribblings from last week, let alone
five years from now---as anyone who has had to decipher the hieroglyphics of a 
co-worker can testify."  [@butler2005electronic]

> "Handwritten lab notebooks are usually chaotic and always unsearchable." 
[@perkel2011coding]

> "But the biggest advantage of going electronic should appeal to both industry and
academia alike. With paper records, vast amounts of data lie unused and 
effectively hidden, whereas e-notebooks allow results to be instantly shared with
collaborators." [@butler2005electronic]

Given a widespread recognition of the limitations of paper laboratory notebooks,
in the past couple of decades,  there have been a number of efforts, both formal
and informal, to move from paper laboratory notebooks to electronic
alternatives. In some fields that rely heavily on computational analysis, there
are very few research labs (if any) that use paper laboratory notebooks
[@butler2005electronic]. In other fields, where researchers have traditionally
used paper lab notebooks, companies have been working for a while to develop
electronic laboratory notebooks specifically tailored to scientific research
needs [@giles2012digital]. These were adopted more early in pharmaceutical
industrial labs, where companies had the budgets to get customized versions and
the authority to require their use, but have taken longer to be adapted in
academic laboratories [@giles2012digital; @butler2005electronic]. A widely 
adopted platform for electronic laboratory notebooks has yet to be taken up 
by the scientific community, despite clear advantages of recording data directly 
into a computer rather than first using a paper notebook.

> "Since at least the 1990s, articles on technology have predicted the imminent, 
widespread adoption of electronic laboratory notebooks (ELNs) by researchers. It has 
yet to happen---but more and more scientists are taking the plunge." [@kwok2018lab]

Instead of using customized electronic laboratory notebook software, some
academics are moving their data recording online, but are using more generalized
electronic alternatives, like Dropbox, Google applications, OneNote, and
Evernote [@perkel2011coding; @kwok2018lab; @giles2012digital; @powell2012lab].
Some scientists have started using version control tools, especially the
combination of git and GitHub, as a way to improve laboratory data recording,
and in particular to improve transparency and reproducibility standards.
These pieces of software share the same pattern as Google tools or
Dropbox---they are generalized tools that have been honed and optimized for ease
of use through their role outside of scientific research, but can be harnessed
as a powerful tool in a scientific laboratory, as well. They are also free---at
least, for GitHub, at the entry and academic levels---and, even better, one
(git) is open source.

> "The purpose of a lab notebook is to provide a lasting record of events in a
laboratory. In the same way that a chemistry experiment would be nearly
impossible without a lab notebook, scientific computing would be a nightmare of
inefficiency and uncertainty without version-control systems."
[@tippmannmy2014digital]

While some generalized tools like Google tools and Dropbox might be simpler to 
initially learn, version control tools offer some key advantages for recording
scientific data and are worth the effort to adopt. A key advantage is their
ability to track the full history of files as they evolve, including not only
the history of changes to each file, but also a record of why each change was
made. Git excels in tracking changes made to plain text
files. For these files, whether they record code, data, or text, git can show
line-by-line differences between two versions of the file. This makes it very
easy to go through the history of "commits" to a plain text file in a
git-tracked repository and see what change was made at each time point, and then
read through the commit messages associated with those commits to see why a
change was made. For example, if a value was entered in the wrong row of a csv,
and the researcher then made a commit to correct that data entry mistake, the
researcher could explain the problem and its resolution in the commit message
for that change.

The ability in git to compare differences between two plain text files derives from
a longstanding Unix command line tool called `diff`. This tool developed early in 
the history of Unix at AT&T [@raymond2003art]. This small, extremely solid and 
well-tested tool serves as a basis for tracking changes in the files is a directory
under version control as they evolve. Version control systems have added the 
ability to align commit messages and commit tags with each "snapshot" of these 
differences in files, creating a stable system for creating a complete history of
how files in a project directory have changed over the timecourse of the project and
why.

Platforms for using git often include nice tools for visualizing differences
between two files, providing a more visual way to look at the "diffs" between
files across time points in the project. For example, GitHub automatically shows
these using colors to highlight addititions and substractions of plain text for
one file compared to another version of it when you look through a repository's
commit history. Similarly, RStudio provides a new "Commit" window that can be
used to compare differences between the original and revised version of plain
text files at a particular stage in the commit history.

[Maybe include a figure with an example of how the difference between two 
text files can be seen, along with a commit message explaining the change?]

The use of version control tools and platforms, like git and GitHub, not only 
helps in transparent and trackable recording of data, but it also brings some
additional advantages in the research project. First, this combination of tools
aids in collaboration across a research group, as we discuss in depth in the next
chapter. 

Second, if a project uses these tools, it is very easy to share data recorded
for the project publicly. In a project that uses git and GitHub version control
tools, it is easy to share the project data online once an associated manuscript
is published, an increasingly common request or requirement from journals and
funding agencies [@blischak2016quick]. Sharing data allows a more
complete assessment of the research by reviewers and readers and makes it easier
for other researchers to build off the published results in their own work,
extending and adapting the code to explore their own datasets or ask their own
research questions [@perez2016ten]. In GitHub, a repository's setting can be
changed from "Private" to "Public", allowing anyone to explore the files in the
repository. Because git tracks the full history of changes to these documents,
it includes functionality that let's you tag the code and data at a specific
point (for example, the date when a paper was submitted) so that viewers can
look at that specific "version" of the repository files, even while the project
team continues to move forward in improving files in the directory. At the more
advanced end of functionality, there are even ways to assign a DOI to a specific
version of a GitHub repository [@perez2016ten].

Third, the combination of git and GitHub can help as a way to backup study data
[@blischak2016quick; @perez2016ten; @perkel2018git]. Together, git and GitHub
provide a structure where the project directory (repository) is copied on
multiple computers, both the users' laptop or desktop computers and on a remote
server hosted by GitHub or a similar organization. This set-up makes it easy to
bring all the project files onto a new computer---all you have to do is clone
the project repository. It also ensures that there are copies of the full
project directory, including all its files, in multiple places
[@blischak2016quick]. Further, not only is the data backed up across multiple
computers, but so is the full history of all changes made to that data and the
recorded messages explaining those changes, through the repositories commit
messages [@perez2016ten].

There are, of course, some limitations to using version control tools when
recording experimental data. First, while ideally laboratory data is recorded in
a plain text format (see Chapter [x] for a deeper discussion of why), some data
may be recorded in a binary file format. Some version control tools, including
git, can be used to track changes in binary files. However, git does not take to
these types of files naturally. In particular, git typically will not be able to
show users a useful comparison of the differences between two versions of a
binary file. More problems can arise if the binary file is very large
[@perez2016ten; @blischak2016quick], as some experimental research data files
are (e.g., if they are the output of 'omics laboratory equipment like a mass
spectrometer). However, there are emerging tools and strategies for improving
the ability to include and track large binary files when using git and GitHub
[@blischak2016quick]

> "You can version control any file that you put in a Git repository, whether it is
text-based, an image, or a giant data file. However, just because you *can* version
control something, does not mean that you *should*." [@blischak2016quick]

Further, as with other tools and techniques described in this book, there is an
investment required to learn how to use git and GitHub [@perez2016ten], as well
as a bit of extra overhead when using version control tools in a project
[@raymond2003art]. However, both can bring dramatic gains to efficiency,
transparency, and organization of research projects, even if you only use a
small subset of its basic functionality [@perez2016ten]. In Chapter 11 we
provide guidance on getting started with using git and Github to track a
scientific research project.

> "Although Git has a complex set of commands and can be used for rather complex 
operations, learning to apply the basics requires only a handful of new concepts
and commands and will provide a solid ground to efficiently track code and related
content for research projects." [@perez2016ten]

### Discussion questions

