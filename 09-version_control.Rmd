## Harnessing version control for transparent data recording

As a research project progresses, a typical practice in many experimental
research groups is to save new versions of files (e.g., 'draft1.doc',
'draft2.doc'), so that changes can be reverted. However, this practice leads to
an explosion of files, and it becomes hard to track which files represent the
'current' state of a project. Version control allows researchers to edit and
change research project files more cleanly, while maintaining the power to
'backtrack' to previous versions, messages included to explain changes. We will
explain what version control is and how it can be used in research projects to
improve the transparency and reproducibility of research, particularly for data
recording.

**Objectives.** After this module, the trainee will be able to:

- Describe version control  
- Explain how version control can be used to improve reproducibility 
for data recording

### What is version control?

Version control developed as a way to coordinate collaborative work on 
software programming projects. The term "version" here refers to the current
state of a document or set of documents, for example the source code for a
computer program. The idea of "control" is to allow for safe changes and updates
to this version while more than one person is working on it. 
The general term "version control" can refer to any method of
syncing contributions from several people to a file or set of files, and
very early on it was done by people rather than through a computer program. 
Some software developers have shared their memories of taking their
code to the "Source Control" team, who then integrated it into the main
source code file by hand [@irving2011astonishments]. 

> "Tracking all that detail is just the sort of thing computers
are good at and humans are not." [@raymond2003art]

In earlier types of version control programs, there was one central "main"
repository the file or set of files the team was working on
[@raymondunderstanding; @target2018version]. Very early on, this was kept on one
computer [@irving2011astonishments]. A team member who wanted to make a change
would "check out" the file he or she wanted to work on, make changes, and then
check it back in as the newest main version [@raymond2003art. While one team
member had this file checkout out, other members would often be "locked" out of
making any changes to that file---they could look at it, but couldn't make any
edits [@raymondunderstanding; @target2018version]. This meant that there was no
chance of two people trying to change the same part of a file at the same time.
In spirit, this early system is pretty similar to the idea of sending a file
around the team by email, with the understanding that only one person works on
it at a time. While the "main" version is in different people's hands at
different times, to do work, you all agree that only one person will work on it
at a time. A slightly more modern analogy is the idea of having a single version
of a file in Dropbox or Google Docs, and avoiding working on the file when you
see that another team member is working on it. (However, both of these examples
other key features of version control, which we'll discuss a bit later.)

This system is pretty clunky, though. In particular, it probably usually
increases the amount of time that it takes the team to finish the project,
because only one person can work on a file at a time. Later types of version
control programs moved toward a different style, allowing for *distributed*
rather than *centralized* collaborative work on a file or a set of files
[@raymondunderstanding; @irving2011astonishments]. Under the distributed model,
all team members can have their own version of all the files, work on them and
make records of changes they make to the files, and then occassionally sync with
everyone else to share your changes with them and bring their changes into your
copy of the files. 

So, this is the basic idea of modern version control---for a project that
involves a set of computer files, everyone on the team (even if that's just one
person) has their own copy of a directory with those files on their own
computer, makes changes at the time and in the spots in the files that they
want, and then regularly re-syncs their local directory with everyone else's to
share changes and updates. Remote repositories---which may be on a server in 
a different location---can be added with another copy of the project, which 
can similarly be synced regularly to update with any changes made to project 
files.

Add on this distribution of files is the ability to keep track of the changes
made to the file, as well as messages about why those changes were made. These
systems allow you to explain your changes as you make them---in other words, it
allows for *annotation* of the developing and editing process
[@raymondunderstanding]. The ability in version control software to compare
differences between two plain text files derives from a longstanding Unix
command line tool called `diff`. This tool developed early in the history of
Unix at AT&T [@raymond2003art]. This small, extremely solid and well-tested tool
serves as a basis for tracking changes in the files is a directory under version
control as they evolve. Version control systems have added the ability to align
commit messages and commit tags with each "snapshot" of these differences in
files, creating a stable system for creating a complete history of how files in
a project directory have changed over the timecourse of the project and why.
Each snapshot of changes to the files in a directory is called a *commit*, 
which is tagged with an identifier so it can be found later, as well as a 
*commit message* describing why the change was made. The commit messages 
can serve as a powerful tool for explaining changes to other team members or
for reminding yourself in the future about why certain changes were made.

Further, because the changes made to the files in the project are regularly
*committed*, with a message for each commit and a record of what was changed in
that commit, the team members can, at any point, go back to the *exact* version
of the project at any earlier point in time. Each of the commits is given its
own ID tag ([name for this? hash?]), and *git* has a number of commands that let
you "roll back" to earlier versions, by going back to the version as it was when
a certain commit was made, provided *reversability* within the project files
[@raymondunderstanding].

> "If you make a change, and discover it's not viable, how can you revert
to a code version that is known good? If reversion is difficult or unreliable, 
it's hard to risk making changes at all (you could trash the whole project, or
make many hours of painful work for yourself)." [@raymond2003art]

It turns out that this functionality---of being able to "roll back" to earlier
versions---has a wonderful side benefit when it comes to working on a large
project. It means that you **don't** need to save earlier versions of each file.
You can maintain one and only one version of each project file in the project's
directory, with the confidence that you never "lose" old versions of the file
[@perkel2018git; @blischak2016quick]. 

> "Early in his graduate career, John Blischak found himself creating figures
for his advisor's grant application. Blischak was using the programming language
R to generate the figures, and as he iterated and optimized his code, he ran
into a familiar problem: Determined not to lose his work, he gave each new
version a different filename---analysis_1, analysis_2, and so on, for
instance---but failed to document how they had evolved. 'I had no idea what had
changed between them,' says Blischak... Using Git, Blischak says, he no longer
needed to maintain multiple copies of his files. 'I just keep overwriting it and
changing it and saving the snapshots. And if the professor comes back and says,
'oh, you sent me an email back in March with this figure', I can say, 'okay,
well, I'll just bo back to the March version of my code and I can recreate
it'.'" [@perkel2018git]

The most common version control program currently used for scienctific projects is
*git*. This program was created by Linus Torvalds, who also created the Linux 
operating system, in 2005 as a way to facilitate the team working on Linux 
development. This program for version control thrives in large collaborative
projects, for example open-source software development projects that include
numerous contributors, both regular and occasional [@brown2018git].

> "If your software engineering career, like mine, is no older than GitHub, then 
git may be the only version control software you have ever used. While people 
sometimes grouse about its steep learning curve or unintuitive interface, git has
become everyone's go-to for version control." [@target2018version]

In recent years, some complementary tools have been developed that make the
process of collaborating together using version control software easier. Other
tools can helps in collaborating on file-based projects, including *bug
trackers* or *issue trackers*, which allow the team to keep a running "to-do"
list of what needs to be done to complete the project, all of which are
discussed in the next chapter as tools that can be used to improve collaboration
on scientific projects spread across teams. GitHub, a very popular version
control platform with these additional tools, was created in 2008 as a web-based
platform to facilitate collaborating on projects running under git version
control. It can provide an easier entry to using git for version control than
trying to learn to use git from the command line [@perez2016ten]. It also plays
well with RStudio, making it easy to integrate a collaborative workflow through
GitHub from the same RStudio window on your computer where you are otherwise
doing your analysis [@perez2016ten].

### Recording data in the laboratory---from paper to computers

Traditionally, experimental data collected in a laboratory was recorded in a
paper laboratory notebook. These laboratory notebooks played a role not only as
the initial recording of data, but also can serve as, for example, a legal
record of the data recorded in the lab [@mascarelli2014research]. They were also
a resource for collaborating across a team and for passing on a research project
from one lab member to another [@butler2005electronic]. 

However, paper laboratory notebooks have a number of limitations. First, they
can be very inefficient. In a time when almost all data analyses---even simple
calculations---are done on a computer, recording research data on paper rather
than directly entering it into a computer is inefficient. Also, any stage of
copying data from one format to another, especially when done by a human rather
than a machine, introduces the chance to copying errors. Handwritten laboratory
notebooks can be hard to read [@butler2005electronic; @perkel2011coding], and
may lack adequate flexibility and expandability to handle the complex
experiments often conducted. Further, electronic alternatives can also be easier
to search, allowing for deeper and more comprehensive investigations of the data
collected across multiple experiments [@giles2012digital; @butler2005electronic;
@perkel2011coding].

> "Handwritten lab notebooks are usually chaotic and always unsearchable." 
[@perkel2011coding]

Given a widespread recognition of the limitations of paper laboratory notebooks,
in the past couple of decades,  there have been a number of efforts, both formal
and informal, to move from paper laboratory notebooks to electronic
alternatives. In some fields that rely heavily on computational analysis, there
are very few research labs (if any) that use paper laboratory notebooks
[@butler2005electronic]. In other fields, where researchers have traditionally
used paper lab notebooks, companies have been working for a while to develop
electronic laboratory notebooks specifically tailored to scientific research
needs [@giles2012digital]. These were adopted more early in pharmaceutical
industrial labs, where companies had the budgets to get customized versions and
the authority to require their use, but have taken longer to be adapted in
academic laboratories [@giles2012digital; @butler2005electronic]. A widely 
adopted platform for electronic laboratory notebooks has yet to be taken up 
by the scientific community, despite clear advantages of recording data directly 
into a computer rather than first using a paper notebook.

> "Since at least the 1990s, articles on technology have predicted the imminent, 
widespread adoption of electronic laboratory notebooks (ELNs) by researchers. It has 
yet to happen---but more and more scientists are taking the plunge." [@kwok2018lab]

Instead of using customized electronic laboratory notebook software, some
academics are moving their data recording online, but are using more generalized
electronic alternatives, like Dropbox, Google applications, OneNote, and
Evernote [@perkel2011coding; @kwok2018lab; @giles2012digital; @powell2012lab].
Some scientists have started using version control tools, especially the
combination of git and GitHub, as a way to improve laboratory data recording,
and in particular to improve transparency and reproducibility standards.
These pieces of software share the same pattern as Google tools or
Dropbox---they are generalized tools that have been honed and optimized for ease
of use through their role outside of scientific research, but can be harnessed
as a powerful tool in a scientific laboratory, as well. They are also free---at
least, for GitHub, at the entry and academic levels---and, even better, one
(git) is open source.

> "The purpose of a lab notebook is to provide a lasting record of events in a
laboratory. In the same way that a chemistry experiment would be nearly
impossible without a lab notebook, scientific computing would be a nightmare of
inefficiency and uncertainty without version-control systems."
[@tippmannmy2014digital]

While some generalized tools like Google tools and Dropbox might be simpler to 
initially learn, version control tools offer some key advantages for recording
scientific data and are worth the effort to adopt. A key advantage is their
ability to track the full history of files as they evolve, including not only
the history of changes to each file, but also a record of why each change was
made. Git excels in tracking changes made to plain text
files. For these files, whether they record code, data, or text, git can show
line-by-line differences between two versions of the file. This makes it very
easy to go through the history of "commits" to a plain text file in a
git-tracked repository and see what change was made at each time point, and then
read through the commit messages associated with those commits to see why a
change was made. For example, if a value was entered in the wrong row of a csv,
and the researcher then made a commit to correct that data entry mistake, the
researcher could explain the problem and its resolution in the commit message
for that change.

Platforms for using git often include nice tools for visualizing differences
between two files, providing a more visual way to look at the "diffs" between
files across time points in the project. For example, GitHub automatically shows
these using colors to highlight addititions and substractions of plain text for
one file compared to another version of it when you look through a repository's
commit history. Similarly, RStudio provides a new "Commit" window that can be
used to compare differences between the original and revised version of plain
text files at a particular stage in the commit history.

[Maybe include a figure with an example of how the difference between two 
text files can be seen, along with a commit message explaining the change?]

The use of version control tools and platforms, like git and GitHub, not only 
helps in transparent and trackable recording of data, but it also brings some
additional advantages in the research project. First, this combination of tools
aids in collaboration across a research group, as we discuss in depth in the next
chapter. 

Second, if a project uses these tools, it is very easy to share data recorded
for the project publicly. In a project that uses git and GitHub version control
tools, it is easy to share the project data online once an associated manuscript
is published, an increasingly common request or requirement from journals and
funding agencies [@blischak2016quick]. Sharing data allows a more complete
assessment of the research by reviewers and readers and makes it easier for
other researchers to build off the published results in their own work,
extending and adapting the code to explore their own datasets or ask their own
research questions [@perez2016ten]. On GitHub, you can set the access to a
project to be either public or private, and can be converted easily from one
form to the other over the course of the project [@metz2015github]. A private
project can be viewed only by fellow team members, while a public project can be
viewed by anyone. Further, because git tracks the full history of changes to
these documents, it includes functionality that let's you tag the code and data
at a specific point (for example, the date when a paper was submitted) so that
viewers can look at that specific "version" of the repository files, even while
the project team continues to move forward in improving files in the directory.
At the more advanced end of functionality, there are even ways to assign a DOI
to a specific version of a GitHub repository [@perez2016ten].

Third, the combination of git and GitHub can help as a way to backup study data
[@blischak2016quick; @perez2016ten; @perkel2018git]. Together, git and GitHub
provide a structure where the project directory (repository) is copied on
multiple computers, both the users' laptop or desktop computers and on a remote
server hosted by GitHub or a similar organization. This set-up makes it easy to
bring all the project files onto a new computer---all you have to do is clone
the project repository. It also ensures that there are copies of the full
project directory, including all its files, in multiple places
[@blischak2016quick]. Further, not only is the data backed up across multiple
computers, but so is the full history of all changes made to that data and the
recorded messages explaining those changes, through the repositories commit
messages [@perez2016ten].

There are, of course, some limitations to using version control tools when
recording experimental data. First, while ideally laboratory data is recorded in
a plain text format (see Chapter [x] for a deeper discussion of why), some data
may be recorded in a binary file format. Some version control tools, including
git, can be used to track changes in binary files. However, git does not take to
these types of files naturally. In particular, git typically will not be able to
show users a useful comparison of the differences between two versions of a
binary file. More problems can arise if the binary file is very large
[@perez2016ten; @blischak2016quick], as some experimental research data files
are (e.g., if they are the output of 'omics laboratory equipment like a mass
spectrometer). However, there are emerging tools and strategies for improving
the ability to include and track large binary files when using git and GitHub
[@blischak2016quick]

> "You can version control any file that you put in a Git repository, whether it is
text-based, an image, or a giant data file. However, just because you *can* version
control something, does not mean that you *should*." [@blischak2016quick]

[Add something about whether version control timestamps would meet legal standards, 
e.g., for patent claims? Mike had a comment about using locks with data that might
go with that.]

Finally, as with other tools and techniques described in this book, there is an
investment required to learn how to use git and GitHub [@perez2016ten], as well
as a bit of extra overhead when using version control tools in a project
[@raymond2003art]. However, both can bring dramatic gains to efficiency,
transparency, and organization of research projects, even if you only use a
small subset of its basic functionality [@perez2016ten]. In Chapter 11 we
provide guidance on getting started with using git and Github to track a
scientific research project.

> "Although Git has a complex set of commands and can be used for rather complex 
operations, learning to apply the basics requires only a handful of new concepts
and commands and will provide a solid ground to efficiently track code and related
content for research projects." [@perez2016ten]

### Discussion questions

