## Organizing project files {#module6}

To improve the computational reproducibility of a research project, researchers
can use a single 'Project' directory to collectively store all research data,
meta-data, pre-processing code, and research products (e.g., paper drafts,
figures). We will explain how this practice improves the reproducibility and
list some of the common components and subdirectories to include in the
structure of a 'Project' directory, including subdirectories for raw and
pre-processed experimental data.

**Objectives.** After this module, the trainee will be able to:

- Describe a 'Project' directory, including common components and subdirectories 
- List how a single 'Project' directory improves reproducibility

In earlier modules, we discussed how to separate data collection from data
analysis. By separating data collection and analysis into separate files, we can
make the file for each step simpler. Further, by separating steps into different
files, we can save the files in plain text, which makes it easier to track them
using version control software (discussed in later modules). This helps create a
record of changes made to the data or analysis code during the research process.

While this process helps in reproducibility, it results in more files being
collected for an experiment. Instead of data and its analysis collected within a
single spreadsheet file, you may end up with multiple files of data collected
from the experiment, as well as separate files with scripts for processing,
analyzing, and visualizing the data. With more complex experiments, there may be
different data files containing the data collected from different assays. For example,
you may run an experiment where you collect data from each research animal on
bacterial load, as well as flow cytometry data, as well as a measure of antibody
levels through ELISA. As a result, you may have one raw data file from each
assay and, for some assays, even one file per study subject (e.g., flow
cytometry). The files for a research project will also include files with
writing and presentations (posters and slides) associated with the project, as
well as code scripts for preprocessing data, for conducting data analysis, and
for creating and sharing final figures and tables.

In the next few modules, we'll discuss how you can organize the files for an
experiment using a single directory that is designed to follow a similar format
across all your projects. The modules will discuss the advantages
of well-designed project directories, tips for arranging files within a project
directory, and how to create a directory template that allows you to use
consistent file organization across many experiments.

### Organizing project files 

As the files for a project accumulate, do you have a clear plan for keeping them
organized? Based on one analysis, many biomedical researchers do not. One study,
for example, surveyed over 250 biomedical researchers at the University of
Washington. They noted that, "Some researchers admitted to having no
organizational methodology at all, while others used whatever method best suited
their individual needs" [@anderson2007issues]. One respondent answered, "They're
not organized in any way---they're just thrown into files under different
projects," while another said "I grab them when I need them, they're not
organized in any decent way," and another, "It's not even organized---a file on
a central computer of protocols that we use, common lab protocols but those are
just individual Word files within a folder so it's not searchable *per se*"
[@anderson2007issues]. 

Similarly, in an article on organizing project files for research, Marwick
notes:

> "Virtually all researchers use computers as a central tool in their 
workflow. However, our formal education rarely includes any training in 
how to organise our computer files to make it easy to reproduce results
and share our analysis pipeline with others. Without clear instructions, 
many researchers struggle to avoid chaos in their file structures, and so 
are understandable reluctant to expose their workflow for others to see. 
This may be one of the reasons that so many requests for details about 
method, including requests for data and code, are turned down or go 
unanswered." [@marwick2018packaging]

In an earlier module, we introduced Adam Savage's idea of "knolling" to keep a
workspace tidy (Module 2.3). He was talking about a physical workspace. When
you are working with data, computer files and directories are your workspace.
For any type of work, the design of the workspace plays a critical role in 
how the workers approach tasks and solve problems. Rod Judkins, who is a 
lecturer at St Martin's College of Art, highlights this in a book on 
creative thinking:

> "Your working environment, whether it's a supermarket, office, studio, or 
building site, persuades you to work and think in certain ways. The more aware
you are of that, and the more you understand your medium, the more you can use 
it to your advantage." [@judkins2016art]

Adam Savage describes how important this is in another type of working, gourmet
cooking, describing how this idea of an organized workspace is captured by the
technique of *mise en place*---of laying out all the elements needed for the
work ahead of time and in an organized way---introduced by the famous French
chef August Escoffier:

> "Kitchens are pressure cookers in which wasted movement and hasty technique
can ruin a dish, slice an artery, burn a hand, land you in the weeds, and
ultimately kill a restaurant. *Mise en place* is the only way to reliably create
a perfect dish, to exact specifications, over and over again, night after night,
for paying customers who demand nothing less." [@savage2020every]

Good organization of your files can similarly encourage clear thinking and help
in reasoning through how to analyze data. One article notes that "mundane issues
such as organizing files and directories and documenting progress ... are
important because poor organizational choices can lead to significantly slower
research progress." [@noble2009quick] In fact, if files are organized in a
consistent way across multiple projects, this can even allow you to start
automating some necessary tasks through code that is built to work with that
consistent structure [@buffalo2015bioinformatics].

Organization also helps you know where to find things. You even know where to
find things when you come back to a project after a while away from it (for
example, while the paper was out for review). You can teach someone else how to
find things quickly and consistently across your multiple projects, as well as
where to put things if they're contributing to one of them. You have a place for
everything. 

As one article notes, with good organization, "methods and data sections in
papers practically write themselves, with no time wasted in frenzied hunting for
missing information." [@baker2016quality] An article on organizing computational
biology projects also highlights how good organization can improve your
efficiency:

> "Everything you do, you will probably have to do over again. Inevitably, you
will discover some flaw in your initial preparation of the data being analyzed,
or you will get access to new data, or you will decide that your
parameterization of a particular model was not broad enough. This means that the
experiment you did last week, or even the set of experiments you've been working
on over the past month, will probably need to be redone. If you have organized
and documented your work clearly, then repeating the experiment with the new
data or the new parameterization will be much, much easier." [@noble2009quick]

Finally, when your research files are kept in one place and well-organized, it
makes it easier for you to share those as a supplement to articles you write
about the research, and are also more likely to do so. One article notes:

> Without clear instructions, many researchers struggle to avoid chaos in their
file structures, and so are understandably reluctant to expose their workflow
for others to see. This may be one of the reasons that so many requests for
details about method, including requests for data and code, are turned down or
go unanswered". [@marwick2018packaging]

Sharing data and code is crucial to research reproducibility, especially for
projects that include extensive proprocessing and complex analysis of data, as
many biomedical research projects now do. As a further bonus, research articles
that include data with the publication may be more impactful, as measured by
citations that the paper receives [@marwick2018packaging].

### How to organize project files

First, and at a minimum, you should get in the habit of storing all of the files
for an experiment in the same place. Specifically, project files should all be
in a single directory within the file system of a computer [@noble2009quick].
While this can be an individual's computer, it may also be on a dedicated 
server or through an online, cloud-based program.

There are a number of advantages to keeping all files related to a single
project inside a dedicated file directory. First, this provides
a clear and obvious place to search for all project files throughout your work
on the project, including after lulls in activity (like waiting for reviews from
a paper submission). As one article notes: 

> "During the course of a project, you'll have amassed data files, notes,
scripts, and so on---if these were scattered all over your hard drive (or worse,
across many computers' hard drives), it would be a nightmare to keep track of
everything." [@buffalo2015bioinformatics]

Another article highlights how helpful this organization was for a project
involving a large group:

> "Instead of squirrelling away data in individual folders and lab books,
researchers now archive all published data in a designated central drive, so
that the information is accessible for the long haul. Initially, people thought
the process was just extra bureaucratic work, or that it had been invented so I
could police their data. Now, it has become the norm, and researchers tell me
they save time and worry by having their data organized and archived."
[@winchester2018give]

Second, by keeping all project files within a single directory, you also make it
easier to share the collection those files. There are several reasons you might
want to share these files. An obvious one is that you likely will want to share
the project files across members in your research team, so they can collaborate
together on the project. However, there are also other reasons you'd need to
share files, and one that is growing in importance is that you may be asked to
share files (data, code scripts, etc.) when you publish a paper describing your
results.

When files are all stored in one directory, the directory can be compressed and
shared as an email attachment or through a file sharing platform like Google
Drive. When all the materials for a project are stored in a single directory, it
also makes it easier to share the set of files through version control and
online version control platforms [@vuorre2021sharing]. (This also helps you to
track changes to files across the project [@vuorre2021sharing]). In later
modules in this book, we will introduce `git` version control software and the
GitHub platform for sharing files under this type of version control---this is
one example of this more dynamic way of sharing files within a directory.
Further, services like Google Drive and Microsoft Teams are steadily advancing
in their capabilities for versioning and tracking changes across shared files.

To gain the advantages of directory-based project file organization, all the
files need to be within a single directory, but they don't all have to be within
the same "level" in that directory. Instead, you can use subdirectories to
structure and organize these files, while still retaining all the advantages of
directory-based file organization. Computer file systems are well-structured to
use a hierarchical design, with subdirectories nested inside directories. You
can leverage this to manage the complexity and breadth of files for your
project.

This will help limit the number of files in each "level" of the directory, so
none becomes an overwhelming collection of files of different types. It can help
you navigate the files in the directory, and also help someone you share the
directory with figure out what's in it and where everything is. However, 
to leverage these gains, you need to be thoughtful about exactly how you 
organize the files into subdirectories. 

As you decide how to organize files, keep in mind a concept called 
"discoverability". In the classic design book *The Design of Everyday 
Things*, Don Norman presents discoverability as a key principle of good design, 
explaining as the ability for a user to be able to figure out, from the design
of something, how to use that thing quickly, easily, and correctly. He 
illustrates this with an example of discoverability in the design of doors. 
For a door, the location of a pull handle and a push bar immediately shows
someone how to use the door: pull where you see a pull handle and push where you
see a push bar. If the door is lacking these, it makes it harder for a user
to "discover" how to use it at first glance, and they might try to push when 
they need to pull or vice-versa. 

The same idea applies to designing the way to organize research project files
within a directory. You want to make sure that a new user (or you in the future)
will be able to easily navigate through the directory to find what they need.
One article on organizing research project files notes that, when it comes to
deciding how to organize your files, "The core guiding principle is simple:
Someone unfamiliar with your project should be able to look at your computer
files and understand in detail what you did and why." [@noble2009quick] Another
notes, "Regardless of the particular project you're working on, your project
directory should be laid out in a consistent and understandable fashion. Clear
project organization makes it easier for both you and collaborators to figure
out exactly where and what everything is." [@buffalo2015bioinformatics]

One way to improve discoverability is to name your files and subdirectories 
in meaningful ways. The computer will give you wide flexibility in setting
names for files and subdirectories, but a human will find it much easier to 
navigate a directory when the names are clear labels that describe the contents.
For example, if you have data from different assays, you might organize them 
all into a directory named "raw_data" that is then divided into subdirectories
named with the type of assay. 

As you develop names that are discoverable, keep in mind that your users may
include some people outside your field, for whom some shorthand common in the
field might be unclear. For example, in some studies of infectious bacterial
disease, the bacterial load is measured in an assay that counts colony forming
units. Among bench scientists in this field, the assay is often called "CFUs".
If you are collaborating with a biostatistician, however, they may find the
files more discoverable if you named the subdirectory with these files something
like "bacterial_load" rather than "cfus", as they may not be familiar with that
shorthand.

One way to improve discoverability is to follow any standards that exist for
organizing project files [@marwick2018packaging]. As an example of how standards
can help discoverability, think about the design of cars. Most cars, regardless
of the manufacturer, will have the steering wheel, accelerator, and brake in
approximately the same position relative to the driver. By following this
standard, it's easier (and safer) for a driver to learn to use a car they
haven't driven before. When it comes to project file organization, these
standards will come in the form of which subdirectories are included, how
they're organized hierarchically, and how subdirectories and files are named.

These standards could exist as several levels: for your discipline, for your lab
group, or even for you as an individual. For example, when people develop R
packages, the package consists of a set of files, and there is a very clear and
highly enforced standard for how these files are arranged in a directory and how
the subdirectories are named. By enforcing this standard, many different people
can create packages and have them work in a similar way. On the opposite end of
the spectrum, if there are not clear standards at the level of your discipline,
you could create a clear standard that you plan to follow either for your lab
group or even for your individual work. If you're consistent in organizing your
files using that standard, it will make it easier to navigate files as you move
from one project to another. One article notes, 

> "The key principle is to organize the compendium so that another person can
know what to expect from the plain meaning of the file and directory names.
Using widely held conventions... will help other people to understand how your
files relate to each other without having to ask you. Naming objects is
difficult to do well, so it is worth to put some effort into a logical and
systematic file naming convention if you have a complex project with many files
and directories (e.g., a multi-experiment study where each experiment has
numerous data and code files)." [@marwick2018packaging]

As an added bonus, subdirectory organization can also be used in clever ways
within code scripts applied to files in the directory. For example, there are
functions in all scripting languages that will list all the files in a specified
subdirectory. If you keep all your raw data files of a certain type (for
example, all output from running flow cytometry for the project) within a single
subdirectory, you can use this type of function with code scripts to list all
the files in that directory and then apply code that you've developed to
preprocess or visualize the data across all those files. This code would
continue to work as you added files to that directory, since it starts by
looking in that subdirectory each time it runs and working with all files there
as of that moment. One article notes:

> "Organizing data files into a single directory with consistent filenames
prepares us to iterate over *all* of our data, whether it's the four example
files used in this example, or 40,000 files in a real project. Think of it this
way: remember when you discovered you could select many files with your mouse
cursor? With this trick, you could move 60 files as easily as six files. You
could also select certain file types (e.g., photos) and attach them all to an
email with one movement. By using consistent file naming and directory
organization, you can do the same programatically using the Unix shell and other
programming languages." [@buffalo2015bioinformatics]

### What is a project template?

Louis Pastuer famously said that "Luck favors the prepared mind." In file
organization, as with so much else, time spent preparing can pay off
exponentially later. In this case, the next step is to not only use a structured
directory for each project or experiment, but to start using the same,
standardized structure for every one of your projects and experiments. This
takes more work, in particular to design a structure that can be used across
many projects. However, the gains in terms of organization and efficiency can be
extraordinary. We have not run across many people who have taken the time to set
this up. However, among the people we know who have, we haven't run across many
who ever went back once they started using this type of system.

This involves first designing a common template for the directory structure for
your projects. Once you have decided on a structure for this template, you can
create a version of it on your computer---a file directory with all the
subdirectories included, but without any files (or only template files you'd
want to use as a starting point in each project, like templates for data
collection and reports as presented in Modules 2.4 and 2.5). When you start a
new project, you can then just copy this template and rename it. If you are
using R and begin to use R Projects (described in the next section), you can
also create an R Studio Project template to serve as this kind of starting point
each time you start a new project.

In other areas of science and engineering, this idea of standardized directory
structures has allowed the development of powerful techniques for open-source
software developers to work together. For example, anyone may create their own
extensions to the R programming language and share these with others through
GitHub or several large repositories. As mentioned briefly earlier in this
module, this is coordinated by enforcing a common directory structure on these
extension "packages"---to create a new package, you must put certain types of
files in certain subdirectories within a project directory. With these
standardized rules of directory structure and content, each of these packages
can interact with the base version of R, since there are functions that can tap
into any of these new packages by assuming where each type of file will be
within the package's directory of files. 

In a similar way, if you impose a common directory structure across all the
project directories in your research lab, your collaborators will quickly be
able to learn where to find each element, even in projects they are new to, and
you will all be able to write code that can be easily applied across all project
directories, allowing you to improve reproducibility and comparability across
all projects by assuring that you are conducting the same preprocessing and
analysis across all projects (or, if you are conducting things differently for
different projects, that you are deliberate and aware that you are doing so).
Creating a project template that you copy and rename as you start a new 
project is one way to facilitate this. 

As you use a template for a project, you can customize it as you need. For
example, if you had included a subdirectory for flow cytometry data, but are not
running that assay in this experiment, you can remove that subdirectory.
Similarly, you can customize the report as you go to help it work well for this
specific experiment. However, you will aim to keep to the standard format as
much as possible, since it's the standardization across projects that provides
many of the advantages.

In the next module, we will walk through the steps of designing a project
template that you can use across experiments for your laboratory group. In
module 2.8, we'll walk through an example of creating and using this kind of
project template for an example set of studies.

<!-- ### Practice quiz -->

